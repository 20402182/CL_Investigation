{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Investigation_into_CL.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "rv89m9nBPXSh",
        "0Ek0mErIac6n",
        "Dh8LaTgul6Jo",
        "aR4EUecz9tkD",
        "eunNybNi-a0t",
        "yUNaukXyiJni",
        "lCK0EYT-pJa8",
        "o3SM7U5fwTqV"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "dd834bb3245248c99b676b960a6ca8a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f924079ec3e144499a7e151e9bd7c455",
              "IPY_MODEL_ccb49d0c4c044e958ae414cbe97b3513",
              "IPY_MODEL_a0ae0288a9f042849bcd57d9981d2f9d"
            ],
            "layout": "IPY_MODEL_91c72dd077b24ca28946f2cb694e7c40"
          }
        },
        "f924079ec3e144499a7e151e9bd7c455": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b35ec4b0060e4003b2fbc9c50b574d42",
            "placeholder": "​",
            "style": "IPY_MODEL_1e78a6be766042559772af16632a072a",
            "value": ""
          }
        },
        "ccb49d0c4c044e958ae414cbe97b3513": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d1f55ef0b9044d4283b7b58f21b6a800",
            "max": 9912422,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e54db424f61245088bba2621768e361f",
            "value": 9912422
          }
        },
        "a0ae0288a9f042849bcd57d9981d2f9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a7e36fa29a54fdaabf134c548109155",
            "placeholder": "​",
            "style": "IPY_MODEL_a94d60c5e7bb46aa92f356df2db832bd",
            "value": " 9913344/? [00:00&lt;00:00, 18287172.04it/s]"
          }
        },
        "91c72dd077b24ca28946f2cb694e7c40": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b35ec4b0060e4003b2fbc9c50b574d42": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e78a6be766042559772af16632a072a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d1f55ef0b9044d4283b7b58f21b6a800": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e54db424f61245088bba2621768e361f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5a7e36fa29a54fdaabf134c548109155": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a94d60c5e7bb46aa92f356df2db832bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "17c325b091004c4aab0ddb9cdf1a0b1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_177377b9a5004ff2ae5f0b0296aa0c78",
              "IPY_MODEL_953c54da3c8d4dba8b17f536a5f303fc",
              "IPY_MODEL_da485fd099ce46d3b9c86d441864e334"
            ],
            "layout": "IPY_MODEL_86b26bd2374e48bea323594e96f148b5"
          }
        },
        "177377b9a5004ff2ae5f0b0296aa0c78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_595d59e325d74dcaa229ba27b11d3043",
            "placeholder": "​",
            "style": "IPY_MODEL_381f27cff22d40abaccbcc1a89651a76",
            "value": ""
          }
        },
        "953c54da3c8d4dba8b17f536a5f303fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e5fd446271645e9b39ac4ab30b465c9",
            "max": 28881,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_34e8c46a6c114759853643223a3286e8",
            "value": 28881
          }
        },
        "da485fd099ce46d3b9c86d441864e334": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2211773c55ad4139b0ca973a2ccdf872",
            "placeholder": "​",
            "style": "IPY_MODEL_363d0a458a5047a5b744bdcd157343c9",
            "value": " 29696/? [00:00&lt;00:00, 340424.16it/s]"
          }
        },
        "86b26bd2374e48bea323594e96f148b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "595d59e325d74dcaa229ba27b11d3043": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "381f27cff22d40abaccbcc1a89651a76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8e5fd446271645e9b39ac4ab30b465c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34e8c46a6c114759853643223a3286e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2211773c55ad4139b0ca973a2ccdf872": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "363d0a458a5047a5b744bdcd157343c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f9f52ea3ee1548eebc0e892244816e19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_feee71e186c64435aa09d1eb41004767",
              "IPY_MODEL_a129566f262e43c89a192ef54ff38fdd",
              "IPY_MODEL_6e8707bf6dcb40489fa9e6e704d412cc"
            ],
            "layout": "IPY_MODEL_b65b0ac372c24937bde1ffdf6ecf293e"
          }
        },
        "feee71e186c64435aa09d1eb41004767": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c6072aec0c70454698eb18d9c094ac2b",
            "placeholder": "​",
            "style": "IPY_MODEL_190dc056bb694f408168c0708409508f",
            "value": ""
          }
        },
        "a129566f262e43c89a192ef54ff38fdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9ce7c0ca645420c9c8045b4ee54c3c1",
            "max": 1648877,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9ce5a851e0a0452688a4ad5527ffc5f8",
            "value": 1648877
          }
        },
        "6e8707bf6dcb40489fa9e6e704d412cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a4831a6f6cf4713bf7f2f46023fc731",
            "placeholder": "​",
            "style": "IPY_MODEL_1183c6ef2e184cc6a27f9e212750848b",
            "value": " 1649664/? [00:00&lt;00:00, 2491935.19it/s]"
          }
        },
        "b65b0ac372c24937bde1ffdf6ecf293e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6072aec0c70454698eb18d9c094ac2b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "190dc056bb694f408168c0708409508f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a9ce7c0ca645420c9c8045b4ee54c3c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ce5a851e0a0452688a4ad5527ffc5f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9a4831a6f6cf4713bf7f2f46023fc731": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1183c6ef2e184cc6a27f9e212750848b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8356bff44df544e4aa502924a05c4ea4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a8f2bffa2b1a484391b4f742df2de248",
              "IPY_MODEL_68542c4f0e234c048fdf696aa0b14276",
              "IPY_MODEL_fbc3c226c2eb4d078327f2a96a239437"
            ],
            "layout": "IPY_MODEL_098b380899d246b195a35d0615ec6a87"
          }
        },
        "a8f2bffa2b1a484391b4f742df2de248": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c411af4fe5404142ab3befac246f169a",
            "placeholder": "​",
            "style": "IPY_MODEL_d7fbab7c05db48c6b3a11affa1c72587",
            "value": ""
          }
        },
        "68542c4f0e234c048fdf696aa0b14276": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60694e8f551847b5909ab3bd766855e3",
            "max": 4542,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_856c6d65d8e44c66aa1ac8992f6118f2",
            "value": 4542
          }
        },
        "fbc3c226c2eb4d078327f2a96a239437": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77df42012aef4b0097b9b849dc5be5ed",
            "placeholder": "​",
            "style": "IPY_MODEL_75910fc2fc8842679f799b29405a850b",
            "value": " 5120/? [00:00&lt;00:00, 7124.04it/s]"
          }
        },
        "098b380899d246b195a35d0615ec6a87": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c411af4fe5404142ab3befac246f169a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7fbab7c05db48c6b3a11affa1c72587": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "60694e8f551847b5909ab3bd766855e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "856c6d65d8e44c66aa1ac8992f6118f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "77df42012aef4b0097b9b849dc5be5ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75910fc2fc8842679f799b29405a850b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/20402182/CL_Investigation/blob/main/Investigation_into_CL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7AxhUWe68vT"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rv89m9nBPXSh"
      },
      "source": [
        "## MNIST Dataset\n",
        "\n",
        "MNIST is a dataset of 60,000, 28x28 greyscale images depicting handwritten digits from 0 to 9. This dataset is small due to its 28x28x1 image size so training time will be short.   \n",
        "MNIST dataset will be initialised using a script found at https://github.com/ContinualAI/colab.git"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKWbcnh474X3",
        "outputId": "0da58264-d355-4ed8-bbd8-f34e0251808b"
      },
      "source": [
        "!git clone https://github.com/ContinualAI/colab.git continualai/colab"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'continualai/colab'...\n",
            "remote: Enumerating objects: 373, done.\u001b[K\n",
            "remote: Counting objects: 100% (115/115), done.\u001b[K\n",
            "remote: Compressing objects: 100% (53/53), done.\u001b[K\n",
            "remote: Total 373 (delta 75), reused 62 (delta 62), pack-reused 258\u001b[K\n",
            "Receiving objects: 100% (373/373), 26.96 MiB | 22.85 MiB/s, done.\n",
            "Resolving deltas: 100% (195/195), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 785,
          "referenced_widgets": [
            "dd834bb3245248c99b676b960a6ca8a8",
            "f924079ec3e144499a7e151e9bd7c455",
            "ccb49d0c4c044e958ae414cbe97b3513",
            "a0ae0288a9f042849bcd57d9981d2f9d",
            "91c72dd077b24ca28946f2cb694e7c40",
            "b35ec4b0060e4003b2fbc9c50b574d42",
            "1e78a6be766042559772af16632a072a",
            "d1f55ef0b9044d4283b7b58f21b6a800",
            "e54db424f61245088bba2621768e361f",
            "5a7e36fa29a54fdaabf134c548109155",
            "a94d60c5e7bb46aa92f356df2db832bd",
            "17c325b091004c4aab0ddb9cdf1a0b1e",
            "177377b9a5004ff2ae5f0b0296aa0c78",
            "953c54da3c8d4dba8b17f536a5f303fc",
            "da485fd099ce46d3b9c86d441864e334",
            "86b26bd2374e48bea323594e96f148b5",
            "595d59e325d74dcaa229ba27b11d3043",
            "381f27cff22d40abaccbcc1a89651a76",
            "8e5fd446271645e9b39ac4ab30b465c9",
            "34e8c46a6c114759853643223a3286e8",
            "2211773c55ad4139b0ca973a2ccdf872",
            "363d0a458a5047a5b744bdcd157343c9",
            "f9f52ea3ee1548eebc0e892244816e19",
            "feee71e186c64435aa09d1eb41004767",
            "a129566f262e43c89a192ef54ff38fdd",
            "6e8707bf6dcb40489fa9e6e704d412cc",
            "b65b0ac372c24937bde1ffdf6ecf293e",
            "c6072aec0c70454698eb18d9c094ac2b",
            "190dc056bb694f408168c0708409508f",
            "a9ce7c0ca645420c9c8045b4ee54c3c1",
            "9ce5a851e0a0452688a4ad5527ffc5f8",
            "9a4831a6f6cf4713bf7f2f46023fc731",
            "1183c6ef2e184cc6a27f9e212750848b",
            "8356bff44df544e4aa502924a05c4ea4",
            "a8f2bffa2b1a484391b4f742df2de248",
            "68542c4f0e234c048fdf696aa0b14276",
            "fbc3c226c2eb4d078327f2a96a239437",
            "098b380899d246b195a35d0615ec6a87",
            "c411af4fe5404142ab3befac246f169a",
            "d7fbab7c05db48c6b3a11affa1c72587",
            "60694e8f551847b5909ab3bd766855e3",
            "856c6d65d8e44c66aa1ac8992f6118f2",
            "77df42012aef4b0097b9b849dc5be5ed",
            "75910fc2fc8842679f799b29405a850b"
          ]
        },
        "id": "x3BFVukM_y8i",
        "outputId": "4345dffb-4e9c-4fa6-bb62-375ff14cc1b7"
      },
      "source": [
        "from continualai.colab.scripts import mnist\n",
        "mnist.init()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading train-images-idx3-ubyte.gz...\n",
            "Downloading t10k-images-idx3-ubyte.gz...\n",
            "Downloading train-labels-idx1-ubyte.gz...\n",
            "Downloading t10k-labels-idx1-ubyte.gz...\n",
            "Download complete.\n",
            "Save complete.\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to data/mnist/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/9912422 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dd834bb3245248c99b676b960a6ca8a8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/mnist/MNIST/raw/train-images-idx3-ubyte.gz to data/mnist/MNIST/raw\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to data/mnist/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/28881 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "17c325b091004c4aab0ddb9cdf1a0b1e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/mnist/MNIST/raw/train-labels-idx1-ubyte.gz to data/mnist/MNIST/raw\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to data/mnist/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1648877 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f9f52ea3ee1548eebc0e892244816e19"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/mnist/MNIST/raw/t10k-images-idx3-ubyte.gz to data/mnist/MNIST/raw\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to data/mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/4542 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8356bff44df544e4aa502924a05c4ea4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/mnist/MNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jIk6-G6AhWi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5351867a-589f-4d7c-d899-373e4e942966"
      },
      "source": [
        "x_train, t_train, x_test, t_test = mnist.load()\n",
        "\n",
        "print(\"x_train dim and type: \", x_train.shape, x_train.dtype)\n",
        "print(\"t_train dim and type: \", t_train.shape, t_train.dtype)\n",
        "print(\"x_test dim and type: \", x_test.shape, x_test.dtype)\n",
        "print(\"t_test dim and type: \", t_test.shape, t_test.dtype)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train dim and type:  (60000, 1, 28, 28) float32\n",
            "t_train dim and type:  (60000,) uint8\n",
            "x_test dim and type:  (10000, 1, 28, 28) float32\n",
            "t_test dim and type:  (10000,) uint8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XEWG2PmbVvb7"
      },
      "source": [
        "This shows a few examples of the data that exist in the set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RyIuYAw8AuO6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "6aa4c475-e833-4196-ff64-19c84e261ea5"
      },
      "source": [
        "f, axarr = plt.subplots(2,2)\n",
        "axarr[0,0].imshow(x_train[1, 0], cmap=\"gray\")\n",
        "axarr[0,1].imshow(x_train[2, 0], cmap=\"gray\")\n",
        "axarr[1,0].imshow(x_train[3, 0], cmap=\"gray\")\n",
        "axarr[1,1].imshow(x_train[4, 0], cmap=\"gray\")\n",
        "np.vectorize(lambda ax:ax.axis('off'))(axarr);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baEsU4PGXsgS"
      },
      "source": [
        "This chooses to use cuda cores if they are available. \n",
        "Using cuda cores means to use GPU acceleration, which dramatically reduces training time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztZAPQNXZ4ll"
      },
      "source": [
        "# switch to False to use CPU\n",
        "use_cuda = True\n",
        "\n",
        "use_cuda = use_cuda and torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\");\n",
        "torch.manual_seed(1);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Ek0mErIac6n"
      },
      "source": [
        "# Model and shared functions"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model utilises 3 convolutional layers and 2 fully contected layers"
      ],
      "metadata": {
        "id": "6_Rrsg9o7R7B"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONMdybG4Be0z"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        # this function creates the layers to bee used\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
        "        self.conv2_drop = nn.Dropout2d()\n",
        "        self.fc1 = nn.Linear(320, 50)\n",
        "        self.fc2 = nn.Linear(50, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # this function connects the layers\n",
        "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
        "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
        "        x = x.view(-1, 320)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9S6a-MlYAsu"
      },
      "source": [
        "These are the train and test functions used by some models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGJJfXhJB-zk"
      },
      "source": [
        "def train(model, device, x_train, t_train, optimizer, epoch):\n",
        "    model.train()\n",
        "    \n",
        "    for start in range(0, len(t_train)-1, 256):\n",
        "      end = start + 256\n",
        "      x, y = torch.from_numpy(x_train[start:end]), torch.from_numpy(t_train[start:end]).long()\n",
        "      x, y = x.to(device), y.to(device)\n",
        "      \n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      output = model(x)\n",
        "      loss = F.cross_entropy(output, y)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      #print(loss.item())\n",
        "    print('Train Epoch: {} \\tLoss: {:.6f}'.format(epoch, loss.item()))\n",
        "\n",
        "def test(model, device, x_test, t_test):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    for start in range(0, len(t_test)-1, 256):\n",
        "      end = start + 256\n",
        "      with torch.no_grad():\n",
        "        x, y = torch.from_numpy(x_test[start:end]), torch.from_numpy(t_test[start:end]).long()\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        output = model(x)\n",
        "        test_loss += F.cross_entropy(output, y).item() # sum up batch loss\n",
        "        pred = output.max(1, keepdim=True)[1] # get the index of the max logit\n",
        "        correct += pred.eq(y.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(t_test)\n",
        "    print('Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(t_test),\n",
        "        100. * correct / len(t_test)))\n",
        "    return 100. * correct / len(t_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxIISdDPaqb9"
      },
      "source": [
        "This function permutes, or rearranges the pixels of every image in the dataset in the same way, this creates a new task for the model, as the learning for the unmodified dataset is not relevant to classifying the new images."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def permute_mnist(mnist, seed):\n",
        "    \"\"\" Given the training set, permute pixels of each img the same way. \"\"\"\n",
        "\n",
        "    np.random.seed(seed)\n",
        "    print(\"starting permutation...\")\n",
        "    h = w = 28\n",
        "    perm_inds = list(range(h*w))\n",
        "    np.random.shuffle(perm_inds)\n",
        "    # print(perm_inds)\n",
        "    perm_mnist = []\n",
        "    for set in mnist:\n",
        "        num_img = set.shape[0]\n",
        "        flat_set = set.reshape(num_img, w * h)\n",
        "        perm_mnist.append(flat_set[:, perm_inds].reshape(num_img, 1, w, h))\n",
        "    print(\"done.\")\n",
        "    return perm_mnist"
      ],
      "metadata": {
        "id": "RzOSCWVmIdxD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qwh4T5Va86-"
      },
      "source": [
        "This final set of functions can be used to measure training times for each epoch and for the train as a whole."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://stackoverflow.com/a/55492933\n",
        "import time\n",
        "\n",
        "class TimeHistory():\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.times = []\n",
        "\n",
        "    def on_epoch_begin(self, batch, logs={}):\n",
        "        self.epoch_time_start = time.time()\n",
        "\n",
        "    def on_epoch_end(self, batch, logs={}):\n",
        "        self.times.append(time.time() - self.epoch_time_start)\n",
        "\n",
        "timer = TimeHistory()"
      ],
      "metadata": {
        "id": "ChrRFOpqmo_C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Traditional Strategy"
      ],
      "metadata": {
        "id": "Dh8LaTgul6Jo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NI (new instances)\n",
        "\n",
        "When new instances are added to the dataset there is more data to work with, more training data can potentially increase the accuracy of the model.   \n",
        "This new data though usually means that the model has to be retrained from scratch, which can be a long process, and requires bringing up the *entire* dataset again."
      ],
      "metadata": {
        "id": "aR4EUecz9tkD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, device, x_train, t_train, optimizer, epoch, timer):\n",
        "    timer.on_epoch_begin(1)\n",
        "    model.train()\n",
        "    timer.on_epoch_end(1)\n",
        "    \n",
        "    for start in range(0, len(t_train)-1, 256):\n",
        "      end = start + 256\n",
        "      x, y = torch.from_numpy(x_train[start:end]), torch.from_numpy(t_train[start:end]).long()\n",
        "      x, y = x.to(device), y.to(device)\n",
        "      \n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      output = model(x)\n",
        "      loss = F.cross_entropy(output, y)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      #print(loss.item())\n",
        "    print('Train Epoch: {} \\tLoss: {:.6f}'.format(epoch, loss.item()))\n",
        "    return loss.item()\n",
        "\n",
        "def test(model, device, x_test, t_test):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    for start in range(0, len(t_test)-1, 256):\n",
        "      end = start + 256\n",
        "      with torch.no_grad():\n",
        "        x, y = torch.from_numpy(x_test[start:end]), torch.from_numpy(t_test[start:end]).long()\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        output = model(x)\n",
        "        test_loss += F.cross_entropy(output, y).item() # sum up batch loss\n",
        "        pred = output.max(1, keepdim=True)[1] # get the index of the max logit\n",
        "        correct += pred.eq(y.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(t_test)\n",
        "    print('Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(t_test),\n",
        "        100. * correct / len(t_test)))\n",
        "    return test_loss, 100. * correct / len(t_test)"
      ],
      "metadata": {
        "id": "sikW5PdPmVvY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_increments = 10 # refers to the number of different levels of data that are tested to show the difference between models\n",
        "x_size = len(x_train)\n",
        "t_size = len(t_train)\n",
        "\n",
        "DATA_NI_MODEL = {}\n",
        "for i in range (1,dataset_increments): \n",
        "      print(x_size * (1 / dataset_increments) * i)\n",
        "      DATA_NI_MODEL[i] = {}\n",
        "\n",
        "      x = x_train[:int(x_size * (1 / dataset_increments) * i)]\n",
        "      t = t_train[:int(x_size * (1 / dataset_increments) * i)]\n",
        "\n",
        "      model = Net().to(device)\n",
        "      optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "      timer.on_train_begin()\n",
        "      for epoch in range(1, 4):\n",
        "          train_loss = train(model, device, x, t, optimizer, epoch, timer)\n",
        "          loss, acc = test(model, device, x_test, t_test)\n",
        "          DATA_NI_MODEL[i][epoch] = {\n",
        "              \"train_loss\" : train_loss,\n",
        "              \"loss\" : loss,\n",
        "              \"acc\" : acc\n",
        "          }\n",
        "\n",
        "      timeCount = np.average(timer.times) * 10000\n",
        "      DATA_NI_MODEL[i][\"time\"] = timeCount\n",
        "      print(\"Time: \" + str(timeCount))\n",
        "print(DATA_NI_MODEL)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ml6hPQpzmyHz",
        "outputId": "9e9584c8-2865-479b-a966-df2807195501"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6000.0\n",
            "Train Epoch: 1 \tLoss: 2.292454\n",
            "Test set: Average loss: 0.0092, Accuracy: 1195/10000 (12%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 2.266730\n",
            "Test set: Average loss: 0.0090, Accuracy: 2212/10000 (22%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 2.139745\n",
            "Test set: Average loss: 0.0082, Accuracy: 4299/10000 (43%)\n",
            "\n",
            "Time: 0.40133794148763025\n",
            "12000.0\n",
            "Train Epoch: 1 \tLoss: 2.275947\n",
            "Test set: Average loss: 0.0091, Accuracy: 2961/10000 (30%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 1.989419\n",
            "Test set: Average loss: 0.0074, Accuracy: 4857/10000 (49%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 1.111719\n",
            "Test set: Average loss: 0.0028, Accuracy: 7990/10000 (80%)\n",
            "\n",
            "Time: 0.3544489542643229\n",
            "18000.0\n",
            "Train Epoch: 1 \tLoss: 2.270383\n",
            "Test set: Average loss: 0.0091, Accuracy: 2660/10000 (27%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 1.341165\n",
            "Test set: Average loss: 0.0042, Accuracy: 7428/10000 (74%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 0.678102\n",
            "Test set: Average loss: 0.0017, Accuracy: 8761/10000 (88%)\n",
            "\n",
            "Time: 0.35365422566731775\n",
            "24000.0\n",
            "Train Epoch: 1 \tLoss: 1.993967\n",
            "Test set: Average loss: 0.0070, Accuracy: 6129/10000 (61%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 0.797854\n",
            "Test set: Average loss: 0.0016, Accuracy: 8876/10000 (89%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 0.585130\n",
            "Test set: Average loss: 0.0011, Accuracy: 9198/10000 (92%)\n",
            "\n",
            "Time: 0.3457069396972656\n",
            "30000.0\n",
            "Train Epoch: 1 \tLoss: 1.432558\n",
            "Test set: Average loss: 0.0031, Accuracy: 8024/10000 (80%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 0.801121\n",
            "Test set: Average loss: 0.0013, Accuracy: 9069/10000 (91%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 0.824693\n",
            "Test set: Average loss: 0.0009, Accuracy: 9308/10000 (93%)\n",
            "\n",
            "Time: 0.3695487976074219\n",
            "36000.0\n",
            "Train Epoch: 1 \tLoss: 1.025127\n",
            "Test set: Average loss: 0.0024, Accuracy: 8234/10000 (82%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 0.676225\n",
            "Test set: Average loss: 0.0013, Accuracy: 9045/10000 (90%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 0.534897\n",
            "Test set: Average loss: 0.0009, Accuracy: 9334/10000 (93%)\n",
            "\n",
            "Time: 0.3488858540852865\n",
            "42000.0\n",
            "Train Epoch: 1 \tLoss: 0.930231\n",
            "Test set: Average loss: 0.0021, Accuracy: 8338/10000 (83%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 0.605528\n",
            "Test set: Average loss: 0.0010, Accuracy: 9282/10000 (93%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 0.600746\n",
            "Test set: Average loss: 0.0007, Accuracy: 9416/10000 (94%)\n",
            "\n",
            "Time: 0.3949801127115885\n",
            "48000.0\n",
            "Train Epoch: 1 \tLoss: 0.970856\n",
            "Test set: Average loss: 0.0016, Accuracy: 8795/10000 (88%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 0.623009\n",
            "Test set: Average loss: 0.0009, Accuracy: 9355/10000 (94%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 0.448713\n",
            "Test set: Average loss: 0.0006, Accuracy: 9509/10000 (95%)\n",
            "\n",
            "Time: 0.358422597249349\n",
            "54000.0\n",
            "Train Epoch: 1 \tLoss: 0.677054\n",
            "Test set: Average loss: 0.0016, Accuracy: 8714/10000 (87%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 0.449160\n",
            "Test set: Average loss: 0.0009, Accuracy: 9362/10000 (94%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 0.360542\n",
            "Test set: Average loss: 0.0006, Accuracy: 9528/10000 (95%)\n",
            "\n",
            "Time: 0.37113825480143225\n",
            "{1: {1: {'train_loss': 2.2924535274505615, 'loss': 0.00916756467819214, 'acc': 11.95}, 2: {'train_loss': 2.2667300701141357, 'loss': 0.009016350555419921, 'acc': 22.12}, 3: {'train_loss': 2.1397452354431152, 'loss': 0.008185567760467529, 'acc': 42.99}, 'time': 0.40133794148763025}, 2: {1: {'train_loss': 2.275947093963623, 'loss': 0.009090036582946777, 'acc': 29.61}, 2: {'train_loss': 1.9894192218780518, 'loss': 0.007368216109275818, 'acc': 48.57}, 3: {'train_loss': 1.111718773841858, 'loss': 0.0027832350075244904, 'acc': 79.9}, 'time': 0.3544489542643229}, 3: {1: {'train_loss': 2.270383358001709, 'loss': 0.009076669883728027, 'acc': 26.6}, 2: {'train_loss': 1.34116530418396, 'loss': 0.00422056525349617, 'acc': 74.28}, 3: {'train_loss': 0.6781015992164612, 'loss': 0.0017463231310248374, 'acc': 87.61}, 'time': 0.35365422566731775}, 4: {1: {'train_loss': 1.9939674139022827, 'loss': 0.00701313568353653, 'acc': 61.29}, 2: {'train_loss': 0.7978543639183044, 'loss': 0.0015894717499613763, 'acc': 88.76}, 3: {'train_loss': 0.5851295590400696, 'loss': 0.0010944849491119385, 'acc': 91.98}, 'time': 0.3457069396972656}, 5: {1: {'train_loss': 1.4325579404830933, 'loss': 0.0031127165138721464, 'acc': 80.24}, 2: {'train_loss': 0.8011205196380615, 'loss': 0.0012794721685349942, 'acc': 90.69}, 3: {'train_loss': 0.8246934413909912, 'loss': 0.0009359110899269581, 'acc': 93.08}, 'time': 0.3695487976074219}, 6: {1: {'train_loss': 1.0251271724700928, 'loss': 0.0024209115505218507, 'acc': 82.34}, 2: {'train_loss': 0.6762245297431946, 'loss': 0.0012897067487239837, 'acc': 90.45}, 3: {'train_loss': 0.534896969795227, 'loss': 0.0008548244556412101, 'acc': 93.34}, 'time': 0.3488858540852865}, 7: {1: {'train_loss': 0.9302313923835754, 'loss': 0.0020833231538534163, 'acc': 83.38}, 2: {'train_loss': 0.6055277585983276, 'loss': 0.0010361372545361518, 'acc': 92.82}, 3: {'train_loss': 0.600745677947998, 'loss': 0.0007485628159716725, 'acc': 94.16}, 'time': 0.3949801127115885}, 8: {1: {'train_loss': 0.970856249332428, 'loss': 0.0016222374781966209, 'acc': 87.95}, 2: {'train_loss': 0.6230085492134094, 'loss': 0.0008837750751525163, 'acc': 93.55}, 3: {'train_loss': 0.4487129747867584, 'loss': 0.0006443192974664271, 'acc': 95.09}, 'time': 0.358422597249349}, 9: {1: {'train_loss': 0.6770536303520203, 'loss': 0.001634502813220024, 'acc': 87.14}, 2: {'train_loss': 0.4491601586341858, 'loss': 0.000883065339922905, 'acc': 93.62}, 3: {'train_loss': 0.36054152250289917, 'loss': 0.0006240164009854197, 'acc': 95.28}, 'time': 0.37113825480143225}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This can be allieviated by remembering the weights in the model and continuing training from where it was left off   \n",
        "this method has its own drawback of potentially leading to overfitting"
      ],
      "metadata": {
        "id": "CbXhQBOs-1mm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Net().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "dataset_increments = 5 # refers to the number of different levels of data that are tested to show the difference between models\n",
        "x_size = len(x_train)\n",
        "t_size = len(t_train)\n",
        "\n",
        "for i in range (1,dataset_increments): \n",
        "      print(x_size * (1 / dataset_increments) * i)\n",
        "\n",
        "      x = x_train[:int(x_size * (1 / dataset_increments) * i)]\n",
        "      t = t_train[:int(x_size * (1 / dataset_increments) * i)]\n",
        "\n",
        "      timer.on_train_begin()\n",
        "      for epoch in range(1, 4):\n",
        "          train(model, device, x, t, optimizer, epoch, timer)\n",
        "          test(model, device, x_test, t_test)\n",
        "\n",
        "      timeCount = np.average(timer.times) * 10000\n",
        "      print(\"Time: \" + str(timeCount))"
      ],
      "metadata": {
        "id": "xnViSjmh_FO2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9722448d-5ddb-4f24-da0e-c1328f685ca6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12000.0\n",
            "Train Epoch: 1 \tLoss: 2.253037\n",
            "Test set: Average loss: 0.0089, Accuracy: 4987/10000 (50%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 1.588302\n",
            "Test set: Average loss: 0.0050, Accuracy: 6625/10000 (66%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 0.887106\n",
            "Test set: Average loss: 0.0024, Accuracy: 8217/10000 (82%)\n",
            "\n",
            "Time: 0.49591064453125\n",
            "24000.0\n",
            "Train Epoch: 1 \tLoss: 0.621161\n",
            "Test set: Average loss: 0.0014, Accuracy: 8932/10000 (89%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 0.488525\n",
            "Test set: Average loss: 0.0010, Accuracy: 9223/10000 (92%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 0.465255\n",
            "Test set: Average loss: 0.0009, Accuracy: 9312/10000 (93%)\n",
            "\n",
            "Time: 0.4140535990397135\n",
            "36000.0\n",
            "Train Epoch: 1 \tLoss: 0.350922\n",
            "Test set: Average loss: 0.0006, Accuracy: 9509/10000 (95%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 0.259530\n",
            "Test set: Average loss: 0.0005, Accuracy: 9575/10000 (96%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 0.353961\n",
            "Test set: Average loss: 0.0005, Accuracy: 9619/10000 (96%)\n",
            "\n",
            "Time: 0.48955281575520837\n",
            "48000.0\n",
            "Train Epoch: 1 \tLoss: 0.507824\n",
            "Test set: Average loss: 0.0004, Accuracy: 9660/10000 (97%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 0.429111\n",
            "Test set: Average loss: 0.0004, Accuracy: 9703/10000 (97%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 0.305639\n",
            "Test set: Average loss: 0.0003, Accuracy: 9723/10000 (97%)\n",
            "\n",
            "Time: 0.49273173014322913\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## New Task\n",
        "\n",
        "If the model were to be trained for a new task, training the model with this additional data to a satisfactory standard can mean that the model is less effective in classifying the previously trained data."
      ],
      "metadata": {
        "id": "eunNybNi-a0t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Net().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "timer.on_train_begin()\n",
        "for epoch in range(1, 4):\n",
        "    train(model, device, x_train, t_train, optimizer, epoch, timer)\n",
        "    test(model, device, x_test, t_test)\n",
        "\n",
        "test(model, device, x_test, t_test)"
      ],
      "metadata": {
        "id": "N6jUvj3Y_JTO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3231c89-6679-4965-8ac5-fb56fd434bde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 \tLoss: 0.676115\n",
            "Test set: Average loss: 0.0012, Accuracy: 9046/10000 (90%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 0.637049\n",
            "Test set: Average loss: 0.0007, Accuracy: 9475/10000 (95%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 0.459596\n",
            "Test set: Average loss: 0.0005, Accuracy: 9585/10000 (96%)\n",
            "\n",
            "Test set: Average loss: 0.0005, Accuracy: 9585/10000 (96%)\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.0004988463742192834, 95.85)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "An accuracy value can be achieved by testing the model"
      ],
      "metadata": {
        "id": "m7RlpY7-APSF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train2, x_test2 = permute_mnist([x_train, x_test], 1)\n",
        "\n",
        "timer.on_train_begin()\n",
        "for epoch in range(1, 4):\n",
        "    train(model, device, x_train2, t_train, optimizer, epoch, timer)\n",
        "    test(model, device, x_test, t_test)\n",
        "\n",
        "test(model, device, x_test2, t_test)"
      ],
      "metadata": {
        "id": "fksbJAxJ_iDW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0a0e5bf-9ade-438c-a3dd-8caf0942392a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "starting permutation...\n",
            "done.\n",
            "Train Epoch: 1 \tLoss: 1.581925\n",
            "Test set: Average loss: 0.0176, Accuracy: 1853/10000 (19%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 1.219720\n",
            "Test set: Average loss: 0.0249, Accuracy: 1554/10000 (16%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 1.117955\n",
            "Test set: Average loss: 0.0242, Accuracy: 1565/10000 (16%)\n",
            "\n",
            "Test set: Average loss: 0.0020, Accuracy: 8491/10000 (85%)\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.001982059819996357, 84.91)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training the model for the additional task and testing on the new task gives a new value for the test"
      ],
      "metadata": {
        "id": "RB6VTSPsAW_1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test(model, device, x_test, t_test)"
      ],
      "metadata": {
        "id": "6jwfEL2OALTu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07928c5a-57f7-4863-f514-fb9115e357e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set: Average loss: 0.0242, Accuracy: 1565/10000 (16%)\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.024163356494903563, 15.65)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The old test has a lower accuracy value than before"
      ],
      "metadata": {
        "id": "BX0jOc2SAuNW"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rUgLpUakTy6"
      },
      "source": [
        "# CL Strategies\n",
        "\n",
        "To effectively learn continuously, the forgetting of previous tasks demonstrateed in Traditional machine learning strategies, called catastrophic forgetting, needs to be mitigated. The following are methods of mitigating catastophic forgetting, by modifying how the existing model updates its weights.\n",
        "\n",
        "1.   Naive\n",
        "2.   Rehearsal\n",
        "3.   Elastic Weight Consolidation (EWC)\n",
        "4.   Synaptic Intelligence (SI)\n",
        "\n",
        "Each method will be testsed using 3 tasks made from Permuted MNIST.\n",
        "\n",
        "Starting with defining the 3 tasks using the permute_mnist() function.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yu0T_V24joGY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "541f4194-1a85-4796-d7cf-835f8f4d1455"
      },
      "source": [
        "# task 1\n",
        "task_1 = [(x_train, t_train), (x_test, t_test)]\n",
        "\n",
        "# task 2\n",
        "x_train2, x_test2 = permute_mnist([x_train, x_test], 1)\n",
        "task_2 = [(x_train2, t_train), (x_test2, t_test)]\n",
        "\n",
        "# task 3\n",
        "x_train3, x_test3 = permute_mnist([x_train, x_test], 2)\n",
        "task_3 = [(x_train3, t_train), (x_test3, t_test)]\n",
        "\n",
        "# task list\n",
        "tasks = [task_1, task_2, task_3]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "starting permutation...\n",
            "done.\n",
            "starting permutation...\n",
            "done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUNaukXyiJni"
      },
      "source": [
        "## Naive / Traditional\n",
        "\n",
        "In Continuous Learning settings, the standard way to refer to a model that does not continuously learn is \"naive\".\n",
        "The naive strategy, as already demonstrated, is simply to train on new tasks, and, as demonstrated, is extremely prone to forgetting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzFEA5F8pI_O"
      },
      "source": [
        "model = Net().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLU6KdIbnLMN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0623ebc4-58b7-414c-e295-93f63d96fa49"
      },
      "source": [
        "dataset_increments = 10 # refers to the number of different levels of data that are tested to show the difference between models\n",
        "x_size = len(x_train)\n",
        "t_size = len(t_train)\n",
        "\n",
        "DATA_NAIVE_MODEL = {}\n",
        "for i in range (1,dataset_increments): \n",
        "      print(x_size * (1 / dataset_increments) * i)\n",
        "      DATA_NAIVE_MODEL[i] = {}\n",
        "\n",
        "      for id, task in enumerate(tasks):\n",
        "        print(\"Training on task: \", id)\n",
        "        DATA_NAIVE_MODEL[i][id] ={}\n",
        "\n",
        "        (x_train, t_train), (x_test, t_test) = task\n",
        "\n",
        "        x = x_train[:int(x_size * (1 / dataset_increments) * i)]\n",
        "        t = t_train[:int(x_size * (1 / dataset_increments) * i)]\n",
        "\n",
        "        timer.on_train_begin()\n",
        "        for epoch in range(1, 4):\n",
        "              train_loss = train(model, device, x, t, optimizer, epoch, timer)\n",
        "\n",
        "              loss, acc = test(model, device, x_test, t_test)\n",
        "\n",
        "              DATA_NAIVE_MODEL[i][id][epoch] = {\n",
        "                  \"train_loss\" : train_loss,\n",
        "                  \"loss\" : loss,\n",
        "                  \"acc\" : acc\n",
        "              }\n",
        "\n",
        "        timeCount = np.average(timer.times) * 10000\n",
        "        DATA_NAIVE_MODEL[i][id][\"time\"] = timeCount\n",
        "        print(\"Time: \" + str(timeCount))\n",
        "print(DATA_NAIVE_MODEL)  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6000.0\n",
            "Training on task:  0\n",
            "Train Epoch: 1 \tLoss: 2.290832\n",
            "Test set: Average loss: 0.0090, Accuracy: 3706/10000 (37%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 2.161490\n",
            "Test set: Average loss: 0.0084, Accuracy: 4743/10000 (47%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 1.733964\n",
            "Test set: Average loss: 0.0058, Accuracy: 6804/10000 (68%)\n",
            "\n",
            "Time: 0.4116694132486979\n",
            "Training on task:  1\n",
            "Train Epoch: 1 \tLoss: 2.287619\n",
            "Test set: Average loss: 0.0091, Accuracy: 2046/10000 (20%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 2.186311\n",
            "Test set: Average loss: 0.0088, Accuracy: 2890/10000 (29%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 2.172372\n",
            "Test set: Average loss: 0.0083, Accuracy: 3437/10000 (34%)\n",
            "\n",
            "Time: 0.39180119832356775\n",
            "Training on task:  2\n",
            "Train Epoch: 1 \tLoss: 2.163676\n",
            "Test set: Average loss: 0.0085, Accuracy: 3074/10000 (31%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 2.003976\n",
            "Test set: Average loss: 0.0078, Accuracy: 3682/10000 (37%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 1.881421\n",
            "Test set: Average loss: 0.0070, Accuracy: 4463/10000 (45%)\n",
            "\n",
            "Time: 0.404516855875651\n",
            "12000.0\n",
            "Training on task:  0\n",
            "Train Epoch: 1 \tLoss: 0.887352\n",
            "Test set: Average loss: 0.0023, Accuracy: 8324/10000 (83%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 0.671583\n",
            "Test set: Average loss: 0.0015, Accuracy: 8911/10000 (89%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 0.561109\n",
            "Test set: Average loss: 0.0012, Accuracy: 9160/10000 (92%)\n",
            "\n",
            "Time: 0.4744529724121094\n",
            "Training on task:  1\n",
            "Train Epoch: 1 \tLoss: 1.943652\n",
            "Test set: Average loss: 0.0070, Accuracy: 4255/10000 (43%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 1.587826\n",
            "Test set: Average loss: 0.0054, Accuracy: 5892/10000 (59%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 1.344030\n",
            "Test set: Average loss: 0.0043, Accuracy: 6682/10000 (67%)\n",
            "\n",
            "Time: 0.4442532857259115\n",
            "Training on task:  2\n",
            "Train Epoch: 1 \tLoss: 1.712312\n",
            "Test set: Average loss: 0.0060, Accuracy: 4994/10000 (50%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 1.500510\n",
            "Test set: Average loss: 0.0046, Accuracy: 6378/10000 (64%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 1.170074\n",
            "Test set: Average loss: 0.0038, Accuracy: 7068/10000 (71%)\n",
            "\n",
            "Time: 0.4331270853678385\n",
            "18000.0\n",
            "Training on task:  0\n",
            "Train Epoch: 1 \tLoss: 0.532260\n",
            "Test set: Average loss: 0.0012, Accuracy: 9102/10000 (91%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 0.381118\n",
            "Test set: Average loss: 0.0010, Accuracy: 9298/10000 (93%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 0.441506\n",
            "Test set: Average loss: 0.0008, Accuracy: 9380/10000 (94%)\n",
            "\n",
            "Time: 0.4291534423828125\n",
            "Training on task:  1\n",
            "Train Epoch: 1 \tLoss: 1.286352\n",
            "Test set: Average loss: 0.0045, Accuracy: 6993/10000 (70%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 1.077898\n",
            "Test set: Average loss: 0.0034, Accuracy: 7697/10000 (77%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 0.898229\n",
            "Test set: Average loss: 0.0028, Accuracy: 8038/10000 (80%)\n",
            "\n",
            "Time: 0.4482269287109375\n",
            "Training on task:  2\n",
            "Train Epoch: 1 \tLoss: 1.320631\n",
            "Test set: Average loss: 0.0043, Accuracy: 7029/10000 (70%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 1.049266\n",
            "Test set: Average loss: 0.0033, Accuracy: 7696/10000 (77%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 0.879793\n",
            "Test set: Average loss: 0.0028, Accuracy: 7987/10000 (80%)\n",
            "\n",
            "Time: 0.44504801432291663\n",
            "24000.0\n",
            "Training on task:  0\n",
            "Train Epoch: 1 \tLoss: 0.558149\n",
            "Test set: Average loss: 0.0009, Accuracy: 9355/10000 (94%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 0.520022\n",
            "Test set: Average loss: 0.0008, Accuracy: 9415/10000 (94%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 0.593791\n",
            "Test set: Average loss: 0.0007, Accuracy: 9481/10000 (95%)\n",
            "\n",
            "Time: 0.43948491414388025\n",
            "Training on task:  1\n",
            "Train Epoch: 1 \tLoss: 1.204592\n",
            "Test set: Average loss: 0.0028, Accuracy: 7961/10000 (80%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 1.090375\n",
            "Test set: Average loss: 0.0024, Accuracy: 8246/10000 (82%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 0.944633\n",
            "Test set: Average loss: 0.0021, Accuracy: 8465/10000 (85%)\n",
            "\n",
            "Time: 0.4522005716959635\n",
            "Training on task:  2\n",
            "Train Epoch: 1 \tLoss: 1.110220\n",
            "Test set: Average loss: 0.0030, Accuracy: 7813/10000 (78%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 1.076504\n",
            "Test set: Average loss: 0.0025, Accuracy: 8198/10000 (82%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 0.925765\n",
            "Test set: Average loss: 0.0022, Accuracy: 8376/10000 (84%)\n",
            "\n",
            "Time: 0.5690256754557291\n",
            "30000.0\n",
            "Training on task:  0\n",
            "Train Epoch: 1 \tLoss: 0.668650\n",
            "Test set: Average loss: 0.0007, Accuracy: 9459/10000 (95%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 0.728740\n",
            "Test set: Average loss: 0.0006, Accuracy: 9516/10000 (95%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 0.451802\n",
            "Test set: Average loss: 0.0005, Accuracy: 9561/10000 (96%)\n",
            "\n",
            "Time: 0.43789545694986975\n",
            "Training on task:  1\n",
            "Train Epoch: 1 \tLoss: 1.276884\n",
            "Test set: Average loss: 0.0021, Accuracy: 8475/10000 (85%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 1.102237\n",
            "Test set: Average loss: 0.0018, Accuracy: 8630/10000 (86%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 1.193459\n",
            "Test set: Average loss: 0.0017, Accuracy: 8720/10000 (87%)\n",
            "\n",
            "Time: 0.42438507080078125\n",
            "Training on task:  2\n",
            "Train Epoch: 1 \tLoss: 1.045723\n",
            "Test set: Average loss: 0.0024, Accuracy: 8245/10000 (82%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 1.150570\n",
            "Test set: Average loss: 0.0020, Accuracy: 8491/10000 (85%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 0.886895\n",
            "Test set: Average loss: 0.0018, Accuracy: 8665/10000 (87%)\n",
            "\n",
            "Time: 0.44345855712890625\n",
            "36000.0\n",
            "Training on task:  0\n",
            "Train Epoch: 1 \tLoss: 0.327814\n",
            "Test set: Average loss: 0.0006, Accuracy: 9533/10000 (95%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 0.411777\n",
            "Test set: Average loss: 0.0005, Accuracy: 9566/10000 (96%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 0.353177\n",
            "Test set: Average loss: 0.0005, Accuracy: 9622/10000 (96%)\n",
            "\n",
            "Time: 0.4315376281738281\n",
            "Training on task:  1\n",
            "Train Epoch: 1 \tLoss: 0.977179\n",
            "Test set: Average loss: 0.0018, Accuracy: 8636/10000 (86%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 0.868196\n",
            "Test set: Average loss: 0.0016, Accuracy: 8755/10000 (88%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 0.802667\n",
            "Test set: Average loss: 0.0015, Accuracy: 8860/10000 (89%)\n",
            "\n",
            "Time: 0.6079673767089844\n",
            "Training on task:  2\n",
            "Train Epoch: 1 \tLoss: 1.013992\n",
            "Test set: Average loss: 0.0021, Accuracy: 8457/10000 (85%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 0.913537\n",
            "Test set: Average loss: 0.0018, Accuracy: 8637/10000 (86%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 0.811136\n",
            "Test set: Average loss: 0.0017, Accuracy: 8782/10000 (88%)\n",
            "\n",
            "Time: 0.5030632019042969\n",
            "42000.0\n",
            "Training on task:  0\n",
            "Train Epoch: 1 \tLoss: 0.514747\n",
            "Test set: Average loss: 0.0006, Accuracy: 9549/10000 (95%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 0.299826\n",
            "Test set: Average loss: 0.0005, Accuracy: 9599/10000 (96%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 0.494710\n",
            "Test set: Average loss: 0.0005, Accuracy: 9626/10000 (96%)\n",
            "\n",
            "Time: 0.41882197062174475\n",
            "Training on task:  1\n",
            "Train Epoch: 1 \tLoss: 1.075366\n",
            "Test set: Average loss: 0.0017, Accuracy: 8684/10000 (87%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 0.846738\n",
            "Test set: Average loss: 0.0015, Accuracy: 8814/10000 (88%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 0.533671\n",
            "Test set: Average loss: 0.0014, Accuracy: 8917/10000 (89%)\n",
            "\n",
            "Time: 0.4903475443522135\n",
            "Training on task:  2\n",
            "Train Epoch: 1 \tLoss: 0.984107\n",
            "Test set: Average loss: 0.0018, Accuracy: 8671/10000 (87%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 0.546795\n",
            "Test set: Average loss: 0.0016, Accuracy: 8782/10000 (88%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 0.709961\n",
            "Test set: Average loss: 0.0015, Accuracy: 8868/10000 (89%)\n",
            "\n",
            "Time: 0.46650568644205725\n",
            "48000.0\n",
            "Training on task:  0\n",
            "Train Epoch: 1 \tLoss: 0.464846\n",
            "Test set: Average loss: 0.0005, Accuracy: 9604/10000 (96%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 0.404500\n",
            "Test set: Average loss: 0.0004, Accuracy: 9645/10000 (96%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 0.398877\n",
            "Test set: Average loss: 0.0004, Accuracy: 9682/10000 (97%)\n",
            "\n",
            "Time: 1.0959307352701824\n",
            "Training on task:  1\n",
            "Train Epoch: 1 \tLoss: 0.951970\n",
            "Test set: Average loss: 0.0016, Accuracy: 8828/10000 (88%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 0.775449\n",
            "Test set: Average loss: 0.0014, Accuracy: 8949/10000 (89%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 0.691837\n",
            "Test set: Average loss: 0.0013, Accuracy: 8998/10000 (90%)\n",
            "\n",
            "Time: 0.434716542561849\n",
            "Training on task:  2\n",
            "Train Epoch: 1 \tLoss: 0.830715\n",
            "Test set: Average loss: 0.0017, Accuracy: 8753/10000 (88%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 0.807955\n",
            "Test set: Average loss: 0.0015, Accuracy: 8862/10000 (89%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 0.772356\n",
            "Test set: Average loss: 0.0014, Accuracy: 8948/10000 (89%)\n",
            "\n",
            "Time: 0.47047932942708337\n",
            "54000.0\n",
            "Training on task:  0\n",
            "Train Epoch: 1 \tLoss: 0.446300\n",
            "Test set: Average loss: 0.0005, Accuracy: 9633/10000 (96%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 0.292799\n",
            "Test set: Average loss: 0.0004, Accuracy: 9678/10000 (97%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 0.336441\n",
            "Test set: Average loss: 0.0004, Accuracy: 9698/10000 (97%)\n",
            "\n",
            "Time: 0.4553794860839844\n",
            "Training on task:  1\n",
            "Train Epoch: 1 \tLoss: 0.719246\n",
            "Test set: Average loss: 0.0014, Accuracy: 8884/10000 (89%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 0.680646\n",
            "Test set: Average loss: 0.0013, Accuracy: 9006/10000 (90%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 0.614978\n",
            "Test set: Average loss: 0.0012, Accuracy: 9054/10000 (91%)\n",
            "\n",
            "Time: 0.4315376281738281\n",
            "Training on task:  2\n",
            "Train Epoch: 1 \tLoss: 0.726266\n",
            "Test set: Average loss: 0.0015, Accuracy: 8831/10000 (88%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 0.617000\n",
            "Test set: Average loss: 0.0014, Accuracy: 8931/10000 (89%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 0.652708\n",
            "Test set: Average loss: 0.0013, Accuracy: 8980/10000 (90%)\n",
            "\n",
            "Time: 0.476837158203125\n",
            "{1: {0: {1: {'train_loss': 2.2908318042755127, 'loss': 0.009046000409126282, 'acc': 37.06}, 2: {'train_loss': 2.161489963531494, 'loss': 0.008399878573417664, 'acc': 47.43}, 3: {'train_loss': 1.7339640855789185, 'loss': 0.005767020928859711, 'acc': 68.04}, 'time': 0.4116694132486979}, 1: {1: {'train_loss': 2.28761887550354, 'loss': 0.009101049137115479, 'acc': 20.46}, 2: {'train_loss': 2.1863107681274414, 'loss': 0.008784336042404174, 'acc': 28.9}, 3: {'train_loss': 2.1723716259002686, 'loss': 0.008316641283035279, 'acc': 34.37}, 'time': 0.39180119832356775}, 2: {1: {'train_loss': 2.1636762619018555, 'loss': 0.008477894949913025, 'acc': 30.74}, 2: {'train_loss': 2.003976345062256, 'loss': 0.007817102587223053, 'acc': 36.82}, 3: {'train_loss': 1.881421446800232, 'loss': 0.007033462226390838, 'acc': 44.63}, 'time': 0.404516855875651}}, 2: {0: {1: {'train_loss': 0.8873515725135803, 'loss': 0.002324506661295891, 'acc': 83.24}, 2: {'train_loss': 0.6715828776359558, 'loss': 0.001472426339238882, 'acc': 89.11}, 3: {'train_loss': 0.5611094236373901, 'loss': 0.001160445024445653, 'acc': 91.6}, 'time': 0.4744529724121094}, 1: {1: {'train_loss': 1.9436523914337158, 'loss': 0.006988550853729248, 'acc': 42.55}, 2: {'train_loss': 1.5878263711929321, 'loss': 0.005404062426090241, 'acc': 58.92}, 3: {'train_loss': 1.3440297842025757, 'loss': 0.004331234407424927, 'acc': 66.82}, 'time': 0.4442532857259115}, 2: {1: {'train_loss': 1.7123115062713623, 'loss': 0.006016760885715485, 'acc': 49.94}, 2: {'train_loss': 1.5005099773406982, 'loss': 0.004604498428106308, 'acc': 63.78}, 3: {'train_loss': 1.1700736284255981, 'loss': 0.0037992547571659087, 'acc': 70.68}, 'time': 0.4331270853678385}}, 3: {0: {1: {'train_loss': 0.5322596430778503, 'loss': 0.0011869549252092838, 'acc': 91.02}, 2: {'train_loss': 0.3811178505420685, 'loss': 0.0009749140378087759, 'acc': 92.98}, 3: {'train_loss': 0.4415058493614197, 'loss': 0.0008203613908961415, 'acc': 93.8}, 'time': 0.4291534423828125}, 1: {1: {'train_loss': 1.2863519191741943, 'loss': 0.004513990712165832, 'acc': 69.93}, 2: {'train_loss': 1.0778982639312744, 'loss': 0.0034189130783081056, 'acc': 76.97}, 3: {'train_loss': 0.8982291221618652, 'loss': 0.0027749655842781067, 'acc': 80.38}, 'time': 0.4482269287109375}, 2: {1: {'train_loss': 1.3206313848495483, 'loss': 0.004261145144701004, 'acc': 70.29}, 2: {'train_loss': 1.04926598072052, 'loss': 0.0033457904636859893, 'acc': 76.96}, 3: {'train_loss': 0.8797932863235474, 'loss': 0.0028175799876451494, 'acc': 79.87}, 'time': 0.44504801432291663}}, 4: {0: {1: {'train_loss': 0.5581488609313965, 'loss': 0.0008802024807780981, 'acc': 93.55}, 2: {'train_loss': 0.5200222730636597, 'loss': 0.0007654850475490093, 'acc': 94.15}, 3: {'train_loss': 0.5937907099723816, 'loss': 0.0006725431594997645, 'acc': 94.81}, 'time': 0.43948491414388025}, 1: {1: {'train_loss': 1.2045917510986328, 'loss': 0.0028498270124197008, 'acc': 79.61}, 2: {'train_loss': 1.0903748273849487, 'loss': 0.0023827342987060547, 'acc': 82.46}, 3: {'train_loss': 0.9446331858634949, 'loss': 0.0021161028385162355, 'acc': 84.65}, 'time': 0.4522005716959635}, 2: {1: {'train_loss': 1.1102200746536255, 'loss': 0.0030250783026218413, 'acc': 78.13}, 2: {'train_loss': 1.076504111289978, 'loss': 0.0024926520526409148, 'acc': 81.98}, 3: {'train_loss': 0.925765335559845, 'loss': 0.002180042476952076, 'acc': 83.76}, 'time': 0.5690256754557291}}, 5: {0: {1: {'train_loss': 0.6686496138572693, 'loss': 0.0007225375248119235, 'acc': 94.59}, 2: {'train_loss': 0.7287397980690002, 'loss': 0.0006304500327445567, 'acc': 95.16}, 3: {'train_loss': 0.45180225372314453, 'loss': 0.0005489348146133125, 'acc': 95.61}, 'time': 0.43789545694986975}, 1: {1: {'train_loss': 1.2768840789794922, 'loss': 0.0020950136050581934, 'acc': 84.75}, 2: {'train_loss': 1.1022371053695679, 'loss': 0.0018340281933546065, 'acc': 86.3}, 3: {'train_loss': 1.1934585571289062, 'loss': 0.0016723869733512402, 'acc': 87.2}, 'time': 0.42438507080078125}, 2: {1: {'train_loss': 1.0457234382629395, 'loss': 0.0024094455868005752, 'acc': 82.45}, 2: {'train_loss': 1.1505699157714844, 'loss': 0.002028274114429951, 'acc': 84.91}, 3: {'train_loss': 0.8868952393531799, 'loss': 0.0018068660512566565, 'acc': 86.65}, 'time': 0.44345855712890625}}, 6: {0: {1: {'train_loss': 0.3278142809867859, 'loss': 0.0006078562119044363, 'acc': 95.33}, 2: {'train_loss': 0.4117773473262787, 'loss': 0.0005337299838196486, 'acc': 95.66}, 3: {'train_loss': 0.3531770706176758, 'loss': 0.0004808208243921399, 'acc': 96.22}, 'time': 0.4315376281738281}, 1: {1: {'train_loss': 0.9771787524223328, 'loss': 0.0018453532814979553, 'acc': 86.36}, 2: {'train_loss': 0.868195652961731, 'loss': 0.0016253675617277621, 'acc': 87.55}, 3: {'train_loss': 0.8026674389839172, 'loss': 0.0015046833291649819, 'acc': 88.6}, 'time': 0.6079673767089844}, 2: {1: {'train_loss': 1.0139923095703125, 'loss': 0.0020664349123835565, 'acc': 84.57}, 2: {'train_loss': 0.9135372042655945, 'loss': 0.0017974338129162788, 'acc': 86.37}, 3: {'train_loss': 0.8111364245414734, 'loss': 0.0016766770541667938, 'acc': 87.82}, 'time': 0.5030632019042969}}, 7: {0: {1: {'train_loss': 0.5147473812103271, 'loss': 0.0005769664481282234, 'acc': 95.49}, 2: {'train_loss': 0.2998255491256714, 'loss': 0.00050104670682922, 'acc': 95.99}, 3: {'train_loss': 0.49471017718315125, 'loss': 0.0004659105593571439, 'acc': 96.26}, 'time': 0.41882197062174475}, 1: {1: {'train_loss': 1.0753659009933472, 'loss': 0.0017457907229661942, 'acc': 86.84}, 2: {'train_loss': 0.8467377424240112, 'loss': 0.0015235428363084794, 'acc': 88.14}, 3: {'train_loss': 0.5336705446243286, 'loss': 0.0013869794875383378, 'acc': 89.17}, 'time': 0.4903475443522135}, 2: {1: {'train_loss': 0.9841068387031555, 'loss': 0.0018091172218322755, 'acc': 86.71}, 2: {'train_loss': 0.5467952489852905, 'loss': 0.0016080388464033604, 'acc': 87.82}, 3: {'train_loss': 0.7099611163139343, 'loss': 0.0014926877789199352, 'acc': 88.68}, 'time': 0.46650568644205725}}, 8: {0: {1: {'train_loss': 0.4648463726043701, 'loss': 0.0005130836253520101, 'acc': 96.04}, 2: {'train_loss': 0.40450021624565125, 'loss': 0.0004496583389118314, 'acc': 96.45}, 3: {'train_loss': 0.3988770544528961, 'loss': 0.0004140155424596742, 'acc': 96.82}, 'time': 1.0959307352701824}, 1: {1: {'train_loss': 0.9519701600074768, 'loss': 0.0015748533710837364, 'acc': 88.28}, 2: {'train_loss': 0.7754494547843933, 'loss': 0.0013775675594806672, 'acc': 89.49}, 3: {'train_loss': 0.69183748960495, 'loss': 0.0013060333669185637, 'acc': 89.98}, 'time': 0.434716542561849}, 2: {1: {'train_loss': 0.8307145237922668, 'loss': 0.0016574259251356126, 'acc': 87.53}, 2: {'train_loss': 0.8079546093940735, 'loss': 0.0014882870651781559, 'acc': 88.62}, 3: {'train_loss': 0.7723559737205505, 'loss': 0.0014134158831089734, 'acc': 89.48}, 'time': 0.47047932942708337}}, 9: {0: {1: {'train_loss': 0.4462997615337372, 'loss': 0.00046187990182079377, 'acc': 96.33}, 2: {'train_loss': 0.2927987277507782, 'loss': 0.0004060784053755924, 'acc': 96.78}, 3: {'train_loss': 0.3364410102367401, 'loss': 0.0003795720061287284, 'acc': 96.98}, 'time': 0.4553794860839844}, 1: {1: {'train_loss': 0.7192458510398865, 'loss': 0.0014319428317248822, 'acc': 88.84}, 2: {'train_loss': 0.6806464791297913, 'loss': 0.00129188720472157, 'acc': 90.06}, 3: {'train_loss': 0.6149784922599792, 'loss': 0.0012247537672519684, 'acc': 90.54}, 'time': 0.4315376281738281}, 2: {1: {'train_loss': 0.7262661457061768, 'loss': 0.0015427979730069637, 'acc': 88.31}, 2: {'train_loss': 0.6169997453689575, 'loss': 0.0014100523814558983, 'acc': 89.31}, 3: {'train_loss': 0.6527081727981567, 'loss': 0.0013281353179365395, 'acc': 89.8}, 'time': 0.476837158203125}}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_NAIVE_MODEL[\"final_accs\"] = {}\n",
        "accs = []\n",
        "for id, task in enumerate(tasks):\n",
        "  _, (x_test, t_test) = task\n",
        "  _, acc = test(model, device, x_test, t_test)\n",
        "  accs.append(acc)\n",
        "  DATA_NAIVE_MODEL[\"final_accs\"][id] = acc\n",
        "\n",
        "DATA_NAIVE_MODEL[\"final_accs\"][\"avg\"] = np.average(accs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GMMOYxgBJdMd",
        "outputId": "22088a16-422d-4aff-b703-28c682e8edbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set: Average loss: 0.0049, Accuracy: 6096/10000 (61%)\n",
            "\n",
            "Test set: Average loss: 0.0049, Accuracy: 5928/10000 (59%)\n",
            "\n",
            "Test set: Average loss: 0.0013, Accuracy: 8980/10000 (90%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lCK0EYT-pJa8"
      },
      "source": [
        "## Rehearsal Strategy\n",
        "\n",
        "A simple CL idea is to retrain or *rehearse* some or all of the previously encountered examples (of the previous tasks), shuffling them with the data of the current task. Using *all* the past data is near to the optimal performance we can desire at the end of the task sequence but at the expense of much bigger memory usage.\n",
        "\n",
        "Start with a function to shuffle past data into current training set.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdWpT2jhfu3o"
      },
      "source": [
        "def shuffle_in_unison(dataset, seed, in_place=False):\n",
        "    \"\"\" Shuffle two (or more) list in unison. \"\"\"\n",
        "\n",
        "    np.random.seed(seed)\n",
        "    rng_state = np.random.get_state()\n",
        "    new_dataset = []\n",
        "    for x in dataset:\n",
        "        if in_place:\n",
        "            np.random.shuffle(x)\n",
        "        else:\n",
        "            new_dataset.append(np.random.permutation(x))\n",
        "        np.random.set_state(rng_state)\n",
        "\n",
        "    if not in_place:\n",
        "        return new_dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94hg1UrtqFmT"
      },
      "source": [
        "Reset model and optimiser."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62TY0Ajgbsgk"
      },
      "source": [
        "model = Net().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_No-qvDbuZi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20781407-7b91-4095-d541-8cbf06472f88"
      },
      "source": [
        "dataset_increments = 10 # refers to the number of different levels of data that are tested to show the difference between models\n",
        "x_size = len(x_train)\n",
        "t_size = len(t_train)\n",
        "\n",
        "DATA_REHEARSE_MODEL = {}\n",
        "for i in range (1,dataset_increments): \n",
        "      print(x_size * (1 / dataset_increments) * i)\n",
        "      DATA_REHEARSE_MODEL[i] = {}\n",
        "\n",
        "      for id, task in enumerate(tasks):\n",
        "        print(\"Training on task: \", id)\n",
        "        DATA_REHEARSE_MODEL[i][id] = {}\n",
        "        \n",
        "        (x_train, t_train), (x_test, t_test) = task\n",
        "\n",
        "        x = x_train[:int(x_size * (1 / dataset_increments) * i)]\n",
        "        t = t_train[:int(x_size * (1 / dataset_increments) * i)]\n",
        "        \n",
        "        # for previous task\n",
        "        for j in range(id):\n",
        "          (past_x_train, past_t_train), _ = tasks[j]\n",
        "          x = np.concatenate((x, past_x_train))\n",
        "          t = np.concatenate((t, past_t_train))\n",
        "        \n",
        "        x, t = shuffle_in_unison([x_train, t_train], 0)\n",
        "\n",
        "        timer.on_train_begin()\n",
        "        for epoch in range(1, 4):\n",
        "              train_loss = train(model, device, x, t, optimizer, epoch, timer)\n",
        "\n",
        "              loss, acc = test(model, device, x_test, t_test)\n",
        "\n",
        "              DATA_REHEARSE_MODEL[i][id][epoch] = {\n",
        "                  \"train_loss\" : train_loss,\n",
        "                  \"loss\" : loss,\n",
        "                  \"acc\" : acc\n",
        "              }\n",
        "\n",
        "        timeCount = np.average(timer.times) * 10000\n",
        "        DATA_REHEARSE_MODEL[i][id][\"time\"] = timeCount\n",
        "        print(\"Time: \" + str(timeCount))\n",
        "print(DATA_REHEARSE_MODEL) \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6000.0\n",
            "Training on task:  0\n",
            "Train Epoch: 1 \tLoss: 0.627441\n",
            "Test set: Average loss: 0.0012, Accuracy: 9146/10000 (91%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 0.448485\n",
            "Test set: Average loss: 0.0007, Accuracy: 9474/10000 (95%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 0.273114\n",
            "Test set: Average loss: 0.0005, Accuracy: 9577/10000 (96%)\n",
            "\n",
            "Time: 0.5245208740234375\n",
            "Training on task:  1\n",
            "Train Epoch: 1 \tLoss: 1.552298\n",
            "Test set: Average loss: 0.0050, Accuracy: 6539/10000 (65%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 1.194747\n",
            "Test set: Average loss: 0.0031, Accuracy: 7723/10000 (77%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 0.939780\n",
            "Test set: Average loss: 0.0024, Accuracy: 8289/10000 (83%)\n",
            "\n",
            "Time: 0.5396207173665365\n",
            "Training on task:  2\n",
            "Train Epoch: 1 \tLoss: 1.393832\n",
            "Test set: Average loss: 0.0044, Accuracy: 6807/10000 (68%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 0.967356\n",
            "Test set: Average loss: 0.0027, Accuracy: 8057/10000 (81%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 0.908479\n",
            "Test set: Average loss: 0.0022, Accuracy: 8421/10000 (84%)\n",
            "\n",
            "Time: 0.530083974202474\n",
            "12000.0\n",
            "Training on task:  0\n",
            "Train Epoch: 1 \tLoss: 0.433035\n",
            "Test set: Average loss: 0.0006, Accuracy: 9575/10000 (96%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 0.370924\n",
            "Test set: Average loss: 0.0005, Accuracy: 9620/10000 (96%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 0.287129\n",
            "Test set: Average loss: 0.0004, Accuracy: 9677/10000 (97%)\n",
            "\n",
            "Time: 0.46253204345703125\n",
            "Training on task:  1\n",
            "Train Epoch: 1 \tLoss: 1.326086\n",
            "Test set: Average loss: 0.0031, Accuracy: 7918/10000 (79%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 1.136528\n",
            "Test set: Average loss: 0.0022, Accuracy: 8399/10000 (84%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 0.793701\n",
            "Test set: Average loss: 0.0018, Accuracy: 8683/10000 (87%)\n",
            "\n",
            "Time: 0.518957773844401\n",
            "Training on task:  2\n",
            "Train Epoch: 1 \tLoss: 1.516739\n",
            "Test set: Average loss: 0.0027, Accuracy: 7968/10000 (80%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 1.095612\n",
            "Test set: Average loss: 0.0021, Accuracy: 8412/10000 (84%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 1.024399\n",
            "Test set: Average loss: 0.0018, Accuracy: 8659/10000 (87%)\n",
            "\n",
            "Time: 0.5284945170084635\n",
            "18000.0\n",
            "Training on task:  0\n",
            "Train Epoch: 1 \tLoss: 0.397167\n",
            "Test set: Average loss: 0.0004, Accuracy: 9649/10000 (96%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 0.258077\n",
            "Test set: Average loss: 0.0004, Accuracy: 9690/10000 (97%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 0.336712\n",
            "Test set: Average loss: 0.0004, Accuracy: 9704/10000 (97%)\n",
            "\n",
            "Time: 0.45696894327799475\n",
            "Training on task:  1\n",
            "Train Epoch: 1 \tLoss: 1.179963\n",
            "Test set: Average loss: 0.0028, Accuracy: 8002/10000 (80%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 0.863769\n",
            "Test set: Average loss: 0.0019, Accuracy: 8515/10000 (85%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 0.844833\n",
            "Test set: Average loss: 0.0017, Accuracy: 8752/10000 (88%)\n",
            "\n",
            "Time: 0.568230946858724\n",
            "Training on task:  2\n",
            "Train Epoch: 1 \tLoss: 0.911704\n",
            "Test set: Average loss: 0.0024, Accuracy: 8254/10000 (83%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 0.604816\n",
            "Test set: Average loss: 0.0017, Accuracy: 8688/10000 (87%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 0.517388\n",
            "Test set: Average loss: 0.0015, Accuracy: 8884/10000 (89%)\n",
            "\n",
            "Time: 0.5435943603515625\n",
            "24000.0\n",
            "Training on task:  0\n",
            "Train Epoch: 1 \tLoss: 0.566086\n",
            "Test set: Average loss: 0.0004, Accuracy: 9658/10000 (97%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 0.413462\n",
            "Test set: Average loss: 0.0004, Accuracy: 9712/10000 (97%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 0.255769\n",
            "Test set: Average loss: 0.0003, Accuracy: 9702/10000 (97%)\n",
            "\n",
            "Time: 0.44743220011393225\n",
            "Training on task:  1\n",
            "Train Epoch: 1 \tLoss: 1.056481\n",
            "Test set: Average loss: 0.0019, Accuracy: 8550/10000 (86%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 0.796760\n",
            "Test set: Average loss: 0.0016, Accuracy: 8758/10000 (88%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 0.645600\n",
            "Test set: Average loss: 0.0014, Accuracy: 8866/10000 (89%)\n",
            "\n",
            "Time: 0.5245208740234375\n",
            "Training on task:  2\n",
            "Train Epoch: 1 \tLoss: 0.630602\n",
            "Test set: Average loss: 0.0018, Accuracy: 8661/10000 (87%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 0.607338\n",
            "Test set: Average loss: 0.0014, Accuracy: 8939/10000 (89%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 0.593854\n",
            "Test set: Average loss: 0.0013, Accuracy: 9041/10000 (90%)\n",
            "\n",
            "Time: 0.499884287516276\n",
            "30000.0\n",
            "Training on task:  0\n",
            "Train Epoch: 1 \tLoss: 0.432902\n",
            "Test set: Average loss: 0.0004, Accuracy: 9693/10000 (97%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 0.247811\n",
            "Test set: Average loss: 0.0003, Accuracy: 9717/10000 (97%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 0.221309\n",
            "Test set: Average loss: 0.0003, Accuracy: 9746/10000 (97%)\n",
            "\n",
            "Time: 0.5316734313964844\n",
            "Training on task:  1\n",
            "Train Epoch: 1 \tLoss: 0.759532\n",
            "Test set: Average loss: 0.0016, Accuracy: 8757/10000 (88%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 0.780209\n",
            "Test set: Average loss: 0.0014, Accuracy: 8890/10000 (89%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 0.606143\n",
            "Test set: Average loss: 0.0013, Accuracy: 8999/10000 (90%)\n",
            "\n",
            "Time: 0.5261103312174479\n",
            "Training on task:  2\n",
            "Train Epoch: 1 \tLoss: 0.647506\n",
            "Test set: Average loss: 0.0014, Accuracy: 8917/10000 (89%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 0.536336\n",
            "Test set: Average loss: 0.0013, Accuracy: 9047/10000 (90%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 0.413432\n",
            "Test set: Average loss: 0.0012, Accuracy: 9110/10000 (91%)\n",
            "\n",
            "Time: 0.5229314168294271\n",
            "36000.0\n",
            "Training on task:  0\n",
            "Train Epoch: 1 \tLoss: 0.377775\n",
            "Test set: Average loss: 0.0003, Accuracy: 9700/10000 (97%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 0.266661\n",
            "Test set: Average loss: 0.0003, Accuracy: 9740/10000 (97%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 0.172779\n",
            "Test set: Average loss: 0.0003, Accuracy: 9748/10000 (97%)\n",
            "\n",
            "Time: 0.5578994750976562\n",
            "Training on task:  1\n",
            "Train Epoch: 1 \tLoss: 0.815678\n",
            "Test set: Average loss: 0.0014, Accuracy: 8901/10000 (89%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 0.582917\n",
            "Test set: Average loss: 0.0013, Accuracy: 8981/10000 (90%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 0.638036\n",
            "Test set: Average loss: 0.0012, Accuracy: 9038/10000 (90%)\n",
            "\n",
            "Time: 0.5284945170084635\n",
            "Training on task:  2\n",
            "Train Epoch: 1 \tLoss: 0.515284\n",
            "Test set: Average loss: 0.0013, Accuracy: 9001/10000 (90%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 0.557529\n",
            "Test set: Average loss: 0.0012, Accuracy: 9098/10000 (91%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 0.489954\n",
            "Test set: Average loss: 0.0012, Accuracy: 9123/10000 (91%)\n",
            "\n",
            "Time: 0.5062421162923177\n",
            "42000.0\n",
            "Training on task:  0\n",
            "Train Epoch: 1 \tLoss: 0.279808\n",
            "Test set: Average loss: 0.0003, Accuracy: 9717/10000 (97%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 0.135816\n",
            "Test set: Average loss: 0.0003, Accuracy: 9750/10000 (98%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 0.377560\n",
            "Test set: Average loss: 0.0003, Accuracy: 9766/10000 (98%)\n",
            "\n",
            "Time: 0.46253204345703125\n",
            "Training on task:  1\n",
            "Train Epoch: 1 \tLoss: 0.619097\n",
            "Test set: Average loss: 0.0014, Accuracy: 8958/10000 (90%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 0.648599\n",
            "Test set: Average loss: 0.0013, Accuracy: 9047/10000 (90%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 0.523454\n",
            "Test set: Average loss: 0.0012, Accuracy: 9086/10000 (91%)\n",
            "\n",
            "Time: 0.5221366882324219\n",
            "Training on task:  2\n",
            "Train Epoch: 1 \tLoss: 0.547309\n",
            "Test set: Average loss: 0.0013, Accuracy: 9037/10000 (90%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 0.426923\n",
            "Test set: Average loss: 0.0012, Accuracy: 9105/10000 (91%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 0.587431\n",
            "Test set: Average loss: 0.0011, Accuracy: 9137/10000 (91%)\n",
            "\n",
            "Time: 0.4975001017252604\n",
            "48000.0\n",
            "Training on task:  0\n",
            "Train Epoch: 1 \tLoss: 0.154712\n",
            "Test set: Average loss: 0.0003, Accuracy: 9736/10000 (97%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 0.237412\n",
            "Test set: Average loss: 0.0003, Accuracy: 9753/10000 (98%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 0.244598\n",
            "Test set: Average loss: 0.0003, Accuracy: 9777/10000 (98%)\n",
            "\n",
            "Time: 0.4943211873372396\n",
            "Training on task:  1\n",
            "Train Epoch: 1 \tLoss: 0.723528\n",
            "Test set: Average loss: 0.0013, Accuracy: 8997/10000 (90%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 0.704756\n",
            "Test set: Average loss: 0.0012, Accuracy: 9084/10000 (91%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 0.479499\n",
            "Test set: Average loss: 0.0012, Accuracy: 9114/10000 (91%)\n",
            "\n",
            "Time: 0.5849202473958334\n",
            "Training on task:  2\n",
            "Train Epoch: 1 \tLoss: 0.460218\n",
            "Test set: Average loss: 0.0012, Accuracy: 9066/10000 (91%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 0.512631\n",
            "Test set: Average loss: 0.0011, Accuracy: 9128/10000 (91%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 0.432518\n",
            "Test set: Average loss: 0.0011, Accuracy: 9180/10000 (92%)\n",
            "\n",
            "Time: 0.5102157592773438\n",
            "54000.0\n",
            "Training on task:  0\n",
            "Train Epoch: 1 \tLoss: 0.322703\n",
            "Test set: Average loss: 0.0003, Accuracy: 9727/10000 (97%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 0.171521\n",
            "Test set: Average loss: 0.0003, Accuracy: 9748/10000 (97%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 0.257067\n",
            "Test set: Average loss: 0.0003, Accuracy: 9771/10000 (98%)\n",
            "\n",
            "Time: 0.4267692565917969\n",
            "Training on task:  1\n",
            "Train Epoch: 1 \tLoss: 0.597674\n",
            "Test set: Average loss: 0.0013, Accuracy: 9040/10000 (90%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 0.571042\n",
            "Test set: Average loss: 0.0012, Accuracy: 9074/10000 (91%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 0.593002\n",
            "Test set: Average loss: 0.0011, Accuracy: 9144/10000 (91%)\n",
            "\n",
            "Time: 0.4903475443522135\n",
            "Training on task:  2\n",
            "Train Epoch: 1 \tLoss: 0.619937\n",
            "Test set: Average loss: 0.0012, Accuracy: 9060/10000 (91%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 0.658556\n",
            "Test set: Average loss: 0.0011, Accuracy: 9127/10000 (91%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 0.465086\n",
            "Test set: Average loss: 0.0011, Accuracy: 9159/10000 (92%)\n",
            "\n",
            "Time: 0.499884287516276\n",
            "{1: {0: {1: {'train_loss': 0.6274406313896179, 'loss': 0.0012102363243699074, 'acc': 91.46}, 2: {'train_loss': 0.4484853744506836, 'loss': 0.0007014840699732304, 'acc': 94.74}, 3: {'train_loss': 0.27311357855796814, 'loss': 0.0005460611859336496, 'acc': 95.77}, 'time': 0.5245208740234375}, 1: {1: {'train_loss': 1.552297592163086, 'loss': 0.00504028542637825, 'acc': 65.39}, 2: {'train_loss': 1.1947468519210815, 'loss': 0.0030701698392629623, 'acc': 77.23}, 3: {'train_loss': 0.9397795796394348, 'loss': 0.002367609940469265, 'acc': 82.89}, 'time': 0.5396207173665365}, 2: {1: {'train_loss': 1.3938320875167847, 'loss': 0.004397496491670609, 'acc': 68.07}, 2: {'train_loss': 0.9673555493354797, 'loss': 0.0027419843822717666, 'acc': 80.57}, 3: {'train_loss': 0.9084789752960205, 'loss': 0.0021527368158102034, 'acc': 84.21}, 'time': 0.530083974202474}}, 2: {0: {1: {'train_loss': 0.4330347776412964, 'loss': 0.0005602493547834456, 'acc': 95.75}, 2: {'train_loss': 0.3709243834018707, 'loss': 0.00047381546972319485, 'acc': 96.2}, 3: {'train_loss': 0.287128746509552, 'loss': 0.0003986152092926204, 'acc': 96.77}, 'time': 0.46253204345703125}, 1: {1: {'train_loss': 1.3260859251022339, 'loss': 0.0031282301396131514, 'acc': 79.18}, 2: {'train_loss': 1.1365277767181396, 'loss': 0.002206906943023205, 'acc': 83.99}, 3: {'train_loss': 0.793700635433197, 'loss': 0.0018260817393660545, 'acc': 86.83}, 'time': 0.518957773844401}, 2: {1: {'train_loss': 1.516738772392273, 'loss': 0.002739869102835655, 'acc': 79.68}, 2: {'train_loss': 1.0956120491027832, 'loss': 0.002134856140613556, 'acc': 84.12}, 3: {'train_loss': 1.0243993997573853, 'loss': 0.001828535359352827, 'acc': 86.59}, 'time': 0.5284945170084635}}, 3: {0: {1: {'train_loss': 0.39716705679893494, 'loss': 0.00044174771010875704, 'acc': 96.49}, 2: {'train_loss': 0.25807711482048035, 'loss': 0.0003774999067070894, 'acc': 96.9}, 3: {'train_loss': 0.3367120921611786, 'loss': 0.00035685009526787326, 'acc': 97.04}, 'time': 0.45696894327799475}, 1: {1: {'train_loss': 1.1799629926681519, 'loss': 0.0027775450080633163, 'acc': 80.02}, 2: {'train_loss': 0.8637688159942627, 'loss': 0.0019468849703669548, 'acc': 85.15}, 3: {'train_loss': 0.8448331952095032, 'loss': 0.0016586091324687004, 'acc': 87.52}, 'time': 0.568230946858724}, 2: {1: {'train_loss': 0.9117042422294617, 'loss': 0.0023554052233695985, 'acc': 82.54}, 2: {'train_loss': 0.604815661907196, 'loss': 0.0017259112417697907, 'acc': 86.88}, 3: {'train_loss': 0.5173882842063904, 'loss': 0.0014806027159094811, 'acc': 88.84}, 'time': 0.5435943603515625}}, 4: {0: {1: {'train_loss': 0.5660855174064636, 'loss': 0.0004154923941940069, 'acc': 96.58}, 2: {'train_loss': 0.4134615659713745, 'loss': 0.0003532135526882485, 'acc': 97.12}, 3: {'train_loss': 0.25576940178871155, 'loss': 0.0003367643014760688, 'acc': 97.02}, 'time': 0.44743220011393225}, 1: {1: {'train_loss': 1.0564805269241333, 'loss': 0.001891276989877224, 'acc': 85.5}, 2: {'train_loss': 0.796760082244873, 'loss': 0.001645739421993494, 'acc': 87.58}, 3: {'train_loss': 0.6455996632575989, 'loss': 0.0014331032499670983, 'acc': 88.66}, 'time': 0.5245208740234375}, 2: {1: {'train_loss': 0.6306024789810181, 'loss': 0.0017647795528173446, 'acc': 86.61}, 2: {'train_loss': 0.6073376536369324, 'loss': 0.001400463417544961, 'acc': 89.39}, 3: {'train_loss': 0.5938542485237122, 'loss': 0.0012922973558306694, 'acc': 90.41}, 'time': 0.499884287516276}}, 5: {0: {1: {'train_loss': 0.4329022169113159, 'loss': 0.0003632208386436105, 'acc': 96.93}, 2: {'train_loss': 0.2478109449148178, 'loss': 0.00033848361051641405, 'acc': 97.17}, 3: {'train_loss': 0.22130919992923737, 'loss': 0.000306708508124575, 'acc': 97.46}, 'time': 0.5316734313964844}, 1: {1: {'train_loss': 0.7595319747924805, 'loss': 0.0016399554215371609, 'acc': 87.57}, 2: {'train_loss': 0.7802092432975769, 'loss': 0.0014499709717929363, 'acc': 88.9}, 3: {'train_loss': 0.6061431765556335, 'loss': 0.001318134470283985, 'acc': 89.99}, 'time': 0.5261103312174479}, 2: {1: {'train_loss': 0.6475062966346741, 'loss': 0.00141071822270751, 'acc': 89.17}, 2: {'train_loss': 0.5363360047340393, 'loss': 0.0012859812609851361, 'acc': 90.47}, 3: {'train_loss': 0.4134317934513092, 'loss': 0.0012213544480502605, 'acc': 91.1}, 'time': 0.5229314168294271}}, 6: {0: {1: {'train_loss': 0.3777752220630646, 'loss': 0.0003485024711349979, 'acc': 97.0}, 2: {'train_loss': 0.26666131615638733, 'loss': 0.0003197130842891056, 'acc': 97.4}, 3: {'train_loss': 0.17277874052524567, 'loss': 0.0002946849603846203, 'acc': 97.48}, 'time': 0.5578994750976562}, 1: {1: {'train_loss': 0.8156778216362, 'loss': 0.0014447338350117207, 'acc': 89.01}, 2: {'train_loss': 0.582916796207428, 'loss': 0.0013144473198801279, 'acc': 89.81}, 3: {'train_loss': 0.6380355954170227, 'loss': 0.0012487020872533321, 'acc': 90.38}, 'time': 0.5284945170084635}, 2: {1: {'train_loss': 0.5152837634086609, 'loss': 0.0013198644164949655, 'acc': 90.01}, 2: {'train_loss': 0.557528555393219, 'loss': 0.001206883493810892, 'acc': 90.98}, 3: {'train_loss': 0.4899539053440094, 'loss': 0.0011528459563851356, 'acc': 91.23}, 'time': 0.5062421162923177}}, 7: {0: {1: {'train_loss': 0.27980828285217285, 'loss': 0.0003416088744532317, 'acc': 97.17}, 2: {'train_loss': 0.13581593334674835, 'loss': 0.00030490574500290676, 'acc': 97.5}, 3: {'train_loss': 0.37755969166755676, 'loss': 0.0002860017248545773, 'acc': 97.66}, 'time': 0.46253204345703125}, 1: {1: {'train_loss': 0.6190974116325378, 'loss': 0.0013805974394083024, 'acc': 89.58}, 2: {'train_loss': 0.6485990881919861, 'loss': 0.0012810211841017007, 'acc': 90.47}, 3: {'train_loss': 0.5234541296958923, 'loss': 0.001198200237751007, 'acc': 90.86}, 'time': 0.5221366882324219}, 2: {1: {'train_loss': 0.5473093390464783, 'loss': 0.001261918317899108, 'acc': 90.37}, 2: {'train_loss': 0.4269225597381592, 'loss': 0.0011580305282026528, 'acc': 91.05}, 3: {'train_loss': 0.5874308943748474, 'loss': 0.0011015700243413448, 'acc': 91.37}, 'time': 0.4975001017252604}}, 8: {0: {1: {'train_loss': 0.1547122448682785, 'loss': 0.0003293900315533392, 'acc': 97.36}, 2: {'train_loss': 0.2374117374420166, 'loss': 0.00029767423743323886, 'acc': 97.53}, 3: {'train_loss': 0.24459820985794067, 'loss': 0.0002775375808880199, 'acc': 97.77}, 'time': 0.4943211873372396}, 1: {1: {'train_loss': 0.7235282063484192, 'loss': 0.001342344219237566, 'acc': 89.97}, 2: {'train_loss': 0.7047563195228577, 'loss': 0.0012254657313227654, 'acc': 90.84}, 3: {'train_loss': 0.47949859499931335, 'loss': 0.0011577315244823694, 'acc': 91.14}, 'time': 0.5849202473958334}, 2: {1: {'train_loss': 0.4602183401584625, 'loss': 0.0012397814501076937, 'acc': 90.66}, 2: {'train_loss': 0.5126312971115112, 'loss': 0.0011414085011929274, 'acc': 91.28}, 3: {'train_loss': 0.4325176179409027, 'loss': 0.001090253070741892, 'acc': 91.8}, 'time': 0.5102157592773438}}, 9: {0: {1: {'train_loss': 0.32270267605781555, 'loss': 0.0003311287362361327, 'acc': 97.27}, 2: {'train_loss': 0.17152054607868195, 'loss': 0.0002983983423851896, 'acc': 97.48}, 3: {'train_loss': 0.25706747174263, 'loss': 0.0002745642997440882, 'acc': 97.71}, 'time': 0.4267692565917969}, 1: {1: {'train_loss': 0.5976736545562744, 'loss': 0.0012660264562815427, 'acc': 90.4}, 2: {'train_loss': 0.5710424780845642, 'loss': 0.0011656930211931466, 'acc': 90.74}, 3: {'train_loss': 0.593002200126648, 'loss': 0.0011120430070906877, 'acc': 91.44}, 'time': 0.4903475443522135}, 2: {1: {'train_loss': 0.6199366450309753, 'loss': 0.0012082397514954209, 'acc': 90.6}, 2: {'train_loss': 0.6585562229156494, 'loss': 0.0011127826103940607, 'acc': 91.27}, 3: {'train_loss': 0.465085506439209, 'loss': 0.0010959560358896852, 'acc': 91.59}, 'time': 0.499884287516276}}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_REHEARSE_MODEL[\"final_accs\"] = {}\n",
        "accs = []\n",
        "for id, task in enumerate(tasks):\n",
        "  _, (x_test, t_test) = task\n",
        "  _, acc = test(model, device, x_test, t_test)\n",
        "  accs.append(acc)\n",
        "  DATA_REHEARSE_MODEL[\"final_accs\"][id] = acc\n",
        "\n",
        "DATA_REHEARSE_MODEL[\"final_accs\"][\"avg\"] = np.average(accs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsr0JylEL1Cw",
        "outputId": "b0f9b002-fac5-4094-a257-34d322b00ab7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set: Average loss: 0.0043, Accuracy: 6514/10000 (65%)\n",
            "\n",
            "Test set: Average loss: 0.0041, Accuracy: 6653/10000 (67%)\n",
            "\n",
            "Test set: Average loss: 0.0011, Accuracy: 9159/10000 (92%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CL Strategies - Weight modification\n",
        "\n",
        "A more advanced method of mitigating CF is to modify how the weights in the model are trained, changing weight training methods during training can dramatically impact how weights are used and optimise each weight individually.   \n",
        "\n",
        "Weight modification strategies benefit from a normalised dataset, as loss values can become extremely large and unmanagable without this normalisation."
      ],
      "metadata": {
        "id": "fvbdH2H9NGkY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = (x_train - x_train.min())/(x_train.max() - x_train.min())\n",
        "t_train = (t_train - t_train.min())/(t_train.max() - t_train.min())"
      ],
      "metadata": {
        "id": "Y0yHruNYI1ih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Elastic Weight consolidation\n",
        "\n",
        "Initially proposed in [\"Overcoming catastrophic forgetting in neural networks\"](https://doi.org/10.1073/pnas.1611835114) Elastic Weight Consolidation helps to remember the training for older tasks by finding which weights are important for that task and slowing the training of those weights, little change in these weights means that the accuracy of the task they contribute to will be similar on revisit."
      ],
      "metadata": {
        "id": "plKgy8Yak-F_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fisher_dict = {}\n",
        "optpar_dict = {}\n",
        "ewc_lambda = 0.4"
      ],
      "metadata": {
        "id": "Kx3Iii7IpLxj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Net().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
      ],
      "metadata": {
        "id": "c3CW19hzpQdF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define a method to measure and log the gradients and fisher matrices, these are useful for the training proess as they define how much to train each weight for a given task"
      ],
      "metadata": {
        "id": "SP7qVOU-UNog"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def on_task_update(task_id, x_mem, t_mem):\n",
        "\n",
        "  model.train()\n",
        "  optimizer.zero_grad()\n",
        "  \n",
        "  # accumulating gradients\n",
        "  for start in range(0, len(t_mem)-1, 256):\n",
        "      end = start + 256\n",
        "      x, y = torch.from_numpy(x_mem[start:end]), torch.from_numpy(t_mem[start:end]).long()\n",
        "      x, y = x.to(device), y.to(device)\n",
        "      output = model(x)\n",
        "      loss = F.cross_entropy(output, y)\n",
        "      loss.backward()\n",
        "\n",
        "  fisher_dict[task_id] = {}\n",
        "  optpar_dict[task_id] = {}\n",
        "\n",
        "  # gradients accumulated can be used to calculate fisher\n",
        "  for name, param in model.named_parameters():\n",
        "    \n",
        "    optpar_dict[task_id][name] = param.data.clone()\n",
        "    fisher_dict[task_id][name] = param.grad.data.clone().pow(2)"
      ],
      "metadata": {
        "id": "wH5l_FITnhya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "EWC requires a special training function that includes the weight modification strategy."
      ],
      "metadata": {
        "id": "bPB9p6JsPwwQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def trainEWC(model, device, task_id, x_train, t_train, optimizer, epoch, timer):\n",
        "    timer.on_epoch_begin(1)\n",
        "    model.train()\n",
        "    timer.on_epoch_end(1)\n",
        "    \n",
        "    for start in range(0, len(t_train)-1, 256):\n",
        "      end = start + 256\n",
        "      x, y = torch.from_numpy(x_train[start:end]), torch.from_numpy(t_train[start:end]).long()\n",
        "      x, y = x.to(device), y.to(device)\n",
        "      \n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      output = model(x)\n",
        "      loss = F.cross_entropy(output, y)\n",
        "\n",
        "      for task in range(task_id):\n",
        "        for name, param in model.named_parameters():\n",
        "          fisher = fisher_dict[task][name]\n",
        "          optpar = optpar_dict[task][name]\n",
        "          loss += (fisher * (optpar - param).pow(2) * 0.0001).sum() * ewc_lambda\n",
        "\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      #print(loss.item())\n",
        "    print('Train Epoch: {} \\tLoss: {:.6f}'.format(epoch, loss.item()))\n",
        "    return loss.item()\n",
        "\n",
        "def testEWC(model, device, x_test, t_test):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    for start in range(0, len(t_test)-1, 256):\n",
        "      end = start + 256\n",
        "      with torch.no_grad():\n",
        "        x, y = torch.from_numpy(x_test[start:end]), torch.from_numpy(t_test[start:end]).long()\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        output = model(x)\n",
        "        test_loss += F.cross_entropy(output, y).item() # sum up batch loss\n",
        "        pred = output.max(1, keepdim=True)[1] # get the index of the max logit\n",
        "        correct += pred.eq(y.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(t_test)\n",
        "    print('Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(t_test),\n",
        "        100. * correct / len(t_test)))\n",
        "    return test_loss, 100. * correct / len(t_test)"
      ],
      "metadata": {
        "id": "-qBW8WAoKAC9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This section begins to train and gather data on the EWC strategy, trying different sizes of dataset, timing and logging the loss and accuracy of each training session."
      ],
      "metadata": {
        "id": "l9daXSjrP2HD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_increments = 10 # refers to the number of different levels of data that are tested to show the difference between models\n",
        "x_size = len(x_train)\n",
        "t_size = len(t_train)\n",
        "\n",
        "DATA_EWC_MODEL = {}\n",
        "for i in range (1,dataset_increments): \n",
        "      print(x_size * (1 / dataset_increments) * i)\n",
        "      DATA_EWC_MODEL[i] = {}\n",
        "\n",
        "      for id, task in enumerate(tasks):\n",
        "          print(\"Training on task: \", id)\n",
        "          DATA_EWC_MODEL[i][id] = {}\n",
        "\n",
        "          (x_train, t_train), (x_test, t_test) = task\n",
        "\n",
        "          x = x_train[:int(x_size * (1 / dataset_increments) * i)]\n",
        "          t = t_train[:int(x_size * (1 / dataset_increments) * i)]\n",
        "\n",
        "          timer.on_train_begin()\n",
        "          for epoch in range(1, 4):\n",
        "              train_loss = trainEWC(model, device, id, x, t, optimizer, epoch, timer)\n",
        "              on_task_update(id, x, t)\n",
        "\n",
        "              loss, acc = testEWC(model, device, x_test, t_test)\n",
        "\n",
        "              DATA_EWC_MODEL[i][id][epoch] = {\n",
        "                  \"train_loss\" : train_loss,\n",
        "                  \"loss\" : loss,\n",
        "                  \"acc\" : acc\n",
        "              }\n",
        "\n",
        "          timeCount = np.average(timer.times) * 10000\n",
        "          DATA_EWC_MODEL[i][id][\"time\"] = timeCount\n",
        "          print(\"Time: \" + str(timeCount))\n",
        "print(DATA_EWC_MODEL)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqnoCnGNWIPt",
        "outputId": "c52e9f12-2b14-4bbd-fcf0-6b152e4fcdf0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6000.0\n",
            "Training on task:  0\n",
            "Train Epoch: 1 \tLoss: 2.301944\n",
            "Test set: Average loss: 0.0092, Accuracy: 2181/10000 (22%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 2.263390\n",
            "Test set: Average loss: 0.0090, Accuracy: 2893/10000 (29%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 2.108776\n",
            "Test set: Average loss: 0.0082, Accuracy: 5101/10000 (51%)\n",
            "\n",
            "Time: 0.4307428995768229\n",
            "Training on task:  1\n",
            "Train Epoch: 1 \tLoss: 2.315231\n",
            "Test set: Average loss: 0.0092, Accuracy: 1260/10000 (13%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 2.284775\n",
            "Test set: Average loss: 0.0091, Accuracy: 2749/10000 (27%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 2.241757\n",
            "Test set: Average loss: 0.0089, Accuracy: 2763/10000 (28%)\n",
            "\n",
            "Time: 0.3552436828613281\n",
            "Training on task:  2\n",
            "Train Epoch: 1 \tLoss: 2.243030\n",
            "Test set: Average loss: 0.0089, Accuracy: 2283/10000 (23%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 2.182085\n",
            "Test set: Average loss: 0.0087, Accuracy: 2783/10000 (28%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 2.163635\n",
            "Test set: Average loss: 0.0084, Accuracy: 3298/10000 (33%)\n",
            "\n",
            "Time: 0.42994817097981775\n",
            "12000.0\n",
            "Training on task:  0\n",
            "Train Epoch: 1 \tLoss: 1.134387\n",
            "Test set: Average loss: 0.0032, Accuracy: 8015/10000 (80%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 0.721701\n",
            "Test set: Average loss: 0.0019, Accuracy: 8697/10000 (87%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 0.606918\n",
            "Test set: Average loss: 0.0014, Accuracy: 8996/10000 (90%)\n",
            "\n",
            "Time: 0.3790855407714844\n",
            "Training on task:  1\n",
            "Train Epoch: 1 \tLoss: 2.082062\n",
            "Test set: Average loss: 0.0078, Accuracy: 3626/10000 (36%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 1.842908\n",
            "Test set: Average loss: 0.0063, Accuracy: 4838/10000 (48%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 1.554885\n",
            "Test set: Average loss: 0.0051, Accuracy: 6170/10000 (62%)\n",
            "\n",
            "Time: 0.4903475443522135\n",
            "Training on task:  2\n",
            "Train Epoch: 1 \tLoss: 1.857989\n",
            "Test set: Average loss: 0.0065, Accuracy: 4614/10000 (46%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 1.592713\n",
            "Test set: Average loss: 0.0052, Accuracy: 6050/10000 (60%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 1.272886\n",
            "Test set: Average loss: 0.0042, Accuracy: 6783/10000 (68%)\n",
            "\n",
            "Time: 0.3838539123535156\n",
            "18000.0\n",
            "Training on task:  0\n",
            "Train Epoch: 1 \tLoss: 0.525962\n",
            "Test set: Average loss: 0.0013, Accuracy: 9092/10000 (91%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 0.424162\n",
            "Test set: Average loss: 0.0010, Accuracy: 9322/10000 (93%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 0.267063\n",
            "Test set: Average loss: 0.0008, Accuracy: 9399/10000 (94%)\n",
            "\n",
            "Time: 0.42835871378580725\n",
            "Training on task:  1\n",
            "Train Epoch: 1 \tLoss: 1.622598\n",
            "Test set: Average loss: 0.0058, Accuracy: 5964/10000 (60%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 1.295251\n",
            "Test set: Average loss: 0.0042, Accuracy: 7007/10000 (70%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 1.155900\n",
            "Test set: Average loss: 0.0034, Accuracy: 7544/10000 (75%)\n",
            "\n",
            "Time: 0.43392181396484375\n",
            "Training on task:  2\n",
            "Train Epoch: 1 \tLoss: 1.407100\n",
            "Test set: Average loss: 0.0048, Accuracy: 6453/10000 (65%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 0.955383\n",
            "Test set: Average loss: 0.0034, Accuracy: 7480/10000 (75%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 0.900409\n",
            "Test set: Average loss: 0.0029, Accuracy: 7967/10000 (80%)\n",
            "\n",
            "Time: 0.41961669921875\n",
            "24000.0\n",
            "Training on task:  0\n",
            "Train Epoch: 1 \tLoss: 0.551306\n",
            "Test set: Average loss: 0.0009, Accuracy: 9357/10000 (94%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 0.450520\n",
            "Test set: Average loss: 0.0007, Accuracy: 9463/10000 (95%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 0.378560\n",
            "Test set: Average loss: 0.0006, Accuracy: 9504/10000 (95%)\n",
            "\n",
            "Time: 0.42597452799479163\n",
            "Training on task:  1\n",
            "Train Epoch: 1 \tLoss: 1.380188\n",
            "Test set: Average loss: 0.0033, Accuracy: 7659/10000 (77%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 1.090880\n",
            "Test set: Average loss: 0.0026, Accuracy: 8150/10000 (82%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 0.997340\n",
            "Test set: Average loss: 0.0022, Accuracy: 8409/10000 (84%)\n",
            "\n",
            "Time: 0.4498163859049479\n",
            "Training on task:  2\n",
            "Train Epoch: 1 \tLoss: 1.058813\n",
            "Test set: Average loss: 0.0026, Accuracy: 8028/10000 (80%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 0.918832\n",
            "Test set: Average loss: 0.0021, Accuracy: 8407/10000 (84%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 0.813900\n",
            "Test set: Average loss: 0.0019, Accuracy: 8607/10000 (86%)\n",
            "\n",
            "Time: 0.4172325134277344\n",
            "30000.0\n",
            "Training on task:  0\n",
            "Train Epoch: 1 \tLoss: 0.669118\n",
            "Test set: Average loss: 0.0007, Accuracy: 9518/10000 (95%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 0.649101\n",
            "Test set: Average loss: 0.0005, Accuracy: 9581/10000 (96%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 0.479339\n",
            "Test set: Average loss: 0.0005, Accuracy: 9620/10000 (96%)\n",
            "\n",
            "Time: 0.42279561360677087\n",
            "Training on task:  1\n",
            "Train Epoch: 1 \tLoss: 1.248126\n",
            "Test set: Average loss: 0.0022, Accuracy: 8417/10000 (84%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 1.019073\n",
            "Test set: Average loss: 0.0018, Accuracy: 8688/10000 (87%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 0.948676\n",
            "Test set: Average loss: 0.0016, Accuracy: 8812/10000 (88%)\n",
            "\n",
            "Time: 0.4363059997558594\n",
            "Training on task:  2\n",
            "Train Epoch: 1 \tLoss: 1.147631\n",
            "Test set: Average loss: 0.0020, Accuracy: 8567/10000 (86%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 1.090045\n",
            "Test set: Average loss: 0.0017, Accuracy: 8784/10000 (88%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 0.990329\n",
            "Test set: Average loss: 0.0015, Accuracy: 8899/10000 (89%)\n",
            "\n",
            "Time: 0.43551127115885413\n",
            "36000.0\n",
            "Training on task:  0\n",
            "Train Epoch: 1 \tLoss: 0.420103\n",
            "Test set: Average loss: 0.0006, Accuracy: 9571/10000 (96%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 0.360071\n",
            "Test set: Average loss: 0.0005, Accuracy: 9625/10000 (96%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 0.247164\n",
            "Test set: Average loss: 0.0004, Accuracy: 9652/10000 (97%)\n",
            "\n",
            "Time: 0.4172325134277344\n",
            "Training on task:  1\n",
            "Train Epoch: 1 \tLoss: 1.023177\n",
            "Test set: Average loss: 0.0017, Accuracy: 8706/10000 (87%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 0.849820\n",
            "Test set: Average loss: 0.0016, Accuracy: 8861/10000 (89%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 0.881133\n",
            "Test set: Average loss: 0.0014, Accuracy: 8934/10000 (89%)\n",
            "\n",
            "Time: 0.4688898722330729\n",
            "Training on task:  2\n",
            "Train Epoch: 1 \tLoss: 0.820047\n",
            "Test set: Average loss: 0.0017, Accuracy: 8753/10000 (88%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 0.783626\n",
            "Test set: Average loss: 0.0015, Accuracy: 8932/10000 (89%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 0.849989\n",
            "Test set: Average loss: 0.0014, Accuracy: 8963/10000 (90%)\n",
            "\n",
            "Time: 0.4784266153971354\n",
            "42000.0\n",
            "Training on task:  0\n",
            "Train Epoch: 1 \tLoss: 0.329709\n",
            "Test set: Average loss: 0.0005, Accuracy: 9620/10000 (96%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 0.195431\n",
            "Test set: Average loss: 0.0004, Accuracy: 9670/10000 (97%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 0.346689\n",
            "Test set: Average loss: 0.0004, Accuracy: 9696/10000 (97%)\n",
            "\n",
            "Time: 0.42994817097981775\n",
            "Training on task:  1\n",
            "Train Epoch: 1 \tLoss: 0.781115\n",
            "Test set: Average loss: 0.0016, Accuracy: 8838/10000 (88%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 0.543699\n",
            "Test set: Average loss: 0.0014, Accuracy: 8969/10000 (90%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 0.795321\n",
            "Test set: Average loss: 0.0013, Accuracy: 9045/10000 (90%)\n",
            "\n",
            "Time: 0.41325887044270837\n",
            "Training on task:  2\n",
            "Train Epoch: 1 \tLoss: 0.953248\n",
            "Test set: Average loss: 0.0014, Accuracy: 8918/10000 (89%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 1.262121\n",
            "Test set: Average loss: 0.0013, Accuracy: 9053/10000 (91%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 0.466339\n",
            "Test set: Average loss: 0.0012, Accuracy: 9119/10000 (91%)\n",
            "\n",
            "Time: 0.43233235677083337\n",
            "48000.0\n",
            "Training on task:  0\n",
            "Train Epoch: 1 \tLoss: 0.450433\n",
            "Test set: Average loss: 0.0004, Accuracy: 9670/10000 (97%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 0.343694\n",
            "Test set: Average loss: 0.0004, Accuracy: 9711/10000 (97%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 0.298937\n",
            "Test set: Average loss: 0.0004, Accuracy: 9733/10000 (97%)\n",
            "\n",
            "Time: 0.4212061564127604\n",
            "Training on task:  1\n",
            "Train Epoch: 1 \tLoss: 0.658898\n",
            "Test set: Average loss: 0.0014, Accuracy: 8922/10000 (89%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 0.584862\n",
            "Test set: Average loss: 0.0013, Accuracy: 9017/10000 (90%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 0.613125\n",
            "Test set: Average loss: 0.0012, Accuracy: 9075/10000 (91%)\n",
            "\n",
            "Time: 0.4291534423828125\n",
            "Training on task:  2\n",
            "Train Epoch: 1 \tLoss: 0.851503\n",
            "Test set: Average loss: 0.0014, Accuracy: 8970/10000 (90%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 0.599713\n",
            "Test set: Average loss: 0.0012, Accuracy: 9100/10000 (91%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 0.509786\n",
            "Test set: Average loss: 0.0011, Accuracy: 9128/10000 (91%)\n",
            "\n",
            "Time: 0.42438507080078125\n",
            "54000.0\n",
            "Training on task:  0\n",
            "Train Epoch: 1 \tLoss: 0.356035\n",
            "Test set: Average loss: 0.0004, Accuracy: 9706/10000 (97%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 0.387420\n",
            "Test set: Average loss: 0.0003, Accuracy: 9736/10000 (97%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 0.321314\n",
            "Test set: Average loss: 0.0003, Accuracy: 9742/10000 (97%)\n",
            "\n",
            "Time: 0.4084904988606771\n",
            "Training on task:  1\n",
            "Train Epoch: 1 \tLoss: 0.695982\n",
            "Test set: Average loss: 0.0013, Accuracy: 8972/10000 (90%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 0.582071\n",
            "Test set: Average loss: 0.0012, Accuracy: 9056/10000 (91%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 0.576508\n",
            "Test set: Average loss: 0.0011, Accuracy: 9108/10000 (91%)\n",
            "\n",
            "Time: 0.4561742146809896\n",
            "Training on task:  2\n",
            "Train Epoch: 1 \tLoss: 0.694073\n",
            "Test set: Average loss: 0.0012, Accuracy: 9033/10000 (90%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 0.590910\n",
            "Test set: Average loss: 0.0011, Accuracy: 9116/10000 (91%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 0.679525\n",
            "Test set: Average loss: 0.0011, Accuracy: 9173/10000 (92%)\n",
            "\n",
            "Time: 0.4220008850097656\n",
            "{1: {0: {1: {'train_loss': 2.3019444942474365, 'loss': 0.009153960084915161, 'acc': 21.81}, 2: {'train_loss': 2.263390064239502, 'loss': 0.008974904012680054, 'acc': 28.93}, 3: {'train_loss': 2.1087758541107178, 'loss': 0.008170814967155457, 'acc': 51.01}, 'time': 0.4307428995768229}, 1: {1: {'train_loss': 2.3152313232421875, 'loss': 0.009175422644615173, 'acc': 12.6}, 2: {'train_loss': 2.2847750186920166, 'loss': 0.009079998874664307, 'acc': 27.49}, 3: {'train_loss': 2.2417569160461426, 'loss': 0.008944898319244384, 'acc': 27.63}, 'time': 0.3552436828613281}, 2: {1: {'train_loss': 2.243030309677124, 'loss': 0.008903159475326538, 'acc': 22.83}, 2: {'train_loss': 2.1820850372314453, 'loss': 0.008662461233139037, 'acc': 27.83}, 3: {'train_loss': 2.163635015487671, 'loss': 0.008391227340698242, 'acc': 32.98}, 'time': 0.42994817097981775}}, 2: {0: {1: {'train_loss': 1.1343872547149658, 'loss': 0.0031547297328710557, 'acc': 80.15}, 2: {'train_loss': 0.7217012643814087, 'loss': 0.001862979130446911, 'acc': 86.97}, 3: {'train_loss': 0.606917679309845, 'loss': 0.0014495251938700677, 'acc': 89.96}, 'time': 0.3790855407714844}, 1: {1: {'train_loss': 2.082061529159546, 'loss': 0.007775472939014435, 'acc': 36.26}, 2: {'train_loss': 1.8429077863693237, 'loss': 0.0062793725490570065, 'acc': 48.38}, 3: {'train_loss': 1.5548853874206543, 'loss': 0.005128163594007492, 'acc': 61.7}, 'time': 0.4903475443522135}, 2: {1: {'train_loss': 1.8579894304275513, 'loss': 0.006540326762199402, 'acc': 46.14}, 2: {'train_loss': 1.5927132368087769, 'loss': 0.005218375873565674, 'acc': 60.5}, 3: {'train_loss': 1.2728859186172485, 'loss': 0.004230648910999298, 'acc': 67.83}, 'time': 0.3838539123535156}}, 3: {0: {1: {'train_loss': 0.5259624719619751, 'loss': 0.001310065098851919, 'acc': 90.92}, 2: {'train_loss': 0.4241620898246765, 'loss': 0.0009775260526686906, 'acc': 93.22}, 3: {'train_loss': 0.26706311106681824, 'loss': 0.0008173444006592035, 'acc': 93.99}, 'time': 0.42835871378580725}, 1: {1: {'train_loss': 1.6225982904434204, 'loss': 0.0057544766902923586, 'acc': 59.64}, 2: {'train_loss': 1.295251488685608, 'loss': 0.00420419015288353, 'acc': 70.07}, 3: {'train_loss': 1.155900001525879, 'loss': 0.0033988414704799654, 'acc': 75.44}, 'time': 0.43392181396484375}, 2: {1: {'train_loss': 1.407099723815918, 'loss': 0.0047797093152999875, 'acc': 64.53}, 2: {'train_loss': 0.9553828835487366, 'loss': 0.003435159331560135, 'acc': 74.8}, 3: {'train_loss': 0.9004089832305908, 'loss': 0.002883328527212143, 'acc': 79.67}, 'time': 0.41961669921875}}, 4: {0: {1: {'train_loss': 0.5513060092926025, 'loss': 0.0009176120780408383, 'acc': 93.57}, 2: {'train_loss': 0.45052027702331543, 'loss': 0.0007330915594473481, 'acc': 94.63}, 3: {'train_loss': 0.37856027483940125, 'loss': 0.0006463408529758454, 'acc': 95.04}, 'time': 0.42597452799479163}, 1: {1: {'train_loss': 1.3801878690719604, 'loss': 0.003279374659061432, 'acc': 76.59}, 2: {'train_loss': 1.0908796787261963, 'loss': 0.0025552284836769103, 'acc': 81.5}, 3: {'train_loss': 0.9973396062850952, 'loss': 0.002167459212243557, 'acc': 84.09}, 'time': 0.4498163859049479}, 2: {1: {'train_loss': 1.058813214302063, 'loss': 0.002610666635632515, 'acc': 80.28}, 2: {'train_loss': 0.9188316464424133, 'loss': 0.0021442686885595323, 'acc': 84.07}, 3: {'train_loss': 0.8139001131057739, 'loss': 0.001939412146806717, 'acc': 86.07}, 'time': 0.4172325134277344}}, 5: {0: {1: {'train_loss': 0.6691182255744934, 'loss': 0.0006502960790880024, 'acc': 95.18}, 2: {'train_loss': 0.6491013169288635, 'loss': 0.0005490875827148557, 'acc': 95.81}, 3: {'train_loss': 0.47933903336524963, 'loss': 0.0004999241857789457, 'acc': 96.2}, 'time': 0.42279561360677087}, 1: {1: {'train_loss': 1.2481260299682617, 'loss': 0.0021773475736379623, 'acc': 84.17}, 2: {'train_loss': 1.0190733671188354, 'loss': 0.0018183711126446723, 'acc': 86.88}, 3: {'train_loss': 0.9486762881278992, 'loss': 0.0016296020478010177, 'acc': 88.12}, 'time': 0.4363059997558594}, 2: {1: {'train_loss': 1.147631287574768, 'loss': 0.001953464764356613, 'acc': 85.67}, 2: {'train_loss': 1.0900447368621826, 'loss': 0.001666036094725132, 'acc': 87.84}, 3: {'train_loss': 0.9903292655944824, 'loss': 0.0014973020166158676, 'acc': 88.99}, 'time': 0.43551127115885413}}, 6: {0: {1: {'train_loss': 0.42010298371315, 'loss': 0.0005698721673339605, 'acc': 95.71}, 2: {'train_loss': 0.3600710332393646, 'loss': 0.0004892759680282325, 'acc': 96.25}, 3: {'train_loss': 0.24716362357139587, 'loss': 0.0004440851854626089, 'acc': 96.52}, 'time': 0.4172325134277344}, 1: {1: {'train_loss': 1.023177146911621, 'loss': 0.001749087891727686, 'acc': 87.06}, 2: {'train_loss': 0.8498203754425049, 'loss': 0.001558219362050295, 'acc': 88.61}, 3: {'train_loss': 0.8811331391334534, 'loss': 0.0014288979113101959, 'acc': 89.34}, 'time': 0.4688898722330729}, 2: {1: {'train_loss': 0.8200473189353943, 'loss': 0.0017136690221726894, 'acc': 87.53}, 2: {'train_loss': 0.78362637758255, 'loss': 0.0014709669448435307, 'acc': 89.32}, 3: {'train_loss': 0.8499892354011536, 'loss': 0.0013611122220754624, 'acc': 89.63}, 'time': 0.4784266153971354}}, 7: {0: {1: {'train_loss': 0.32970890402793884, 'loss': 0.00048121282644569873, 'acc': 96.2}, 2: {'train_loss': 0.195431187748909, 'loss': 0.0004272887727012858, 'acc': 96.7}, 3: {'train_loss': 0.3466893434524536, 'loss': 0.00038057550599332896, 'acc': 96.96}, 'time': 0.42994817097981775}, 1: {1: {'train_loss': 0.7811146974563599, 'loss': 0.0015599076703190803, 'acc': 88.38}, 2: {'train_loss': 0.5436989068984985, 'loss': 0.0013637574926018716, 'acc': 89.69}, 3: {'train_loss': 0.7953214049339294, 'loss': 0.0012651720475405455, 'acc': 90.45}, 'time': 0.41325887044270837}, 2: {1: {'train_loss': 0.9532480835914612, 'loss': 0.0014367005765438079, 'acc': 89.18}, 2: {'train_loss': 1.2621209621429443, 'loss': 0.0012565618269145488, 'acc': 90.53}, 3: {'train_loss': 0.4663394093513489, 'loss': 0.0011733840841799974, 'acc': 91.19}, 'time': 0.43233235677083337}}, 8: {0: {1: {'train_loss': 0.45043331384658813, 'loss': 0.00043057667692191897, 'acc': 96.7}, 2: {'train_loss': 0.34369397163391113, 'loss': 0.0003719350669765845, 'acc': 97.11}, 3: {'train_loss': 0.2989371418952942, 'loss': 0.0003537105667637661, 'acc': 97.33}, 'time': 0.4212061564127604}, 1: {1: {'train_loss': 0.658897876739502, 'loss': 0.0014295659806579351, 'acc': 89.22}, 2: {'train_loss': 0.584862232208252, 'loss': 0.0012786278240382672, 'acc': 90.17}, 3: {'train_loss': 0.6131247878074646, 'loss': 0.0011954524435102939, 'acc': 90.75}, 'time': 0.4291534423828125}, 2: {1: {'train_loss': 0.851503312587738, 'loss': 0.0013690111860632896, 'acc': 89.7}, 2: {'train_loss': 0.5997130870819092, 'loss': 0.0011896320939064025, 'acc': 91.0}, 3: {'train_loss': 0.5097864270210266, 'loss': 0.001127686496451497, 'acc': 91.28}, 'time': 0.42438507080078125}}, 9: {0: {1: {'train_loss': 0.35603535175323486, 'loss': 0.00038019699533469977, 'acc': 97.06}, 2: {'train_loss': 0.38741981983184814, 'loss': 0.0003464800464687869, 'acc': 97.36}, 3: {'train_loss': 0.32131436467170715, 'loss': 0.00032040087229106575, 'acc': 97.42}, 'time': 0.4084904988606771}, 1: {1: {'train_loss': 0.6959816217422485, 'loss': 0.0013233786046504975, 'acc': 89.72}, 2: {'train_loss': 0.5820710062980652, 'loss': 0.0012010686334222554, 'acc': 90.56}, 3: {'train_loss': 0.5765084624290466, 'loss': 0.0011297800667583943, 'acc': 91.08}, 'time': 0.4561742146809896}, 2: {1: {'train_loss': 0.6940727829933167, 'loss': 0.0012457259967923165, 'acc': 90.33}, 2: {'train_loss': 0.5909097194671631, 'loss': 0.0011268669433891773, 'acc': 91.16}, 3: {'train_loss': 0.6795246005058289, 'loss': 0.001075294377282262, 'acc': 91.73}, 'time': 0.4220008850097656}}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_EWC_MODEL[\"final_accs\"] = {}\n",
        "accs = []\n",
        "for id, task in enumerate(tasks):\n",
        "  _, (x_test, t_test) = task\n",
        "  _, acc = testEWC(model, device, x_test, t_test)\n",
        "  accs.append(acc)\n",
        "  DATA_EWC_MODEL[\"final_accs\"][id] = acc\n",
        "\n",
        "DATA_EWC_MODEL[\"final_accs\"][\"avg\"] = np.average(accs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iaweitM_Dyh5",
        "outputId": "9f43acce-5ddc-4f07-e1f8-8c1b103cd283"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set: Average loss: 0.0018, Accuracy: 8578/10000 (86%)\n",
            "\n",
            "Test set: Average loss: 0.0033, Accuracy: 7350/10000 (74%)\n",
            "\n",
            "Test set: Average loss: 0.0011, Accuracy: 9173/10000 (92%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Synaptic Intelligence (SI)\n",
        "\n",
        "Proposed in [\"Continual Learning Through Synaptic Intelligence\"](http://proceedings.mlr.press/v70/zenke17a/zenke17a.pdf) as a variant of EWC.   \n",
        "SI was introduced as an improvement on EWC because EWC uses fisher matrices for calculating the importance of a weight, which is not used by SI, potentially increasing its efficiency."
      ],
      "metadata": {
        "id": "YbpJU840C5FB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optpar_dict = {}\n",
        "ewc_lambda = 0.4\n",
        "XI = 0.001 # a small constant to avoid divide by zero"
      ],
      "metadata": {
        "id": "ZNZPAZkxDGEY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Net().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
      ],
      "metadata": {
        "id": "9R2l_G61DJZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def on_task_update(task_id, x_mem, t_mem):\n",
        "\n",
        "  model.train()\n",
        "  optimizer.zero_grad()\n",
        "  \n",
        "  # accumulating gradients\n",
        "  for start in range(0, len(t_mem)-1, 256):\n",
        "      end = start + 256\n",
        "      x, y = torch.from_numpy(x_mem[start:end]), torch.from_numpy(t_mem[start:end]).long()\n",
        "      x, y = x.to(device), y.to(device)\n",
        "      output = model(x)\n",
        "      loss = F.cross_entropy(output, y)\n",
        "      loss.backward()\n",
        "\n",
        "  optpar_dict[task_id] = {}\n",
        "\n",
        "  # gradients accumulated can be used to calculate fisher\n",
        "  for name, param in model.named_parameters():\n",
        "    \n",
        "    optpar_dict[task_id][name] = param.data.clone()"
      ],
      "metadata": {
        "id": "vEaJDWHJDNRA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def trainSI(model, device, task_id, x_train, t_train, optimizer, epoch, timer):\n",
        "    timer.on_epoch_begin(1)\n",
        "    model.train()\n",
        "    timer.on_epoch_end(1)\n",
        "    \n",
        "    for start in range(0, len(t_train)-1, 256):\n",
        "      end = start + 256\n",
        "      x, y = torch.from_numpy(x_train[start:end]), torch.from_numpy(t_train[start:end]).long()\n",
        "      x, y = x.to(device), y.to(device)\n",
        "      \n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      output = model(x)\n",
        "      loss = F.cross_entropy(output, y)\n",
        "      DELTA_L = 0 # change in L\n",
        "      batches = 10\n",
        "\n",
        "      for task in range(task_id):\n",
        "        for name, param in model.named_parameters():\n",
        "          optpar = optpar_dict[task][name]\n",
        "          TOTAL_DELTA_L = 0\n",
        "          DELTA_THETA_K = optpar - param\n",
        "          for batch in range(0,batches):\n",
        "            if batch == 0:\n",
        "              DELTA_L = ewc_lambda * (ewc_lambda * (optpar - param).pow(2)).sum()\n",
        "            else:\n",
        "              TK = DELTA_L # tk is the previous change in L\n",
        "              DELTA_L = ewc_lambda * ( ( (TOTAL_DELTA_L).sum()  / ((TK).pow(2) + XI) ) * (DELTA_THETA_K).pow(2) * 0.0001).sum()   \n",
        "              # this is the line that makes SI special, its similar to EWC\n",
        "            TOTAL_DELTA_L += DELTA_L\n",
        "          loss += TOTAL_DELTA_L\n",
        "\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      #print(loss.item())\n",
        "    print('Train Epoch: {} \\tLoss: {:.6f}'.format(epoch, loss.item()))\n",
        "    return loss.item()\n",
        "\n",
        "def testSI(model, device, x_test, t_test):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    for start in range(0, len(t_test)-1, 256):\n",
        "      end = start + 256\n",
        "      with torch.no_grad():\n",
        "        x, y = torch.from_numpy(x_test[start:end]), torch.from_numpy(t_test[start:end]).long()\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        output = model(x)\n",
        "        test_loss += F.cross_entropy(output, y).item() # sum up batch loss\n",
        "        pred = output.max(1, keepdim=True)[1] # get the index of the max logit\n",
        "        correct += pred.eq(y.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(t_test)\n",
        "    print('Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(t_test),\n",
        "        100. * correct / len(t_test)))\n",
        "    return test_loss, 100. * correct / len(t_test)"
      ],
      "metadata": {
        "id": "7f4fBaL0DRs3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_increments = 10 # refers to the number of different levels of data that are tested to show the difference between models\n",
        "x_size = len(x_train)\n",
        "t_size = len(t_train)\n",
        "\n",
        "DATA_SI_MODEL = {}\n",
        "for i in range (1,dataset_increments): \n",
        "      print(x_size * (1 / dataset_increments) * i)\n",
        "      DATA_SI_MODEL[i] = {}\n",
        "\n",
        "      for id, task in enumerate(tasks):\n",
        "          print(\"Training on task: \", id)\n",
        "          DATA_SI_MODEL[i][id] = {}\n",
        "\n",
        "          (x_train, t_train), (x_test, t_test) = task\n",
        "\n",
        "          x = x_train[:int(x_size * (1 / dataset_increments) * i)]\n",
        "          t = t_train[:int(x_size * (1 / dataset_increments) * i)]\n",
        "\n",
        "\n",
        "          timer.on_train_begin()\n",
        "          for epoch in range(1, 4):\n",
        "              train_loss = trainSI(model, device, id, x, t, optimizer, epoch, timer)\n",
        "              on_task_update(id, x, t)\n",
        "\n",
        "              loss, acc = testSI(model, device, x_test, t_test)\n",
        "\n",
        "              DATA_SI_MODEL[i][id][epoch] = {\n",
        "                  \"train_loss\" : train_loss,\n",
        "                  \"loss\" : loss,\n",
        "                  \"acc\" : acc\n",
        "              }\n",
        "\n",
        "          timeCount = np.average(timer.times) * 10000\n",
        "          DATA_SI_MODEL[i][id][\"time\"] = timeCount\n",
        "          print(\"Time: \" + str(timeCount))\n",
        "print(DATA_SI_MODEL)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ca407c7-d13d-4c38-e92c-58d311dfd579",
        "id": "HXKXtbBLDXyT"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6000.0\n",
            "Training on task:  0\n",
            "Train Epoch: 1 \tLoss: 2.288982\n",
            "Test set: Average loss: 0.0092, Accuracy: 1845/10000 (18%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 2.260105\n",
            "Test set: Average loss: 0.0090, Accuracy: 4247/10000 (42%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 2.197322\n",
            "Test set: Average loss: 0.0085, Accuracy: 4303/10000 (43%)\n",
            "\n",
            "Time: 0.7073084513346355\n",
            "Training on task:  1\n",
            "Train Epoch: 1 \tLoss: 2.306656\n",
            "Test set: Average loss: 0.0092, Accuracy: 1474/10000 (15%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 2.309240\n",
            "Test set: Average loss: 0.0091, Accuracy: 1942/10000 (19%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 2.281035\n",
            "Test set: Average loss: 0.0091, Accuracy: 2262/10000 (23%)\n",
            "\n",
            "Time: 0.4251797993977865\n",
            "Training on task:  2\n",
            "Train Epoch: 1 \tLoss: 2.300925\n",
            "Test set: Average loss: 0.0091, Accuracy: 2017/10000 (20%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 2.287255\n",
            "Test set: Average loss: 0.0091, Accuracy: 1982/10000 (20%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 2.297637\n",
            "Test set: Average loss: 0.0091, Accuracy: 1819/10000 (18%)\n",
            "\n",
            "Time: 0.4291534423828125\n",
            "12000.0\n",
            "Training on task:  0\n",
            "Train Epoch: 1 \tLoss: 1.475639\n",
            "Test set: Average loss: 0.0037, Accuracy: 7697/10000 (77%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 0.855537\n",
            "Test set: Average loss: 0.0019, Accuracy: 8634/10000 (86%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 0.698200\n",
            "Test set: Average loss: 0.0014, Accuracy: 9017/10000 (90%)\n",
            "\n",
            "Time: 0.4331270853678385\n",
            "Training on task:  1\n",
            "Train Epoch: 1 \tLoss: 2.334032\n",
            "Test set: Average loss: 0.0087, Accuracy: 2176/10000 (22%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 2.329940\n",
            "Test set: Average loss: 0.0081, Accuracy: 3755/10000 (38%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 2.277538\n",
            "Test set: Average loss: 0.0079, Accuracy: 3911/10000 (39%)\n",
            "\n",
            "Time: 0.40372212727864587\n",
            "Training on task:  2\n",
            "Train Epoch: 1 \tLoss: 2.305786\n",
            "Test set: Average loss: 0.0083, Accuracy: 3046/10000 (30%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 2.305543\n",
            "Test set: Average loss: 0.0083, Accuracy: 3148/10000 (31%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 2.302202\n",
            "Test set: Average loss: 0.0082, Accuracy: 3196/10000 (32%)\n",
            "\n",
            "Time: 0.4251797993977865\n",
            "18000.0\n",
            "Training on task:  0\n",
            "Train Epoch: 1 \tLoss: 0.423127\n",
            "Test set: Average loss: 0.0011, Accuracy: 9192/10000 (92%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 0.372270\n",
            "Test set: Average loss: 0.0009, Accuracy: 9319/10000 (93%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 0.414463\n",
            "Test set: Average loss: 0.0007, Accuracy: 9409/10000 (94%)\n",
            "\n",
            "Time: 0.38782755533854163\n",
            "Training on task:  1\n",
            "Train Epoch: 1 \tLoss: 2.165849\n",
            "Test set: Average loss: 0.0077, Accuracy: 4003/10000 (40%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 2.101592\n",
            "Test set: Average loss: 0.0074, Accuracy: 4307/10000 (43%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 2.116347\n",
            "Test set: Average loss: 0.0074, Accuracy: 4377/10000 (44%)\n",
            "\n",
            "Time: 0.4482269287109375\n",
            "Training on task:  2\n",
            "Train Epoch: 1 \tLoss: 2.292831\n",
            "Test set: Average loss: 0.0077, Accuracy: 4002/10000 (40%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 2.201981\n",
            "Test set: Average loss: 0.0076, Accuracy: 3964/10000 (40%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 2.245519\n",
            "Test set: Average loss: 0.0076, Accuracy: 4139/10000 (41%)\n",
            "\n",
            "Time: 0.38782755533854163\n",
            "24000.0\n",
            "Training on task:  0\n",
            "Train Epoch: 1 \tLoss: 0.505213\n",
            "Test set: Average loss: 0.0007, Accuracy: 9451/10000 (95%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 0.435160\n",
            "Test set: Average loss: 0.0006, Accuracy: 9524/10000 (95%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 0.373106\n",
            "Test set: Average loss: 0.0005, Accuracy: 9565/10000 (96%)\n",
            "\n",
            "Time: 0.41882197062174475\n",
            "Training on task:  1\n",
            "Train Epoch: 1 \tLoss: 2.034592\n",
            "Test set: Average loss: 0.0066, Accuracy: 5252/10000 (53%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 2.004701\n",
            "Test set: Average loss: 0.0065, Accuracy: 5462/10000 (55%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 1.999661\n",
            "Test set: Average loss: 0.0064, Accuracy: 5437/10000 (54%)\n",
            "\n",
            "Time: 0.442663828531901\n",
            "Training on task:  2\n",
            "Train Epoch: 1 \tLoss: 2.193655\n",
            "Test set: Average loss: 0.0071, Accuracy: 4285/10000 (43%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 2.200183\n",
            "Test set: Average loss: 0.0070, Accuracy: 4424/10000 (44%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 2.191398\n",
            "Test set: Average loss: 0.0069, Accuracy: 4627/10000 (46%)\n",
            "\n",
            "Time: 0.4522005716959635\n",
            "30000.0\n",
            "Training on task:  0\n",
            "Train Epoch: 1 \tLoss: 0.557805\n",
            "Test set: Average loss: 0.0005, Accuracy: 9608/10000 (96%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 0.439363\n",
            "Test set: Average loss: 0.0004, Accuracy: 9652/10000 (97%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 0.352277\n",
            "Test set: Average loss: 0.0004, Accuracy: 9673/10000 (97%)\n",
            "\n",
            "Time: 0.415643056233724\n",
            "Training on task:  1\n",
            "Train Epoch: 1 \tLoss: 2.199011\n",
            "Test set: Average loss: 0.0064, Accuracy: 5621/10000 (56%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 2.223786\n",
            "Test set: Average loss: 0.0063, Accuracy: 5824/10000 (58%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 2.066646\n",
            "Test set: Average loss: 0.0062, Accuracy: 5775/10000 (58%)\n",
            "\n",
            "Time: 0.453790028889974\n",
            "Training on task:  2\n",
            "Train Epoch: 1 \tLoss: 2.131224\n",
            "Test set: Average loss: 0.0067, Accuracy: 5114/10000 (51%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 2.163514\n",
            "Test set: Average loss: 0.0066, Accuracy: 5248/10000 (52%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 2.211489\n",
            "Test set: Average loss: 0.0068, Accuracy: 5146/10000 (51%)\n",
            "\n",
            "Time: 0.4275639851888021\n",
            "36000.0\n",
            "Training on task:  0\n",
            "Train Epoch: 1 \tLoss: 0.352612\n",
            "Test set: Average loss: 0.0004, Accuracy: 9696/10000 (97%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 0.339946\n",
            "Test set: Average loss: 0.0004, Accuracy: 9709/10000 (97%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 0.265575\n",
            "Test set: Average loss: 0.0003, Accuracy: 9722/10000 (97%)\n",
            "\n",
            "Time: 0.4180272420247396\n",
            "Training on task:  1\n",
            "Train Epoch: 1 \tLoss: 2.119836\n",
            "Test set: Average loss: 0.0060, Accuracy: 5771/10000 (58%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 2.156899\n",
            "Test set: Average loss: 0.0060, Accuracy: 5695/10000 (57%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 2.071585\n",
            "Test set: Average loss: 0.0060, Accuracy: 5788/10000 (58%)\n",
            "\n",
            "Time: 0.4124641418457031\n",
            "Training on task:  2\n",
            "Train Epoch: 1 \tLoss: 2.132645\n",
            "Test set: Average loss: 0.0063, Accuracy: 5403/10000 (54%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 2.198874\n",
            "Test set: Average loss: 0.0062, Accuracy: 5515/10000 (55%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 2.171981\n",
            "Test set: Average loss: 0.0063, Accuracy: 5312/10000 (53%)\n",
            "\n",
            "Time: 0.41961669921875\n",
            "42000.0\n",
            "Training on task:  0\n",
            "Train Epoch: 1 \tLoss: 0.149897\n",
            "Test set: Average loss: 0.0004, Accuracy: 9715/10000 (97%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 0.215563\n",
            "Test set: Average loss: 0.0003, Accuracy: 9738/10000 (97%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 0.186079\n",
            "Test set: Average loss: 0.0003, Accuracy: 9746/10000 (97%)\n",
            "\n",
            "Time: 0.4076957702636719\n",
            "Training on task:  1\n",
            "Train Epoch: 1 \tLoss: 1.557138\n",
            "Test set: Average loss: 0.0056, Accuracy: 6070/10000 (61%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 1.743867\n",
            "Test set: Average loss: 0.0057, Accuracy: 6101/10000 (61%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 1.825573\n",
            "Test set: Average loss: 0.0056, Accuracy: 6139/10000 (61%)\n",
            "\n",
            "Time: 0.4752477010091146\n",
            "Training on task:  2\n",
            "Train Epoch: 1 \tLoss: 2.080620\n",
            "Test set: Average loss: 0.0061, Accuracy: 5525/10000 (55%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 2.198055\n",
            "Test set: Average loss: 0.0061, Accuracy: 5462/10000 (55%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 1.911287\n",
            "Test set: Average loss: 0.0060, Accuracy: 5572/10000 (56%)\n",
            "\n",
            "Time: 0.4267692565917969\n",
            "48000.0\n",
            "Training on task:  0\n",
            "Train Epoch: 1 \tLoss: 0.308133\n",
            "Test set: Average loss: 0.0003, Accuracy: 9768/10000 (98%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 0.392920\n",
            "Test set: Average loss: 0.0003, Accuracy: 9778/10000 (98%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 0.427071\n",
            "Test set: Average loss: 0.0003, Accuracy: 9784/10000 (98%)\n",
            "\n",
            "Time: 0.44902165730794275\n",
            "Training on task:  1\n",
            "Train Epoch: 1 \tLoss: 1.842074\n",
            "Test set: Average loss: 0.0052, Accuracy: 6524/10000 (65%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 1.859018\n",
            "Test set: Average loss: 0.0053, Accuracy: 6522/10000 (65%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 1.946608\n",
            "Test set: Average loss: 0.0052, Accuracy: 6465/10000 (65%)\n",
            "\n",
            "Time: 0.4482269287109375\n",
            "Training on task:  2\n",
            "Train Epoch: 1 \tLoss: 1.935551\n",
            "Test set: Average loss: 0.0056, Accuracy: 6033/10000 (60%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 1.951498\n",
            "Test set: Average loss: 0.0056, Accuracy: 5970/10000 (60%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 1.987133\n",
            "Test set: Average loss: 0.0057, Accuracy: 5966/10000 (60%)\n",
            "\n",
            "Time: 0.400543212890625\n",
            "54000.0\n",
            "Training on task:  0\n",
            "Train Epoch: 1 \tLoss: 0.275634\n",
            "Test set: Average loss: 0.0003, Accuracy: 9780/10000 (98%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 0.183327\n",
            "Test set: Average loss: 0.0003, Accuracy: 9792/10000 (98%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 0.228259\n",
            "Test set: Average loss: 0.0002, Accuracy: 9787/10000 (98%)\n",
            "\n",
            "Time: 0.48001607259114587\n",
            "Training on task:  1\n",
            "Train Epoch: 1 \tLoss: 1.675761\n",
            "Test set: Average loss: 0.0048, Accuracy: 6752/10000 (68%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 1.815996\n",
            "Test set: Average loss: 0.0048, Accuracy: 6824/10000 (68%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 1.772885\n",
            "Test set: Average loss: 0.0048, Accuracy: 6767/10000 (68%)\n",
            "\n",
            "Time: 0.46094258626302087\n",
            "Training on task:  2\n",
            "Train Epoch: 1 \tLoss: 1.931210\n",
            "Test set: Average loss: 0.0054, Accuracy: 6312/10000 (63%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 2.020565\n",
            "Test set: Average loss: 0.0055, Accuracy: 6278/10000 (63%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 1.945478\n",
            "Test set: Average loss: 0.0054, Accuracy: 6258/10000 (63%)\n",
            "\n",
            "Time: 0.4371007283528646\n",
            "{1: {0: {1: {'train_loss': 2.288982391357422, 'loss': 0.009163366436958312, 'acc': 18.45}, 2: {'train_loss': 2.2601053714752197, 'loss': 0.009036232089996338, 'acc': 42.47}, 3: {'train_loss': 2.197322130203247, 'loss': 0.008484111452102662, 'acc': 43.03}, 'time': 0.7073084513346355}, 1: {1: {'train_loss': 2.3066556453704834, 'loss': 0.0091843852519989, 'acc': 14.74}, 2: {'train_loss': 2.3092403411865234, 'loss': 0.009142498230934142, 'acc': 19.42}, 3: {'train_loss': 2.2810349464416504, 'loss': 0.009129105806350709, 'acc': 22.62}, 'time': 0.4251797993977865}, 2: {1: {'train_loss': 2.3009254932403564, 'loss': 0.009119842839241029, 'acc': 20.17}, 2: {'train_loss': 2.287254571914673, 'loss': 0.009107551765441894, 'acc': 19.82}, 3: {'train_loss': 2.2976372241973877, 'loss': 0.009105771374702453, 'acc': 18.19}, 'time': 0.4291534423828125}}, 2: {0: {1: {'train_loss': 1.47563898563385, 'loss': 0.0037031627237796784, 'acc': 76.97}, 2: {'train_loss': 0.8555365800857544, 'loss': 0.0018965802222490312, 'acc': 86.34}, 3: {'train_loss': 0.6982001066207886, 'loss': 0.0014448268331587314, 'acc': 90.17}, 'time': 0.4331270853678385}, 1: {1: {'train_loss': 2.334031820297241, 'loss': 0.008704758143424987, 'acc': 21.76}, 2: {'train_loss': 2.329939603805542, 'loss': 0.008058484005928039, 'acc': 37.55}, 3: {'train_loss': 2.277538299560547, 'loss': 0.007857767033576966, 'acc': 39.11}, 'time': 0.40372212727864587}, 2: {1: {'train_loss': 2.305785894393921, 'loss': 0.00831253571510315, 'acc': 30.46}, 2: {'train_loss': 2.3055429458618164, 'loss': 0.00825920022726059, 'acc': 31.48}, 3: {'train_loss': 2.302201509475708, 'loss': 0.008229767298698426, 'acc': 31.96}, 'time': 0.4251797993977865}}, 3: {0: {1: {'train_loss': 0.42312702536582947, 'loss': 0.0011159356072545051, 'acc': 91.92}, 2: {'train_loss': 0.3722698986530304, 'loss': 0.0009235059574246407, 'acc': 93.19}, 3: {'train_loss': 0.4144625663757324, 'loss': 0.0007476439727470279, 'acc': 94.09}, 'time': 0.38782755533854163}, 1: {1: {'train_loss': 2.165849447250366, 'loss': 0.00768477463722229, 'acc': 40.03}, 2: {'train_loss': 2.1015923023223877, 'loss': 0.007394906973838806, 'acc': 43.07}, 3: {'train_loss': 2.116346597671509, 'loss': 0.007359751307964325, 'acc': 43.77}, 'time': 0.4482269287109375}, 2: {1: {'train_loss': 2.2928309440612793, 'loss': 0.0077181107401847835, 'acc': 40.02}, 2: {'train_loss': 2.2019805908203125, 'loss': 0.0075760366678237915, 'acc': 39.64}, 3: {'train_loss': 2.245518922805786, 'loss': 0.007579428255558014, 'acc': 41.39}, 'time': 0.38782755533854163}}, 4: {0: {1: {'train_loss': 0.5052129626274109, 'loss': 0.0007121291277930141, 'acc': 94.51}, 2: {'train_loss': 0.435159832239151, 'loss': 0.0005911776191554963, 'acc': 95.24}, 3: {'train_loss': 0.37310561537742615, 'loss': 0.0005453216046560556, 'acc': 95.65}, 'time': 0.41882197062174475}, 1: {1: {'train_loss': 2.0345919132232666, 'loss': 0.006587878382205963, 'acc': 52.52}, 2: {'train_loss': 2.0047011375427246, 'loss': 0.006516342377662659, 'acc': 54.62}, 3: {'train_loss': 1.9996607303619385, 'loss': 0.0064267778754234315, 'acc': 54.37}, 'time': 0.442663828531901}, 2: {1: {'train_loss': 2.193655490875244, 'loss': 0.007059564304351807, 'acc': 42.85}, 2: {'train_loss': 2.2001829147338867, 'loss': 0.007046002948284149, 'acc': 44.24}, 3: {'train_loss': 2.1913976669311523, 'loss': 0.006917003345489502, 'acc': 46.27}, 'time': 0.4522005716959635}}, 5: {0: {1: {'train_loss': 0.5578049421310425, 'loss': 0.0005022795783355832, 'acc': 96.08}, 2: {'train_loss': 0.4393634796142578, 'loss': 0.00044981735397595915, 'acc': 96.52}, 3: {'train_loss': 0.35227689146995544, 'loss': 0.00042703125509433446, 'acc': 96.73}, 'time': 0.415643056233724}, 1: {1: {'train_loss': 2.1990108489990234, 'loss': 0.006415299713611603, 'acc': 56.21}, 2: {'train_loss': 2.2237863540649414, 'loss': 0.006278079569339752, 'acc': 58.24}, 3: {'train_loss': 2.066645860671997, 'loss': 0.0062121346950531, 'acc': 57.75}, 'time': 0.453790028889974}, 2: {1: {'train_loss': 2.1312243938446045, 'loss': 0.006700616943836212, 'acc': 51.14}, 2: {'train_loss': 2.163513660430908, 'loss': 0.006635157907009125, 'acc': 52.48}, 3: {'train_loss': 2.21148943901062, 'loss': 0.006768620562553406, 'acc': 51.46}, 'time': 0.4275639851888021}}, 6: {0: {1: {'train_loss': 0.35261183977127075, 'loss': 0.0003922044415259734, 'acc': 96.96}, 2: {'train_loss': 0.33994561433792114, 'loss': 0.0003641065443400294, 'acc': 97.09}, 3: {'train_loss': 0.2655746638774872, 'loss': 0.00034572489687707277, 'acc': 97.22}, 'time': 0.4180272420247396}, 1: {1: {'train_loss': 2.1198360919952393, 'loss': 0.006008326804637909, 'acc': 57.71}, 2: {'train_loss': 2.1568994522094727, 'loss': 0.005996437823772431, 'acc': 56.95}, 3: {'train_loss': 2.071584939956665, 'loss': 0.0060294353723526, 'acc': 57.88}, 'time': 0.4124641418457031}, 2: {1: {'train_loss': 2.1326446533203125, 'loss': 0.006333420300483703, 'acc': 54.03}, 2: {'train_loss': 2.1988742351531982, 'loss': 0.0062381223320961, 'acc': 55.15}, 3: {'train_loss': 2.1719813346862793, 'loss': 0.00629458533525467, 'acc': 53.12}, 'time': 0.41961669921875}}, 7: {0: {1: {'train_loss': 0.14989672601222992, 'loss': 0.00035194842548808084, 'acc': 97.15}, 2: {'train_loss': 0.21556344628334045, 'loss': 0.00033416237775236367, 'acc': 97.38}, 3: {'train_loss': 0.1860794574022293, 'loss': 0.00031240342757664623, 'acc': 97.46}, 'time': 0.4076957702636719}, 1: {1: {'train_loss': 1.557138442993164, 'loss': 0.005643065822124481, 'acc': 60.7}, 2: {'train_loss': 1.7438668012619019, 'loss': 0.005710247027873993, 'acc': 61.01}, 3: {'train_loss': 1.8255726099014282, 'loss': 0.005563441610336304, 'acc': 61.39}, 'time': 0.4752477010091146}, 2: {1: {'train_loss': 2.080620050430298, 'loss': 0.006134108114242554, 'acc': 55.25}, 2: {'train_loss': 2.1980552673339844, 'loss': 0.0060686442613601685, 'acc': 54.62}, 3: {'train_loss': 1.9112871885299683, 'loss': 0.006031629025936127, 'acc': 55.72}, 'time': 0.4267692565917969}}, 8: {0: {1: {'train_loss': 0.30813321471214294, 'loss': 0.0002939747471828014, 'acc': 97.68}, 2: {'train_loss': 0.3929198086261749, 'loss': 0.00028806067559635266, 'acc': 97.78}, 3: {'train_loss': 0.42707082629203796, 'loss': 0.0002734502214589156, 'acc': 97.84}, 'time': 0.44902165730794275}, 1: {1: {'train_loss': 1.8420742750167847, 'loss': 0.005179232716560364, 'acc': 65.24}, 2: {'train_loss': 1.8590184450149536, 'loss': 0.005322930949926376, 'acc': 65.22}, 3: {'train_loss': 1.946608304977417, 'loss': 0.0052125362277030945, 'acc': 64.65}, 'time': 0.4482269287109375}, 2: {1: {'train_loss': 1.9355510473251343, 'loss': 0.005588630378246307, 'acc': 60.33}, 2: {'train_loss': 1.9514976739883423, 'loss': 0.005630765426158905, 'acc': 59.7}, 3: {'train_loss': 1.9871325492858887, 'loss': 0.005686966848373413, 'acc': 59.66}, 'time': 0.400543212890625}}, 9: {0: {1: {'train_loss': 0.27563440799713135, 'loss': 0.0002711124181339983, 'acc': 97.8}, 2: {'train_loss': 0.18332652747631073, 'loss': 0.0002593362840416376, 'acc': 97.92}, 3: {'train_loss': 0.22825898230075836, 'loss': 0.0002494748776545748, 'acc': 97.87}, 'time': 0.48001607259114587}, 1: {1: {'train_loss': 1.6757605075836182, 'loss': 0.004794643479585648, 'acc': 67.52}, 2: {'train_loss': 1.8159960508346558, 'loss': 0.004760275042057037, 'acc': 68.24}, 3: {'train_loss': 1.7728853225708008, 'loss': 0.004802428859472275, 'acc': 67.67}, 'time': 0.46094258626302087}, 2: {1: {'train_loss': 1.9312098026275635, 'loss': 0.005435413050651551, 'acc': 63.12}, 2: {'train_loss': 2.0205652713775635, 'loss': 0.005521136891841889, 'acc': 62.78}, 3: {'train_loss': 1.9454776048660278, 'loss': 0.0054088513612747195, 'acc': 62.58}, 'time': 0.4371007283528646}}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_SI_MODEL[\"final_accs\"] = {}\n",
        "accs = []\n",
        "for id, task in enumerate(tasks):\n",
        "  _, (x_test, t_test) = task\n",
        "  _, acc = testSI(model, device, x_test, t_test)\n",
        "  accs.append(acc)\n",
        "  DATA_SI_MODEL[\"final_accs\"][id] = acc\n",
        "\n",
        "DATA_SI_MODEL[\"final_accs\"][\"avg\"] = np.average(accs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FMd70HBrGAnf",
        "outputId": "e255c066-1970-4667-d249-76f49e9decf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set: Average loss: 0.0004, Accuracy: 9706/10000 (97%)\n",
            "\n",
            "Test set: Average loss: 0.0067, Accuracy: 4065/10000 (41%)\n",
            "\n",
            "Test set: Average loss: 0.0054, Accuracy: 6258/10000 (63%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train SI for only one task so that it can be directly compared to 'traditional' in an application that suits 'traditional'"
      ],
      "metadata": {
        "id": "gTYPageWxsN8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Net().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "dataset_increments = 10 # refers to the number of different levels of data that are tested to show the difference between models\n",
        "x_size = len(x_train)\n",
        "t_size = len(t_train)\n",
        "\n",
        "DATA_SI_SIT_MODEL = {}\n",
        "for i in range (1,dataset_increments): \n",
        "      print(x_size * (1 / dataset_increments) * i)\n",
        "      DATA_SI_SIT_MODEL[i] = {}\n",
        "\n",
        "      x = x_train[:int(x_size * (1 / dataset_increments) * i)]\n",
        "      t = t_train[:int(x_size * (1 / dataset_increments) * i)]\n",
        "\n",
        "      timer.on_train_begin()\n",
        "      for epoch in range(1, 4):\n",
        "          train_loss = trainSI(model, device, 0, x, t, optimizer, epoch, timer)\n",
        "\n",
        "          loss, acc = testSI(model, device, x_test, t_test)\n",
        "\n",
        "          DATA_SI_SIT_MODEL[i][epoch] = {\n",
        "              \"train_loss\" : train_loss,\n",
        "              \"loss\" : loss,\n",
        "              \"acc\" : acc\n",
        "          }\n",
        "\n",
        "      timeCount = np.average(timer.times) * 10000\n",
        "      DATA_SI_SIT_MODEL[i][\"time\"] = timeCount\n",
        "      print(\"Time: \" + str(timeCount))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNsAdnwRxrZU",
        "outputId": "91d56ff7-2179-41cb-da5b-37e352db5de1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6000.0\n",
            "Train Epoch: 1 \tLoss: 2.296127\n",
            "Test set: Average loss: 0.0092, Accuracy: 980/10000 (10%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 2.298663\n",
            "Test set: Average loss: 0.0092, Accuracy: 981/10000 (10%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 2.293697\n",
            "Test set: Average loss: 0.0092, Accuracy: 2283/10000 (23%)\n",
            "\n",
            "Time: 0.38226445515950525\n",
            "12000.0\n",
            "Train Epoch: 1 \tLoss: 2.291453\n",
            "Test set: Average loss: 0.0091, Accuracy: 3112/10000 (31%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 2.270966\n",
            "Test set: Average loss: 0.0090, Accuracy: 2578/10000 (26%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 2.202689\n",
            "Test set: Average loss: 0.0086, Accuracy: 3096/10000 (31%)\n",
            "\n",
            "Time: 0.37272771199544275\n",
            "18000.0\n",
            "Train Epoch: 1 \tLoss: 1.999080\n",
            "Test set: Average loss: 0.0073, Accuracy: 4581/10000 (46%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 1.436518\n",
            "Test set: Average loss: 0.0052, Accuracy: 6479/10000 (65%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 1.114424\n",
            "Test set: Average loss: 0.0039, Accuracy: 7252/10000 (73%)\n",
            "\n",
            "Time: 0.5062421162923177\n",
            "24000.0\n",
            "Train Epoch: 1 \tLoss: 1.045286\n",
            "Test set: Average loss: 0.0029, Accuracy: 7909/10000 (79%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 0.913737\n",
            "Test set: Average loss: 0.0024, Accuracy: 8235/10000 (82%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 0.828115\n",
            "Test set: Average loss: 0.0020, Accuracy: 8575/10000 (86%)\n",
            "\n",
            "Time: 0.4124641418457031\n",
            "30000.0\n",
            "Train Epoch: 1 \tLoss: 0.936928\n",
            "Test set: Average loss: 0.0017, Accuracy: 8767/10000 (88%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 0.789697\n",
            "Test set: Average loss: 0.0015, Accuracy: 8913/10000 (89%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 0.973701\n",
            "Test set: Average loss: 0.0014, Accuracy: 9009/10000 (90%)\n",
            "\n",
            "Time: 0.47206878662109375\n",
            "36000.0\n",
            "Train Epoch: 1 \tLoss: 0.713782\n",
            "Test set: Average loss: 0.0012, Accuracy: 9091/10000 (91%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 0.587432\n",
            "Test set: Average loss: 0.0011, Accuracy: 9167/10000 (92%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 0.506307\n",
            "Test set: Average loss: 0.0011, Accuracy: 9186/10000 (92%)\n",
            "\n",
            "Time: 0.4863739013671875\n",
            "42000.0\n",
            "Train Epoch: 1 \tLoss: 0.747345\n",
            "Test set: Average loss: 0.0010, Accuracy: 9245/10000 (92%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 0.555096\n",
            "Test set: Average loss: 0.0010, Accuracy: 9287/10000 (93%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 0.266685\n",
            "Test set: Average loss: 0.0010, Accuracy: 9300/10000 (93%)\n",
            "\n",
            "Time: 0.472863515218099\n",
            "48000.0\n",
            "Train Epoch: 1 \tLoss: 0.496168\n",
            "Test set: Average loss: 0.0009, Accuracy: 9331/10000 (93%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 0.485899\n",
            "Test set: Average loss: 0.0009, Accuracy: 9336/10000 (93%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 0.514038\n",
            "Test set: Average loss: 0.0008, Accuracy: 9354/10000 (94%)\n",
            "\n",
            "Time: 0.4752477010091146\n",
            "54000.0\n",
            "Train Epoch: 1 \tLoss: 0.528214\n",
            "Test set: Average loss: 0.0008, Accuracy: 9370/10000 (94%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 0.428382\n",
            "Test set: Average loss: 0.0008, Accuracy: 9391/10000 (94%)\n",
            "\n",
            "Train Epoch: 3 \tLoss: 0.438242\n",
            "Test set: Average loss: 0.0008, Accuracy: 9408/10000 (94%)\n",
            "\n",
            "Time: 0.4982948303222656\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3SM7U5fwTqV"
      },
      "source": [
        "# Plot Results\n",
        "\n",
        "To conclude, let's summerize our results in a nice plot! :-)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "print(\"ni\")\n",
        "print(json.dumps(DATA_NI_MODEL, indent=4))\n",
        "print(\"naive\")\n",
        "print(json.dumps(DATA_NAIVE_MODEL, indent=4))\n",
        "print(\"rehearse\")\n",
        "print(json.dumps(DATA_REHEARSE_MODEL, indent=4))\n",
        "print(\"ewc\")\n",
        "print(json.dumps(DATA_EWC_MODEL, indent=4))\n",
        "print(\"si\")\n",
        "print(json.dumps(DATA_SI_MODEL, indent=4))\n",
        "DATA = { \n",
        "    \"NAIVE\" : DATA_NAIVE_MODEL, \n",
        "    \"REHEARSAL\" : DATA_REHEARSE_MODEL, \n",
        "    \"EWC\" : DATA_EWC_MODEL, \n",
        "    \"SI\" : DATA_SI_MODEL\n",
        "}\n",
        "\n",
        "DATA_SIT = {\n",
        "    \"NI\" : DATA_NI_MODEL,\n",
        "    \"SI\" : DATA_SI_SIT_MODEL\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9urlvYSH7k1",
        "outputId": "b2f9a161-1c7a-41b0-b41d-9e4c8f9145b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ni\n",
            "{\n",
            "    \"1\": {\n",
            "        \"1\": {\n",
            "            \"train_loss\": 2.2924535274505615,\n",
            "            \"loss\": 0.00916756467819214,\n",
            "            \"acc\": 11.95\n",
            "        },\n",
            "        \"2\": {\n",
            "            \"train_loss\": 2.2667300701141357,\n",
            "            \"loss\": 0.009016350555419921,\n",
            "            \"acc\": 22.12\n",
            "        },\n",
            "        \"3\": {\n",
            "            \"train_loss\": 2.1397452354431152,\n",
            "            \"loss\": 0.008185567760467529,\n",
            "            \"acc\": 42.99\n",
            "        },\n",
            "        \"time\": 0.40133794148763025\n",
            "    },\n",
            "    \"2\": {\n",
            "        \"1\": {\n",
            "            \"train_loss\": 2.275947093963623,\n",
            "            \"loss\": 0.009090036582946777,\n",
            "            \"acc\": 29.61\n",
            "        },\n",
            "        \"2\": {\n",
            "            \"train_loss\": 1.9894192218780518,\n",
            "            \"loss\": 0.007368216109275818,\n",
            "            \"acc\": 48.57\n",
            "        },\n",
            "        \"3\": {\n",
            "            \"train_loss\": 1.111718773841858,\n",
            "            \"loss\": 0.0027832350075244904,\n",
            "            \"acc\": 79.9\n",
            "        },\n",
            "        \"time\": 0.3544489542643229\n",
            "    },\n",
            "    \"3\": {\n",
            "        \"1\": {\n",
            "            \"train_loss\": 2.270383358001709,\n",
            "            \"loss\": 0.009076669883728027,\n",
            "            \"acc\": 26.6\n",
            "        },\n",
            "        \"2\": {\n",
            "            \"train_loss\": 1.34116530418396,\n",
            "            \"loss\": 0.00422056525349617,\n",
            "            \"acc\": 74.28\n",
            "        },\n",
            "        \"3\": {\n",
            "            \"train_loss\": 0.6781015992164612,\n",
            "            \"loss\": 0.0017463231310248374,\n",
            "            \"acc\": 87.61\n",
            "        },\n",
            "        \"time\": 0.35365422566731775\n",
            "    },\n",
            "    \"4\": {\n",
            "        \"1\": {\n",
            "            \"train_loss\": 1.9939674139022827,\n",
            "            \"loss\": 0.00701313568353653,\n",
            "            \"acc\": 61.29\n",
            "        },\n",
            "        \"2\": {\n",
            "            \"train_loss\": 0.7978543639183044,\n",
            "            \"loss\": 0.0015894717499613763,\n",
            "            \"acc\": 88.76\n",
            "        },\n",
            "        \"3\": {\n",
            "            \"train_loss\": 0.5851295590400696,\n",
            "            \"loss\": 0.0010944849491119385,\n",
            "            \"acc\": 91.98\n",
            "        },\n",
            "        \"time\": 0.3457069396972656\n",
            "    },\n",
            "    \"5\": {\n",
            "        \"1\": {\n",
            "            \"train_loss\": 1.4325579404830933,\n",
            "            \"loss\": 0.0031127165138721464,\n",
            "            \"acc\": 80.24\n",
            "        },\n",
            "        \"2\": {\n",
            "            \"train_loss\": 0.8011205196380615,\n",
            "            \"loss\": 0.0012794721685349942,\n",
            "            \"acc\": 90.69\n",
            "        },\n",
            "        \"3\": {\n",
            "            \"train_loss\": 0.8246934413909912,\n",
            "            \"loss\": 0.0009359110899269581,\n",
            "            \"acc\": 93.08\n",
            "        },\n",
            "        \"time\": 0.3695487976074219\n",
            "    },\n",
            "    \"6\": {\n",
            "        \"1\": {\n",
            "            \"train_loss\": 1.0251271724700928,\n",
            "            \"loss\": 0.0024209115505218507,\n",
            "            \"acc\": 82.34\n",
            "        },\n",
            "        \"2\": {\n",
            "            \"train_loss\": 0.6762245297431946,\n",
            "            \"loss\": 0.0012897067487239837,\n",
            "            \"acc\": 90.45\n",
            "        },\n",
            "        \"3\": {\n",
            "            \"train_loss\": 0.534896969795227,\n",
            "            \"loss\": 0.0008548244556412101,\n",
            "            \"acc\": 93.34\n",
            "        },\n",
            "        \"time\": 0.3488858540852865\n",
            "    },\n",
            "    \"7\": {\n",
            "        \"1\": {\n",
            "            \"train_loss\": 0.9302313923835754,\n",
            "            \"loss\": 0.0020833231538534163,\n",
            "            \"acc\": 83.38\n",
            "        },\n",
            "        \"2\": {\n",
            "            \"train_loss\": 0.6055277585983276,\n",
            "            \"loss\": 0.0010361372545361518,\n",
            "            \"acc\": 92.82\n",
            "        },\n",
            "        \"3\": {\n",
            "            \"train_loss\": 0.600745677947998,\n",
            "            \"loss\": 0.0007485628159716725,\n",
            "            \"acc\": 94.16\n",
            "        },\n",
            "        \"time\": 0.3949801127115885\n",
            "    },\n",
            "    \"8\": {\n",
            "        \"1\": {\n",
            "            \"train_loss\": 0.970856249332428,\n",
            "            \"loss\": 0.0016222374781966209,\n",
            "            \"acc\": 87.95\n",
            "        },\n",
            "        \"2\": {\n",
            "            \"train_loss\": 0.6230085492134094,\n",
            "            \"loss\": 0.0008837750751525163,\n",
            "            \"acc\": 93.55\n",
            "        },\n",
            "        \"3\": {\n",
            "            \"train_loss\": 0.4487129747867584,\n",
            "            \"loss\": 0.0006443192974664271,\n",
            "            \"acc\": 95.09\n",
            "        },\n",
            "        \"time\": 0.358422597249349\n",
            "    },\n",
            "    \"9\": {\n",
            "        \"1\": {\n",
            "            \"train_loss\": 0.6770536303520203,\n",
            "            \"loss\": 0.001634502813220024,\n",
            "            \"acc\": 87.14\n",
            "        },\n",
            "        \"2\": {\n",
            "            \"train_loss\": 0.4491601586341858,\n",
            "            \"loss\": 0.000883065339922905,\n",
            "            \"acc\": 93.62\n",
            "        },\n",
            "        \"3\": {\n",
            "            \"train_loss\": 0.36054152250289917,\n",
            "            \"loss\": 0.0006240164009854197,\n",
            "            \"acc\": 95.28\n",
            "        },\n",
            "        \"time\": 0.37113825480143225\n",
            "    }\n",
            "}\n",
            "naive\n",
            "{\n",
            "    \"1\": {\n",
            "        \"0\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 2.2908318042755127,\n",
            "                \"loss\": 0.009046000409126282,\n",
            "                \"acc\": 37.06\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 2.161489963531494,\n",
            "                \"loss\": 0.008399878573417664,\n",
            "                \"acc\": 47.43\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 1.7339640855789185,\n",
            "                \"loss\": 0.005767020928859711,\n",
            "                \"acc\": 68.04\n",
            "            },\n",
            "            \"time\": 0.4116694132486979\n",
            "        },\n",
            "        \"1\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 2.28761887550354,\n",
            "                \"loss\": 0.009101049137115479,\n",
            "                \"acc\": 20.46\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 2.1863107681274414,\n",
            "                \"loss\": 0.008784336042404174,\n",
            "                \"acc\": 28.9\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 2.1723716259002686,\n",
            "                \"loss\": 0.008316641283035279,\n",
            "                \"acc\": 34.37\n",
            "            },\n",
            "            \"time\": 0.39180119832356775\n",
            "        },\n",
            "        \"2\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 2.1636762619018555,\n",
            "                \"loss\": 0.008477894949913025,\n",
            "                \"acc\": 30.74\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 2.003976345062256,\n",
            "                \"loss\": 0.007817102587223053,\n",
            "                \"acc\": 36.82\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 1.881421446800232,\n",
            "                \"loss\": 0.007033462226390838,\n",
            "                \"acc\": 44.63\n",
            "            },\n",
            "            \"time\": 0.404516855875651\n",
            "        }\n",
            "    },\n",
            "    \"2\": {\n",
            "        \"0\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 0.8873515725135803,\n",
            "                \"loss\": 0.002324506661295891,\n",
            "                \"acc\": 83.24\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 0.6715828776359558,\n",
            "                \"loss\": 0.001472426339238882,\n",
            "                \"acc\": 89.11\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 0.5611094236373901,\n",
            "                \"loss\": 0.001160445024445653,\n",
            "                \"acc\": 91.6\n",
            "            },\n",
            "            \"time\": 0.4744529724121094\n",
            "        },\n",
            "        \"1\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 1.9436523914337158,\n",
            "                \"loss\": 0.006988550853729248,\n",
            "                \"acc\": 42.55\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 1.5878263711929321,\n",
            "                \"loss\": 0.005404062426090241,\n",
            "                \"acc\": 58.92\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 1.3440297842025757,\n",
            "                \"loss\": 0.004331234407424927,\n",
            "                \"acc\": 66.82\n",
            "            },\n",
            "            \"time\": 0.4442532857259115\n",
            "        },\n",
            "        \"2\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 1.7123115062713623,\n",
            "                \"loss\": 0.006016760885715485,\n",
            "                \"acc\": 49.94\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 1.5005099773406982,\n",
            "                \"loss\": 0.004604498428106308,\n",
            "                \"acc\": 63.78\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 1.1700736284255981,\n",
            "                \"loss\": 0.0037992547571659087,\n",
            "                \"acc\": 70.68\n",
            "            },\n",
            "            \"time\": 0.4331270853678385\n",
            "        }\n",
            "    },\n",
            "    \"3\": {\n",
            "        \"0\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 0.5322596430778503,\n",
            "                \"loss\": 0.0011869549252092838,\n",
            "                \"acc\": 91.02\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 0.3811178505420685,\n",
            "                \"loss\": 0.0009749140378087759,\n",
            "                \"acc\": 92.98\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 0.4415058493614197,\n",
            "                \"loss\": 0.0008203613908961415,\n",
            "                \"acc\": 93.8\n",
            "            },\n",
            "            \"time\": 0.4291534423828125\n",
            "        },\n",
            "        \"1\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 1.2863519191741943,\n",
            "                \"loss\": 0.004513990712165832,\n",
            "                \"acc\": 69.93\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 1.0778982639312744,\n",
            "                \"loss\": 0.0034189130783081056,\n",
            "                \"acc\": 76.97\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 0.8982291221618652,\n",
            "                \"loss\": 0.0027749655842781067,\n",
            "                \"acc\": 80.38\n",
            "            },\n",
            "            \"time\": 0.4482269287109375\n",
            "        },\n",
            "        \"2\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 1.3206313848495483,\n",
            "                \"loss\": 0.004261145144701004,\n",
            "                \"acc\": 70.29\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 1.04926598072052,\n",
            "                \"loss\": 0.0033457904636859893,\n",
            "                \"acc\": 76.96\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 0.8797932863235474,\n",
            "                \"loss\": 0.0028175799876451494,\n",
            "                \"acc\": 79.87\n",
            "            },\n",
            "            \"time\": 0.44504801432291663\n",
            "        }\n",
            "    },\n",
            "    \"4\": {\n",
            "        \"0\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 0.5581488609313965,\n",
            "                \"loss\": 0.0008802024807780981,\n",
            "                \"acc\": 93.55\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 0.5200222730636597,\n",
            "                \"loss\": 0.0007654850475490093,\n",
            "                \"acc\": 94.15\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 0.5937907099723816,\n",
            "                \"loss\": 0.0006725431594997645,\n",
            "                \"acc\": 94.81\n",
            "            },\n",
            "            \"time\": 0.43948491414388025\n",
            "        },\n",
            "        \"1\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 1.2045917510986328,\n",
            "                \"loss\": 0.0028498270124197008,\n",
            "                \"acc\": 79.61\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 1.0903748273849487,\n",
            "                \"loss\": 0.0023827342987060547,\n",
            "                \"acc\": 82.46\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 0.9446331858634949,\n",
            "                \"loss\": 0.0021161028385162355,\n",
            "                \"acc\": 84.65\n",
            "            },\n",
            "            \"time\": 0.4522005716959635\n",
            "        },\n",
            "        \"2\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 1.1102200746536255,\n",
            "                \"loss\": 0.0030250783026218413,\n",
            "                \"acc\": 78.13\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 1.076504111289978,\n",
            "                \"loss\": 0.0024926520526409148,\n",
            "                \"acc\": 81.98\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 0.925765335559845,\n",
            "                \"loss\": 0.002180042476952076,\n",
            "                \"acc\": 83.76\n",
            "            },\n",
            "            \"time\": 0.5690256754557291\n",
            "        }\n",
            "    },\n",
            "    \"5\": {\n",
            "        \"0\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 0.6686496138572693,\n",
            "                \"loss\": 0.0007225375248119235,\n",
            "                \"acc\": 94.59\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 0.7287397980690002,\n",
            "                \"loss\": 0.0006304500327445567,\n",
            "                \"acc\": 95.16\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 0.45180225372314453,\n",
            "                \"loss\": 0.0005489348146133125,\n",
            "                \"acc\": 95.61\n",
            "            },\n",
            "            \"time\": 0.43789545694986975\n",
            "        },\n",
            "        \"1\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 1.2768840789794922,\n",
            "                \"loss\": 0.0020950136050581934,\n",
            "                \"acc\": 84.75\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 1.1022371053695679,\n",
            "                \"loss\": 0.0018340281933546065,\n",
            "                \"acc\": 86.3\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 1.1934585571289062,\n",
            "                \"loss\": 0.0016723869733512402,\n",
            "                \"acc\": 87.2\n",
            "            },\n",
            "            \"time\": 0.42438507080078125\n",
            "        },\n",
            "        \"2\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 1.0457234382629395,\n",
            "                \"loss\": 0.0024094455868005752,\n",
            "                \"acc\": 82.45\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 1.1505699157714844,\n",
            "                \"loss\": 0.002028274114429951,\n",
            "                \"acc\": 84.91\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 0.8868952393531799,\n",
            "                \"loss\": 0.0018068660512566565,\n",
            "                \"acc\": 86.65\n",
            "            },\n",
            "            \"time\": 0.44345855712890625\n",
            "        }\n",
            "    },\n",
            "    \"6\": {\n",
            "        \"0\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 0.3278142809867859,\n",
            "                \"loss\": 0.0006078562119044363,\n",
            "                \"acc\": 95.33\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 0.4117773473262787,\n",
            "                \"loss\": 0.0005337299838196486,\n",
            "                \"acc\": 95.66\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 0.3531770706176758,\n",
            "                \"loss\": 0.0004808208243921399,\n",
            "                \"acc\": 96.22\n",
            "            },\n",
            "            \"time\": 0.4315376281738281\n",
            "        },\n",
            "        \"1\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 0.9771787524223328,\n",
            "                \"loss\": 0.0018453532814979553,\n",
            "                \"acc\": 86.36\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 0.868195652961731,\n",
            "                \"loss\": 0.0016253675617277621,\n",
            "                \"acc\": 87.55\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 0.8026674389839172,\n",
            "                \"loss\": 0.0015046833291649819,\n",
            "                \"acc\": 88.6\n",
            "            },\n",
            "            \"time\": 0.6079673767089844\n",
            "        },\n",
            "        \"2\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 1.0139923095703125,\n",
            "                \"loss\": 0.0020664349123835565,\n",
            "                \"acc\": 84.57\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 0.9135372042655945,\n",
            "                \"loss\": 0.0017974338129162788,\n",
            "                \"acc\": 86.37\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 0.8111364245414734,\n",
            "                \"loss\": 0.0016766770541667938,\n",
            "                \"acc\": 87.82\n",
            "            },\n",
            "            \"time\": 0.5030632019042969\n",
            "        }\n",
            "    },\n",
            "    \"7\": {\n",
            "        \"0\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 0.5147473812103271,\n",
            "                \"loss\": 0.0005769664481282234,\n",
            "                \"acc\": 95.49\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 0.2998255491256714,\n",
            "                \"loss\": 0.00050104670682922,\n",
            "                \"acc\": 95.99\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 0.49471017718315125,\n",
            "                \"loss\": 0.0004659105593571439,\n",
            "                \"acc\": 96.26\n",
            "            },\n",
            "            \"time\": 0.41882197062174475\n",
            "        },\n",
            "        \"1\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 1.0753659009933472,\n",
            "                \"loss\": 0.0017457907229661942,\n",
            "                \"acc\": 86.84\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 0.8467377424240112,\n",
            "                \"loss\": 0.0015235428363084794,\n",
            "                \"acc\": 88.14\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 0.5336705446243286,\n",
            "                \"loss\": 0.0013869794875383378,\n",
            "                \"acc\": 89.17\n",
            "            },\n",
            "            \"time\": 0.4903475443522135\n",
            "        },\n",
            "        \"2\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 0.9841068387031555,\n",
            "                \"loss\": 0.0018091172218322755,\n",
            "                \"acc\": 86.71\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 0.5467952489852905,\n",
            "                \"loss\": 0.0016080388464033604,\n",
            "                \"acc\": 87.82\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 0.7099611163139343,\n",
            "                \"loss\": 0.0014926877789199352,\n",
            "                \"acc\": 88.68\n",
            "            },\n",
            "            \"time\": 0.46650568644205725\n",
            "        }\n",
            "    },\n",
            "    \"8\": {\n",
            "        \"0\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 0.4648463726043701,\n",
            "                \"loss\": 0.0005130836253520101,\n",
            "                \"acc\": 96.04\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 0.40450021624565125,\n",
            "                \"loss\": 0.0004496583389118314,\n",
            "                \"acc\": 96.45\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 0.3988770544528961,\n",
            "                \"loss\": 0.0004140155424596742,\n",
            "                \"acc\": 96.82\n",
            "            },\n",
            "            \"time\": 1.0959307352701824\n",
            "        },\n",
            "        \"1\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 0.9519701600074768,\n",
            "                \"loss\": 0.0015748533710837364,\n",
            "                \"acc\": 88.28\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 0.7754494547843933,\n",
            "                \"loss\": 0.0013775675594806672,\n",
            "                \"acc\": 89.49\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 0.69183748960495,\n",
            "                \"loss\": 0.0013060333669185637,\n",
            "                \"acc\": 89.98\n",
            "            },\n",
            "            \"time\": 0.434716542561849\n",
            "        },\n",
            "        \"2\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 0.8307145237922668,\n",
            "                \"loss\": 0.0016574259251356126,\n",
            "                \"acc\": 87.53\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 0.8079546093940735,\n",
            "                \"loss\": 0.0014882870651781559,\n",
            "                \"acc\": 88.62\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 0.7723559737205505,\n",
            "                \"loss\": 0.0014134158831089734,\n",
            "                \"acc\": 89.48\n",
            "            },\n",
            "            \"time\": 0.47047932942708337\n",
            "        }\n",
            "    },\n",
            "    \"9\": {\n",
            "        \"0\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 0.4462997615337372,\n",
            "                \"loss\": 0.00046187990182079377,\n",
            "                \"acc\": 96.33\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 0.2927987277507782,\n",
            "                \"loss\": 0.0004060784053755924,\n",
            "                \"acc\": 96.78\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 0.3364410102367401,\n",
            "                \"loss\": 0.0003795720061287284,\n",
            "                \"acc\": 96.98\n",
            "            },\n",
            "            \"time\": 0.4553794860839844\n",
            "        },\n",
            "        \"1\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 0.7192458510398865,\n",
            "                \"loss\": 0.0014319428317248822,\n",
            "                \"acc\": 88.84\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 0.6806464791297913,\n",
            "                \"loss\": 0.00129188720472157,\n",
            "                \"acc\": 90.06\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 0.6149784922599792,\n",
            "                \"loss\": 0.0012247537672519684,\n",
            "                \"acc\": 90.54\n",
            "            },\n",
            "            \"time\": 0.4315376281738281\n",
            "        },\n",
            "        \"2\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 0.7262661457061768,\n",
            "                \"loss\": 0.0015427979730069637,\n",
            "                \"acc\": 88.31\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 0.6169997453689575,\n",
            "                \"loss\": 0.0014100523814558983,\n",
            "                \"acc\": 89.31\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 0.6527081727981567,\n",
            "                \"loss\": 0.0013281353179365395,\n",
            "                \"acc\": 89.8\n",
            "            },\n",
            "            \"time\": 0.476837158203125\n",
            "        }\n",
            "    },\n",
            "    \"final_accs\": {\n",
            "        \"0\": 60.96,\n",
            "        \"1\": 59.28,\n",
            "        \"2\": 89.8,\n",
            "        \"avg\": 70.01333333333334\n",
            "    }\n",
            "}\n",
            "rehearse\n",
            "{\n",
            "    \"1\": {\n",
            "        \"0\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 0.6274406313896179,\n",
            "                \"loss\": 0.0012102363243699074,\n",
            "                \"acc\": 91.46\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 0.4484853744506836,\n",
            "                \"loss\": 0.0007014840699732304,\n",
            "                \"acc\": 94.74\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 0.27311357855796814,\n",
            "                \"loss\": 0.0005460611859336496,\n",
            "                \"acc\": 95.77\n",
            "            },\n",
            "            \"time\": 0.5245208740234375\n",
            "        },\n",
            "        \"1\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 1.552297592163086,\n",
            "                \"loss\": 0.00504028542637825,\n",
            "                \"acc\": 65.39\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 1.1947468519210815,\n",
            "                \"loss\": 0.0030701698392629623,\n",
            "                \"acc\": 77.23\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 0.9397795796394348,\n",
            "                \"loss\": 0.002367609940469265,\n",
            "                \"acc\": 82.89\n",
            "            },\n",
            "            \"time\": 0.5396207173665365\n",
            "        },\n",
            "        \"2\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 1.3938320875167847,\n",
            "                \"loss\": 0.004397496491670609,\n",
            "                \"acc\": 68.07\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 0.9673555493354797,\n",
            "                \"loss\": 0.0027419843822717666,\n",
            "                \"acc\": 80.57\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 0.9084789752960205,\n",
            "                \"loss\": 0.0021527368158102034,\n",
            "                \"acc\": 84.21\n",
            "            },\n",
            "            \"time\": 0.530083974202474\n",
            "        }\n",
            "    },\n",
            "    \"2\": {\n",
            "        \"0\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 0.4330347776412964,\n",
            "                \"loss\": 0.0005602493547834456,\n",
            "                \"acc\": 95.75\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 0.3709243834018707,\n",
            "                \"loss\": 0.00047381546972319485,\n",
            "                \"acc\": 96.2\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 0.287128746509552,\n",
            "                \"loss\": 0.0003986152092926204,\n",
            "                \"acc\": 96.77\n",
            "            },\n",
            "            \"time\": 0.46253204345703125\n",
            "        },\n",
            "        \"1\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 1.3260859251022339,\n",
            "                \"loss\": 0.0031282301396131514,\n",
            "                \"acc\": 79.18\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 1.1365277767181396,\n",
            "                \"loss\": 0.002206906943023205,\n",
            "                \"acc\": 83.99\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 0.793700635433197,\n",
            "                \"loss\": 0.0018260817393660545,\n",
            "                \"acc\": 86.83\n",
            "            },\n",
            "            \"time\": 0.518957773844401\n",
            "        },\n",
            "        \"2\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 1.516738772392273,\n",
            "                \"loss\": 0.002739869102835655,\n",
            "                \"acc\": 79.68\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 1.0956120491027832,\n",
            "                \"loss\": 0.002134856140613556,\n",
            "                \"acc\": 84.12\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 1.0243993997573853,\n",
            "                \"loss\": 0.001828535359352827,\n",
            "                \"acc\": 86.59\n",
            "            },\n",
            "            \"time\": 0.5284945170084635\n",
            "        }\n",
            "    },\n",
            "    \"3\": {\n",
            "        \"0\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 0.39716705679893494,\n",
            "                \"loss\": 0.00044174771010875704,\n",
            "                \"acc\": 96.49\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 0.25807711482048035,\n",
            "                \"loss\": 0.0003774999067070894,\n",
            "                \"acc\": 96.9\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 0.3367120921611786,\n",
            "                \"loss\": 0.00035685009526787326,\n",
            "                \"acc\": 97.04\n",
            "            },\n",
            "            \"time\": 0.45696894327799475\n",
            "        },\n",
            "        \"1\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 1.1799629926681519,\n",
            "                \"loss\": 0.0027775450080633163,\n",
            "                \"acc\": 80.02\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 0.8637688159942627,\n",
            "                \"loss\": 0.0019468849703669548,\n",
            "                \"acc\": 85.15\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 0.8448331952095032,\n",
            "                \"loss\": 0.0016586091324687004,\n",
            "                \"acc\": 87.52\n",
            "            },\n",
            "            \"time\": 0.568230946858724\n",
            "        },\n",
            "        \"2\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 0.9117042422294617,\n",
            "                \"loss\": 0.0023554052233695985,\n",
            "                \"acc\": 82.54\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 0.604815661907196,\n",
            "                \"loss\": 0.0017259112417697907,\n",
            "                \"acc\": 86.88\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 0.5173882842063904,\n",
            "                \"loss\": 0.0014806027159094811,\n",
            "                \"acc\": 88.84\n",
            "            },\n",
            "            \"time\": 0.5435943603515625\n",
            "        }\n",
            "    },\n",
            "    \"4\": {\n",
            "        \"0\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 0.5660855174064636,\n",
            "                \"loss\": 0.0004154923941940069,\n",
            "                \"acc\": 96.58\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 0.4134615659713745,\n",
            "                \"loss\": 0.0003532135526882485,\n",
            "                \"acc\": 97.12\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 0.25576940178871155,\n",
            "                \"loss\": 0.0003367643014760688,\n",
            "                \"acc\": 97.02\n",
            "            },\n",
            "            \"time\": 0.44743220011393225\n",
            "        },\n",
            "        \"1\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 1.0564805269241333,\n",
            "                \"loss\": 0.001891276989877224,\n",
            "                \"acc\": 85.5\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 0.796760082244873,\n",
            "                \"loss\": 0.001645739421993494,\n",
            "                \"acc\": 87.58\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 0.6455996632575989,\n",
            "                \"loss\": 0.0014331032499670983,\n",
            "                \"acc\": 88.66\n",
            "            },\n",
            "            \"time\": 0.5245208740234375\n",
            "        },\n",
            "        \"2\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 0.6306024789810181,\n",
            "                \"loss\": 0.0017647795528173446,\n",
            "                \"acc\": 86.61\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 0.6073376536369324,\n",
            "                \"loss\": 0.001400463417544961,\n",
            "                \"acc\": 89.39\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 0.5938542485237122,\n",
            "                \"loss\": 0.0012922973558306694,\n",
            "                \"acc\": 90.41\n",
            "            },\n",
            "            \"time\": 0.499884287516276\n",
            "        }\n",
            "    },\n",
            "    \"5\": {\n",
            "        \"0\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 0.4329022169113159,\n",
            "                \"loss\": 0.0003632208386436105,\n",
            "                \"acc\": 96.93\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 0.2478109449148178,\n",
            "                \"loss\": 0.00033848361051641405,\n",
            "                \"acc\": 97.17\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 0.22130919992923737,\n",
            "                \"loss\": 0.000306708508124575,\n",
            "                \"acc\": 97.46\n",
            "            },\n",
            "            \"time\": 0.5316734313964844\n",
            "        },\n",
            "        \"1\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 0.7595319747924805,\n",
            "                \"loss\": 0.0016399554215371609,\n",
            "                \"acc\": 87.57\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 0.7802092432975769,\n",
            "                \"loss\": 0.0014499709717929363,\n",
            "                \"acc\": 88.9\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 0.6061431765556335,\n",
            "                \"loss\": 0.001318134470283985,\n",
            "                \"acc\": 89.99\n",
            "            },\n",
            "            \"time\": 0.5261103312174479\n",
            "        },\n",
            "        \"2\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 0.6475062966346741,\n",
            "                \"loss\": 0.00141071822270751,\n",
            "                \"acc\": 89.17\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 0.5363360047340393,\n",
            "                \"loss\": 0.0012859812609851361,\n",
            "                \"acc\": 90.47\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 0.4134317934513092,\n",
            "                \"loss\": 0.0012213544480502605,\n",
            "                \"acc\": 91.1\n",
            "            },\n",
            "            \"time\": 0.5229314168294271\n",
            "        }\n",
            "    },\n",
            "    \"6\": {\n",
            "        \"0\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 0.3777752220630646,\n",
            "                \"loss\": 0.0003485024711349979,\n",
            "                \"acc\": 97.0\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 0.26666131615638733,\n",
            "                \"loss\": 0.0003197130842891056,\n",
            "                \"acc\": 97.4\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 0.17277874052524567,\n",
            "                \"loss\": 0.0002946849603846203,\n",
            "                \"acc\": 97.48\n",
            "            },\n",
            "            \"time\": 0.5578994750976562\n",
            "        },\n",
            "        \"1\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 0.8156778216362,\n",
            "                \"loss\": 0.0014447338350117207,\n",
            "                \"acc\": 89.01\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 0.582916796207428,\n",
            "                \"loss\": 0.0013144473198801279,\n",
            "                \"acc\": 89.81\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 0.6380355954170227,\n",
            "                \"loss\": 0.0012487020872533321,\n",
            "                \"acc\": 90.38\n",
            "            },\n",
            "            \"time\": 0.5284945170084635\n",
            "        },\n",
            "        \"2\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 0.5152837634086609,\n",
            "                \"loss\": 0.0013198644164949655,\n",
            "                \"acc\": 90.01\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 0.557528555393219,\n",
            "                \"loss\": 0.001206883493810892,\n",
            "                \"acc\": 90.98\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 0.4899539053440094,\n",
            "                \"loss\": 0.0011528459563851356,\n",
            "                \"acc\": 91.23\n",
            "            },\n",
            "            \"time\": 0.5062421162923177\n",
            "        }\n",
            "    },\n",
            "    \"7\": {\n",
            "        \"0\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 0.27980828285217285,\n",
            "                \"loss\": 0.0003416088744532317,\n",
            "                \"acc\": 97.17\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 0.13581593334674835,\n",
            "                \"loss\": 0.00030490574500290676,\n",
            "                \"acc\": 97.5\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 0.37755969166755676,\n",
            "                \"loss\": 0.0002860017248545773,\n",
            "                \"acc\": 97.66\n",
            "            },\n",
            "            \"time\": 0.46253204345703125\n",
            "        },\n",
            "        \"1\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 0.6190974116325378,\n",
            "                \"loss\": 0.0013805974394083024,\n",
            "                \"acc\": 89.58\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 0.6485990881919861,\n",
            "                \"loss\": 0.0012810211841017007,\n",
            "                \"acc\": 90.47\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 0.5234541296958923,\n",
            "                \"loss\": 0.001198200237751007,\n",
            "                \"acc\": 90.86\n",
            "            },\n",
            "            \"time\": 0.5221366882324219\n",
            "        },\n",
            "        \"2\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 0.5473093390464783,\n",
            "                \"loss\": 0.001261918317899108,\n",
            "                \"acc\": 90.37\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 0.4269225597381592,\n",
            "                \"loss\": 0.0011580305282026528,\n",
            "                \"acc\": 91.05\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 0.5874308943748474,\n",
            "                \"loss\": 0.0011015700243413448,\n",
            "                \"acc\": 91.37\n",
            "            },\n",
            "            \"time\": 0.4975001017252604\n",
            "        }\n",
            "    },\n",
            "    \"8\": {\n",
            "        \"0\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 0.1547122448682785,\n",
            "                \"loss\": 0.0003293900315533392,\n",
            "                \"acc\": 97.36\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 0.2374117374420166,\n",
            "                \"loss\": 0.00029767423743323886,\n",
            "                \"acc\": 97.53\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 0.24459820985794067,\n",
            "                \"loss\": 0.0002775375808880199,\n",
            "                \"acc\": 97.77\n",
            "            },\n",
            "            \"time\": 0.4943211873372396\n",
            "        },\n",
            "        \"1\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 0.7235282063484192,\n",
            "                \"loss\": 0.001342344219237566,\n",
            "                \"acc\": 89.97\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 0.7047563195228577,\n",
            "                \"loss\": 0.0012254657313227654,\n",
            "                \"acc\": 90.84\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 0.47949859499931335,\n",
            "                \"loss\": 0.0011577315244823694,\n",
            "                \"acc\": 91.14\n",
            "            },\n",
            "            \"time\": 0.5849202473958334\n",
            "        },\n",
            "        \"2\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 0.4602183401584625,\n",
            "                \"loss\": 0.0012397814501076937,\n",
            "                \"acc\": 90.66\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 0.5126312971115112,\n",
            "                \"loss\": 0.0011414085011929274,\n",
            "                \"acc\": 91.28\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 0.4325176179409027,\n",
            "                \"loss\": 0.001090253070741892,\n",
            "                \"acc\": 91.8\n",
            "            },\n",
            "            \"time\": 0.5102157592773438\n",
            "        }\n",
            "    },\n",
            "    \"9\": {\n",
            "        \"0\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 0.32270267605781555,\n",
            "                \"loss\": 0.0003311287362361327,\n",
            "                \"acc\": 97.27\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 0.17152054607868195,\n",
            "                \"loss\": 0.0002983983423851896,\n",
            "                \"acc\": 97.48\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 0.25706747174263,\n",
            "                \"loss\": 0.0002745642997440882,\n",
            "                \"acc\": 97.71\n",
            "            },\n",
            "            \"time\": 0.4267692565917969\n",
            "        },\n",
            "        \"1\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 0.5976736545562744,\n",
            "                \"loss\": 0.0012660264562815427,\n",
            "                \"acc\": 90.4\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 0.5710424780845642,\n",
            "                \"loss\": 0.0011656930211931466,\n",
            "                \"acc\": 90.74\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 0.593002200126648,\n",
            "                \"loss\": 0.0011120430070906877,\n",
            "                \"acc\": 91.44\n",
            "            },\n",
            "            \"time\": 0.4903475443522135\n",
            "        },\n",
            "        \"2\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 0.6199366450309753,\n",
            "                \"loss\": 0.0012082397514954209,\n",
            "                \"acc\": 90.6\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 0.6585562229156494,\n",
            "                \"loss\": 0.0011127826103940607,\n",
            "                \"acc\": 91.27\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 0.465085506439209,\n",
            "                \"loss\": 0.0010959560358896852,\n",
            "                \"acc\": 91.59\n",
            "            },\n",
            "            \"time\": 0.499884287516276\n",
            "        }\n",
            "    },\n",
            "    \"final_accs\": {\n",
            "        \"0\": 65.14,\n",
            "        \"1\": 66.53,\n",
            "        \"2\": 91.59,\n",
            "        \"avg\": 74.42\n",
            "    }\n",
            "}\n",
            "ewc\n",
            "{\n",
            "    \"1\": {\n",
            "        \"0\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 2.3019444942474365,\n",
            "                \"loss\": 0.009153960084915161,\n",
            "                \"acc\": 21.81\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 2.263390064239502,\n",
            "                \"loss\": 0.008974904012680054,\n",
            "                \"acc\": 28.93\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 2.1087758541107178,\n",
            "                \"loss\": 0.008170814967155457,\n",
            "                \"acc\": 51.01\n",
            "            },\n",
            "            \"time\": 0.4307428995768229\n",
            "        },\n",
            "        \"1\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 2.3152313232421875,\n",
            "                \"loss\": 0.009175422644615173,\n",
            "                \"acc\": 12.6\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 2.2847750186920166,\n",
            "                \"loss\": 0.009079998874664307,\n",
            "                \"acc\": 27.49\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 2.2417569160461426,\n",
            "                \"loss\": 0.008944898319244384,\n",
            "                \"acc\": 27.63\n",
            "            },\n",
            "            \"time\": 0.3552436828613281\n",
            "        },\n",
            "        \"2\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 2.243030309677124,\n",
            "                \"loss\": 0.008903159475326538,\n",
            "                \"acc\": 22.83\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 2.1820850372314453,\n",
            "                \"loss\": 0.008662461233139037,\n",
            "                \"acc\": 27.83\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 2.163635015487671,\n",
            "                \"loss\": 0.008391227340698242,\n",
            "                \"acc\": 32.98\n",
            "            },\n",
            "            \"time\": 0.42994817097981775\n",
            "        }\n",
            "    },\n",
            "    \"2\": {\n",
            "        \"0\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 1.1343872547149658,\n",
            "                \"loss\": 0.0031547297328710557,\n",
            "                \"acc\": 80.15\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 0.7217012643814087,\n",
            "                \"loss\": 0.001862979130446911,\n",
            "                \"acc\": 86.97\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 0.606917679309845,\n",
            "                \"loss\": 0.0014495251938700677,\n",
            "                \"acc\": 89.96\n",
            "            },\n",
            "            \"time\": 0.3790855407714844\n",
            "        },\n",
            "        \"1\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 2.082061529159546,\n",
            "                \"loss\": 0.007775472939014435,\n",
            "                \"acc\": 36.26\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 1.8429077863693237,\n",
            "                \"loss\": 0.0062793725490570065,\n",
            "                \"acc\": 48.38\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 1.5548853874206543,\n",
            "                \"loss\": 0.005128163594007492,\n",
            "                \"acc\": 61.7\n",
            "            },\n",
            "            \"time\": 0.4903475443522135\n",
            "        },\n",
            "        \"2\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 1.8579894304275513,\n",
            "                \"loss\": 0.006540326762199402,\n",
            "                \"acc\": 46.14\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 1.5927132368087769,\n",
            "                \"loss\": 0.005218375873565674,\n",
            "                \"acc\": 60.5\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 1.2728859186172485,\n",
            "                \"loss\": 0.004230648910999298,\n",
            "                \"acc\": 67.83\n",
            "            },\n",
            "            \"time\": 0.3838539123535156\n",
            "        }\n",
            "    },\n",
            "    \"3\": {\n",
            "        \"0\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 0.5259624719619751,\n",
            "                \"loss\": 0.001310065098851919,\n",
            "                \"acc\": 90.92\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 0.4241620898246765,\n",
            "                \"loss\": 0.0009775260526686906,\n",
            "                \"acc\": 93.22\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 0.26706311106681824,\n",
            "                \"loss\": 0.0008173444006592035,\n",
            "                \"acc\": 93.99\n",
            "            },\n",
            "            \"time\": 0.42835871378580725\n",
            "        },\n",
            "        \"1\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 1.6225982904434204,\n",
            "                \"loss\": 0.0057544766902923586,\n",
            "                \"acc\": 59.64\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 1.295251488685608,\n",
            "                \"loss\": 0.00420419015288353,\n",
            "                \"acc\": 70.07\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 1.155900001525879,\n",
            "                \"loss\": 0.0033988414704799654,\n",
            "                \"acc\": 75.44\n",
            "            },\n",
            "            \"time\": 0.43392181396484375\n",
            "        },\n",
            "        \"2\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 1.407099723815918,\n",
            "                \"loss\": 0.0047797093152999875,\n",
            "                \"acc\": 64.53\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 0.9553828835487366,\n",
            "                \"loss\": 0.003435159331560135,\n",
            "                \"acc\": 74.8\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 0.9004089832305908,\n",
            "                \"loss\": 0.002883328527212143,\n",
            "                \"acc\": 79.67\n",
            "            },\n",
            "            \"time\": 0.41961669921875\n",
            "        }\n",
            "    },\n",
            "    \"4\": {\n",
            "        \"0\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 0.5513060092926025,\n",
            "                \"loss\": 0.0009176120780408383,\n",
            "                \"acc\": 93.57\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 0.45052027702331543,\n",
            "                \"loss\": 0.0007330915594473481,\n",
            "                \"acc\": 94.63\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 0.37856027483940125,\n",
            "                \"loss\": 0.0006463408529758454,\n",
            "                \"acc\": 95.04\n",
            "            },\n",
            "            \"time\": 0.42597452799479163\n",
            "        },\n",
            "        \"1\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 1.3801878690719604,\n",
            "                \"loss\": 0.003279374659061432,\n",
            "                \"acc\": 76.59\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 1.0908796787261963,\n",
            "                \"loss\": 0.0025552284836769103,\n",
            "                \"acc\": 81.5\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 0.9973396062850952,\n",
            "                \"loss\": 0.002167459212243557,\n",
            "                \"acc\": 84.09\n",
            "            },\n",
            "            \"time\": 0.4498163859049479\n",
            "        },\n",
            "        \"2\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 1.058813214302063,\n",
            "                \"loss\": 0.002610666635632515,\n",
            "                \"acc\": 80.28\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 0.9188316464424133,\n",
            "                \"loss\": 0.0021442686885595323,\n",
            "                \"acc\": 84.07\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 0.8139001131057739,\n",
            "                \"loss\": 0.001939412146806717,\n",
            "                \"acc\": 86.07\n",
            "            },\n",
            "            \"time\": 0.4172325134277344\n",
            "        }\n",
            "    },\n",
            "    \"5\": {\n",
            "        \"0\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 0.6691182255744934,\n",
            "                \"loss\": 0.0006502960790880024,\n",
            "                \"acc\": 95.18\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 0.6491013169288635,\n",
            "                \"loss\": 0.0005490875827148557,\n",
            "                \"acc\": 95.81\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 0.47933903336524963,\n",
            "                \"loss\": 0.0004999241857789457,\n",
            "                \"acc\": 96.2\n",
            "            },\n",
            "            \"time\": 0.42279561360677087\n",
            "        },\n",
            "        \"1\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 1.2481260299682617,\n",
            "                \"loss\": 0.0021773475736379623,\n",
            "                \"acc\": 84.17\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 1.0190733671188354,\n",
            "                \"loss\": 0.0018183711126446723,\n",
            "                \"acc\": 86.88\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 0.9486762881278992,\n",
            "                \"loss\": 0.0016296020478010177,\n",
            "                \"acc\": 88.12\n",
            "            },\n",
            "            \"time\": 0.4363059997558594\n",
            "        },\n",
            "        \"2\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 1.147631287574768,\n",
            "                \"loss\": 0.001953464764356613,\n",
            "                \"acc\": 85.67\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 1.0900447368621826,\n",
            "                \"loss\": 0.001666036094725132,\n",
            "                \"acc\": 87.84\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 0.9903292655944824,\n",
            "                \"loss\": 0.0014973020166158676,\n",
            "                \"acc\": 88.99\n",
            "            },\n",
            "            \"time\": 0.43551127115885413\n",
            "        }\n",
            "    },\n",
            "    \"6\": {\n",
            "        \"0\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 0.42010298371315,\n",
            "                \"loss\": 0.0005698721673339605,\n",
            "                \"acc\": 95.71\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 0.3600710332393646,\n",
            "                \"loss\": 0.0004892759680282325,\n",
            "                \"acc\": 96.25\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 0.24716362357139587,\n",
            "                \"loss\": 0.0004440851854626089,\n",
            "                \"acc\": 96.52\n",
            "            },\n",
            "            \"time\": 0.4172325134277344\n",
            "        },\n",
            "        \"1\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 1.023177146911621,\n",
            "                \"loss\": 0.001749087891727686,\n",
            "                \"acc\": 87.06\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 0.8498203754425049,\n",
            "                \"loss\": 0.001558219362050295,\n",
            "                \"acc\": 88.61\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 0.8811331391334534,\n",
            "                \"loss\": 0.0014288979113101959,\n",
            "                \"acc\": 89.34\n",
            "            },\n",
            "            \"time\": 0.4688898722330729\n",
            "        },\n",
            "        \"2\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 0.8200473189353943,\n",
            "                \"loss\": 0.0017136690221726894,\n",
            "                \"acc\": 87.53\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 0.78362637758255,\n",
            "                \"loss\": 0.0014709669448435307,\n",
            "                \"acc\": 89.32\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 0.8499892354011536,\n",
            "                \"loss\": 0.0013611122220754624,\n",
            "                \"acc\": 89.63\n",
            "            },\n",
            "            \"time\": 0.4784266153971354\n",
            "        }\n",
            "    },\n",
            "    \"7\": {\n",
            "        \"0\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 0.32970890402793884,\n",
            "                \"loss\": 0.00048121282644569873,\n",
            "                \"acc\": 96.2\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 0.195431187748909,\n",
            "                \"loss\": 0.0004272887727012858,\n",
            "                \"acc\": 96.7\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 0.3466893434524536,\n",
            "                \"loss\": 0.00038057550599332896,\n",
            "                \"acc\": 96.96\n",
            "            },\n",
            "            \"time\": 0.42994817097981775\n",
            "        },\n",
            "        \"1\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 0.7811146974563599,\n",
            "                \"loss\": 0.0015599076703190803,\n",
            "                \"acc\": 88.38\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 0.5436989068984985,\n",
            "                \"loss\": 0.0013637574926018716,\n",
            "                \"acc\": 89.69\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 0.7953214049339294,\n",
            "                \"loss\": 0.0012651720475405455,\n",
            "                \"acc\": 90.45\n",
            "            },\n",
            "            \"time\": 0.41325887044270837\n",
            "        },\n",
            "        \"2\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 0.9532480835914612,\n",
            "                \"loss\": 0.0014367005765438079,\n",
            "                \"acc\": 89.18\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 1.2621209621429443,\n",
            "                \"loss\": 0.0012565618269145488,\n",
            "                \"acc\": 90.53\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 0.4663394093513489,\n",
            "                \"loss\": 0.0011733840841799974,\n",
            "                \"acc\": 91.19\n",
            "            },\n",
            "            \"time\": 0.43233235677083337\n",
            "        }\n",
            "    },\n",
            "    \"8\": {\n",
            "        \"0\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 0.45043331384658813,\n",
            "                \"loss\": 0.00043057667692191897,\n",
            "                \"acc\": 96.7\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 0.34369397163391113,\n",
            "                \"loss\": 0.0003719350669765845,\n",
            "                \"acc\": 97.11\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 0.2989371418952942,\n",
            "                \"loss\": 0.0003537105667637661,\n",
            "                \"acc\": 97.33\n",
            "            },\n",
            "            \"time\": 0.4212061564127604\n",
            "        },\n",
            "        \"1\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 0.658897876739502,\n",
            "                \"loss\": 0.0014295659806579351,\n",
            "                \"acc\": 89.22\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 0.584862232208252,\n",
            "                \"loss\": 0.0012786278240382672,\n",
            "                \"acc\": 90.17\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 0.6131247878074646,\n",
            "                \"loss\": 0.0011954524435102939,\n",
            "                \"acc\": 90.75\n",
            "            },\n",
            "            \"time\": 0.4291534423828125\n",
            "        },\n",
            "        \"2\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 0.851503312587738,\n",
            "                \"loss\": 0.0013690111860632896,\n",
            "                \"acc\": 89.7\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 0.5997130870819092,\n",
            "                \"loss\": 0.0011896320939064025,\n",
            "                \"acc\": 91.0\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 0.5097864270210266,\n",
            "                \"loss\": 0.001127686496451497,\n",
            "                \"acc\": 91.28\n",
            "            },\n",
            "            \"time\": 0.42438507080078125\n",
            "        }\n",
            "    },\n",
            "    \"9\": {\n",
            "        \"0\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 0.35603535175323486,\n",
            "                \"loss\": 0.00038019699533469977,\n",
            "                \"acc\": 97.06\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 0.38741981983184814,\n",
            "                \"loss\": 0.0003464800464687869,\n",
            "                \"acc\": 97.36\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 0.32131436467170715,\n",
            "                \"loss\": 0.00032040087229106575,\n",
            "                \"acc\": 97.42\n",
            "            },\n",
            "            \"time\": 0.4084904988606771\n",
            "        },\n",
            "        \"1\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 0.6959816217422485,\n",
            "                \"loss\": 0.0013233786046504975,\n",
            "                \"acc\": 89.72\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 0.5820710062980652,\n",
            "                \"loss\": 0.0012010686334222554,\n",
            "                \"acc\": 90.56\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 0.5765084624290466,\n",
            "                \"loss\": 0.0011297800667583943,\n",
            "                \"acc\": 91.08\n",
            "            },\n",
            "            \"time\": 0.4561742146809896\n",
            "        },\n",
            "        \"2\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 0.6940727829933167,\n",
            "                \"loss\": 0.0012457259967923165,\n",
            "                \"acc\": 90.33\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 0.5909097194671631,\n",
            "                \"loss\": 0.0011268669433891773,\n",
            "                \"acc\": 91.16\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 0.6795246005058289,\n",
            "                \"loss\": 0.001075294377282262,\n",
            "                \"acc\": 91.73\n",
            "            },\n",
            "            \"time\": 0.4220008850097656\n",
            "        }\n",
            "    },\n",
            "    \"final_accs\": {\n",
            "        \"0\": 85.78,\n",
            "        \"1\": 73.5,\n",
            "        \"2\": 91.73,\n",
            "        \"avg\": 83.67\n",
            "    }\n",
            "}\n",
            "si\n",
            "{\n",
            "    \"1\": {\n",
            "        \"0\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 2.288982391357422,\n",
            "                \"loss\": 0.009163366436958312,\n",
            "                \"acc\": 18.45\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 2.2601053714752197,\n",
            "                \"loss\": 0.009036232089996338,\n",
            "                \"acc\": 42.47\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 2.197322130203247,\n",
            "                \"loss\": 0.008484111452102662,\n",
            "                \"acc\": 43.03\n",
            "            },\n",
            "            \"time\": 0.7073084513346355\n",
            "        },\n",
            "        \"1\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 2.3066556453704834,\n",
            "                \"loss\": 0.0091843852519989,\n",
            "                \"acc\": 14.74\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 2.3092403411865234,\n",
            "                \"loss\": 0.009142498230934142,\n",
            "                \"acc\": 19.42\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 2.2810349464416504,\n",
            "                \"loss\": 0.009129105806350709,\n",
            "                \"acc\": 22.62\n",
            "            },\n",
            "            \"time\": 0.4251797993977865\n",
            "        },\n",
            "        \"2\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 2.3009254932403564,\n",
            "                \"loss\": 0.009119842839241029,\n",
            "                \"acc\": 20.17\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 2.287254571914673,\n",
            "                \"loss\": 0.009107551765441894,\n",
            "                \"acc\": 19.82\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 2.2976372241973877,\n",
            "                \"loss\": 0.009105771374702453,\n",
            "                \"acc\": 18.19\n",
            "            },\n",
            "            \"time\": 0.4291534423828125\n",
            "        }\n",
            "    },\n",
            "    \"2\": {\n",
            "        \"0\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 1.47563898563385,\n",
            "                \"loss\": 0.0037031627237796784,\n",
            "                \"acc\": 76.97\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 0.8555365800857544,\n",
            "                \"loss\": 0.0018965802222490312,\n",
            "                \"acc\": 86.34\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 0.6982001066207886,\n",
            "                \"loss\": 0.0014448268331587314,\n",
            "                \"acc\": 90.17\n",
            "            },\n",
            "            \"time\": 0.4331270853678385\n",
            "        },\n",
            "        \"1\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 2.334031820297241,\n",
            "                \"loss\": 0.008704758143424987,\n",
            "                \"acc\": 21.76\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 2.329939603805542,\n",
            "                \"loss\": 0.008058484005928039,\n",
            "                \"acc\": 37.55\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 2.277538299560547,\n",
            "                \"loss\": 0.007857767033576966,\n",
            "                \"acc\": 39.11\n",
            "            },\n",
            "            \"time\": 0.40372212727864587\n",
            "        },\n",
            "        \"2\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 2.305785894393921,\n",
            "                \"loss\": 0.00831253571510315,\n",
            "                \"acc\": 30.46\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 2.3055429458618164,\n",
            "                \"loss\": 0.00825920022726059,\n",
            "                \"acc\": 31.48\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 2.302201509475708,\n",
            "                \"loss\": 0.008229767298698426,\n",
            "                \"acc\": 31.96\n",
            "            },\n",
            "            \"time\": 0.4251797993977865\n",
            "        }\n",
            "    },\n",
            "    \"3\": {\n",
            "        \"0\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 0.42312702536582947,\n",
            "                \"loss\": 0.0011159356072545051,\n",
            "                \"acc\": 91.92\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 0.3722698986530304,\n",
            "                \"loss\": 0.0009235059574246407,\n",
            "                \"acc\": 93.19\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 0.4144625663757324,\n",
            "                \"loss\": 0.0007476439727470279,\n",
            "                \"acc\": 94.09\n",
            "            },\n",
            "            \"time\": 0.38782755533854163\n",
            "        },\n",
            "        \"1\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 2.165849447250366,\n",
            "                \"loss\": 0.00768477463722229,\n",
            "                \"acc\": 40.03\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 2.1015923023223877,\n",
            "                \"loss\": 0.007394906973838806,\n",
            "                \"acc\": 43.07\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 2.116346597671509,\n",
            "                \"loss\": 0.007359751307964325,\n",
            "                \"acc\": 43.77\n",
            "            },\n",
            "            \"time\": 0.4482269287109375\n",
            "        },\n",
            "        \"2\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 2.2928309440612793,\n",
            "                \"loss\": 0.0077181107401847835,\n",
            "                \"acc\": 40.02\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 2.2019805908203125,\n",
            "                \"loss\": 0.0075760366678237915,\n",
            "                \"acc\": 39.64\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 2.245518922805786,\n",
            "                \"loss\": 0.007579428255558014,\n",
            "                \"acc\": 41.39\n",
            "            },\n",
            "            \"time\": 0.38782755533854163\n",
            "        }\n",
            "    },\n",
            "    \"4\": {\n",
            "        \"0\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 0.5052129626274109,\n",
            "                \"loss\": 0.0007121291277930141,\n",
            "                \"acc\": 94.51\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 0.435159832239151,\n",
            "                \"loss\": 0.0005911776191554963,\n",
            "                \"acc\": 95.24\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 0.37310561537742615,\n",
            "                \"loss\": 0.0005453216046560556,\n",
            "                \"acc\": 95.65\n",
            "            },\n",
            "            \"time\": 0.41882197062174475\n",
            "        },\n",
            "        \"1\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 2.0345919132232666,\n",
            "                \"loss\": 0.006587878382205963,\n",
            "                \"acc\": 52.52\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 2.0047011375427246,\n",
            "                \"loss\": 0.006516342377662659,\n",
            "                \"acc\": 54.62\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 1.9996607303619385,\n",
            "                \"loss\": 0.0064267778754234315,\n",
            "                \"acc\": 54.37\n",
            "            },\n",
            "            \"time\": 0.442663828531901\n",
            "        },\n",
            "        \"2\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 2.193655490875244,\n",
            "                \"loss\": 0.007059564304351807,\n",
            "                \"acc\": 42.85\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 2.2001829147338867,\n",
            "                \"loss\": 0.007046002948284149,\n",
            "                \"acc\": 44.24\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 2.1913976669311523,\n",
            "                \"loss\": 0.006917003345489502,\n",
            "                \"acc\": 46.27\n",
            "            },\n",
            "            \"time\": 0.4522005716959635\n",
            "        }\n",
            "    },\n",
            "    \"5\": {\n",
            "        \"0\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 0.5578049421310425,\n",
            "                \"loss\": 0.0005022795783355832,\n",
            "                \"acc\": 96.08\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 0.4393634796142578,\n",
            "                \"loss\": 0.00044981735397595915,\n",
            "                \"acc\": 96.52\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 0.35227689146995544,\n",
            "                \"loss\": 0.00042703125509433446,\n",
            "                \"acc\": 96.73\n",
            "            },\n",
            "            \"time\": 0.415643056233724\n",
            "        },\n",
            "        \"1\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 2.1990108489990234,\n",
            "                \"loss\": 0.006415299713611603,\n",
            "                \"acc\": 56.21\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 2.2237863540649414,\n",
            "                \"loss\": 0.006278079569339752,\n",
            "                \"acc\": 58.24\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 2.066645860671997,\n",
            "                \"loss\": 0.0062121346950531,\n",
            "                \"acc\": 57.75\n",
            "            },\n",
            "            \"time\": 0.453790028889974\n",
            "        },\n",
            "        \"2\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 2.1312243938446045,\n",
            "                \"loss\": 0.006700616943836212,\n",
            "                \"acc\": 51.14\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 2.163513660430908,\n",
            "                \"loss\": 0.006635157907009125,\n",
            "                \"acc\": 52.48\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 2.21148943901062,\n",
            "                \"loss\": 0.006768620562553406,\n",
            "                \"acc\": 51.46\n",
            "            },\n",
            "            \"time\": 0.4275639851888021\n",
            "        }\n",
            "    },\n",
            "    \"6\": {\n",
            "        \"0\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 0.35261183977127075,\n",
            "                \"loss\": 0.0003922044415259734,\n",
            "                \"acc\": 96.96\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 0.33994561433792114,\n",
            "                \"loss\": 0.0003641065443400294,\n",
            "                \"acc\": 97.09\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 0.2655746638774872,\n",
            "                \"loss\": 0.00034572489687707277,\n",
            "                \"acc\": 97.22\n",
            "            },\n",
            "            \"time\": 0.4180272420247396\n",
            "        },\n",
            "        \"1\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 2.1198360919952393,\n",
            "                \"loss\": 0.006008326804637909,\n",
            "                \"acc\": 57.71\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 2.1568994522094727,\n",
            "                \"loss\": 0.005996437823772431,\n",
            "                \"acc\": 56.95\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 2.071584939956665,\n",
            "                \"loss\": 0.0060294353723526,\n",
            "                \"acc\": 57.88\n",
            "            },\n",
            "            \"time\": 0.4124641418457031\n",
            "        },\n",
            "        \"2\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 2.1326446533203125,\n",
            "                \"loss\": 0.006333420300483703,\n",
            "                \"acc\": 54.03\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 2.1988742351531982,\n",
            "                \"loss\": 0.0062381223320961,\n",
            "                \"acc\": 55.15\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 2.1719813346862793,\n",
            "                \"loss\": 0.00629458533525467,\n",
            "                \"acc\": 53.12\n",
            "            },\n",
            "            \"time\": 0.41961669921875\n",
            "        }\n",
            "    },\n",
            "    \"7\": {\n",
            "        \"0\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 0.14989672601222992,\n",
            "                \"loss\": 0.00035194842548808084,\n",
            "                \"acc\": 97.15\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 0.21556344628334045,\n",
            "                \"loss\": 0.00033416237775236367,\n",
            "                \"acc\": 97.38\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 0.1860794574022293,\n",
            "                \"loss\": 0.00031240342757664623,\n",
            "                \"acc\": 97.46\n",
            "            },\n",
            "            \"time\": 0.4076957702636719\n",
            "        },\n",
            "        \"1\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 1.557138442993164,\n",
            "                \"loss\": 0.005643065822124481,\n",
            "                \"acc\": 60.7\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 1.7438668012619019,\n",
            "                \"loss\": 0.005710247027873993,\n",
            "                \"acc\": 61.01\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 1.8255726099014282,\n",
            "                \"loss\": 0.005563441610336304,\n",
            "                \"acc\": 61.39\n",
            "            },\n",
            "            \"time\": 0.4752477010091146\n",
            "        },\n",
            "        \"2\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 2.080620050430298,\n",
            "                \"loss\": 0.006134108114242554,\n",
            "                \"acc\": 55.25\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 2.1980552673339844,\n",
            "                \"loss\": 0.0060686442613601685,\n",
            "                \"acc\": 54.62\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 1.9112871885299683,\n",
            "                \"loss\": 0.006031629025936127,\n",
            "                \"acc\": 55.72\n",
            "            },\n",
            "            \"time\": 0.4267692565917969\n",
            "        }\n",
            "    },\n",
            "    \"8\": {\n",
            "        \"0\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 0.30813321471214294,\n",
            "                \"loss\": 0.0002939747471828014,\n",
            "                \"acc\": 97.68\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 0.3929198086261749,\n",
            "                \"loss\": 0.00028806067559635266,\n",
            "                \"acc\": 97.78\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 0.42707082629203796,\n",
            "                \"loss\": 0.0002734502214589156,\n",
            "                \"acc\": 97.84\n",
            "            },\n",
            "            \"time\": 0.44902165730794275\n",
            "        },\n",
            "        \"1\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 1.8420742750167847,\n",
            "                \"loss\": 0.005179232716560364,\n",
            "                \"acc\": 65.24\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 1.8590184450149536,\n",
            "                \"loss\": 0.005322930949926376,\n",
            "                \"acc\": 65.22\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 1.946608304977417,\n",
            "                \"loss\": 0.0052125362277030945,\n",
            "                \"acc\": 64.65\n",
            "            },\n",
            "            \"time\": 0.4482269287109375\n",
            "        },\n",
            "        \"2\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 1.9355510473251343,\n",
            "                \"loss\": 0.005588630378246307,\n",
            "                \"acc\": 60.33\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 1.9514976739883423,\n",
            "                \"loss\": 0.005630765426158905,\n",
            "                \"acc\": 59.7\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 1.9871325492858887,\n",
            "                \"loss\": 0.005686966848373413,\n",
            "                \"acc\": 59.66\n",
            "            },\n",
            "            \"time\": 0.400543212890625\n",
            "        }\n",
            "    },\n",
            "    \"9\": {\n",
            "        \"0\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 0.27563440799713135,\n",
            "                \"loss\": 0.0002711124181339983,\n",
            "                \"acc\": 97.8\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 0.18332652747631073,\n",
            "                \"loss\": 0.0002593362840416376,\n",
            "                \"acc\": 97.92\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 0.22825898230075836,\n",
            "                \"loss\": 0.0002494748776545748,\n",
            "                \"acc\": 97.87\n",
            "            },\n",
            "            \"time\": 0.48001607259114587\n",
            "        },\n",
            "        \"1\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 1.6757605075836182,\n",
            "                \"loss\": 0.004794643479585648,\n",
            "                \"acc\": 67.52\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 1.8159960508346558,\n",
            "                \"loss\": 0.004760275042057037,\n",
            "                \"acc\": 68.24\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 1.7728853225708008,\n",
            "                \"loss\": 0.004802428859472275,\n",
            "                \"acc\": 67.67\n",
            "            },\n",
            "            \"time\": 0.46094258626302087\n",
            "        },\n",
            "        \"2\": {\n",
            "            \"1\": {\n",
            "                \"train_loss\": 1.9312098026275635,\n",
            "                \"loss\": 0.005435413050651551,\n",
            "                \"acc\": 63.12\n",
            "            },\n",
            "            \"2\": {\n",
            "                \"train_loss\": 2.0205652713775635,\n",
            "                \"loss\": 0.005521136891841889,\n",
            "                \"acc\": 62.78\n",
            "            },\n",
            "            \"3\": {\n",
            "                \"train_loss\": 1.9454776048660278,\n",
            "                \"loss\": 0.0054088513612747195,\n",
            "                \"acc\": 62.58\n",
            "            },\n",
            "            \"time\": 0.4371007283528646\n",
            "        }\n",
            "    },\n",
            "    \"final_accs\": {\n",
            "        \"0\": 97.06,\n",
            "        \"1\": 40.65,\n",
            "        \"2\": 62.58,\n",
            "        \"avg\": 66.76333333333334\n",
            "    }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "names = tuple([key for key in DATA])\n",
        "\n",
        "dataset_increments = range(1,10)\n",
        "task_count = range(0,3)\n",
        "epochs = range(1,4)\n",
        "\n",
        "metrics = DATA[names[0]][dataset_increments[0]][task_count[0]][epochs[0]].keys()\n",
        "metrics = tuple([key for key in metrics])\n",
        "\n",
        "sit_names = tuple([key for key in DATA_SIT])\n",
        "sit_metrics = DATA_SIT[sit_names[0]][dataset_increments[0]][epochs[0]].keys()\n",
        "sit_metrics = tuple([key for key in sit_metrics])"
      ],
      "metadata": {
        "id": "4xL4rcaRRHOk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for metric in metrics:\n",
        "  for dataset_increment in dataset_increments:\n",
        "    for task_id in task_count:\n",
        "      plt.figure()\n",
        "      for name in names:\n",
        "        y = []\n",
        "        for epoch in epochs:\n",
        "          y.append(DATA[name][dataset_increment][task_id][epoch][metric])\n",
        "        plt.plot(epochs, y, label=name)\n",
        "\n",
        "      plt.xlabel('Epoch number', fontsize=14)\n",
        "      plt.ylabel(metric, fontsize=14)\n",
        "      plt.title('{} by Epoch number for task {} datasize {}'.format(metric, task_id + 1, dataset_increment), fontsize=14)\n",
        "      plt.xticks(epochs)\n",
        "      plt.legend(prop={'size': 16})"
      ],
      "metadata": {
        "id": "knRSfqNWjUdH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for metric in metrics:\n",
        "  for dataset_increment in dataset_increments:\n",
        "    plt.figure()\n",
        "    for name in names:\n",
        "      y = []\n",
        "      for task_id in task_count:\n",
        "        metric_data = []\n",
        "        for epoch in epochs:\n",
        "          metric_data.append(DATA[name][dataset_increment][task_id][epoch][metric])\n",
        "\n",
        "        y.append(np.average(metric_data))\n",
        "\n",
        "      plt.plot([task for task in task_count], y, label=name)\n",
        "\n",
        "      plt.xlabel('Task number', fontsize=14)\n",
        "      plt.ylabel(metric, fontsize=14)\n",
        "      plt.title('{} by task number for datasize {}'.format(metric, dataset_increment), fontsize=14)\n",
        "      plt.xticks(task_count)\n",
        "      plt.legend(prop={'size': 16})"
      ],
      "metadata": {
        "id": "ivR-vHx8jYns"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for dataset_increment in dataset_increments:\n",
        "  plt.figure()\n",
        "  for name in names:\n",
        "    y = []\n",
        "    for task_id in task_count:\n",
        "      metric_data = []\n",
        "      for epoch in epochs:\n",
        "        metric_data.append(DATA[name][dataset_increment][task_id][\"time\"])\n",
        "\n",
        "      y.append(np.average(metric_data))\n",
        "\n",
        "    plt.plot([task for task in task_count], y, label=name)\n",
        "\n",
        "    plt.xlabel('Task number', fontsize=14)\n",
        "    plt.ylabel(\"Training time\", fontsize=14)\n",
        "    plt.title('Training time by task number for datasize {}'.format(dataset_increment), fontsize=14)\n",
        "    plt.xticks(task_count)\n",
        "    plt.legend(prop={'size': 16})"
      ],
      "metadata": {
        "id": "Tp2dqd_lnfjm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data for test NI model against SI trained for single incremental task (SIT) for fair comparison."
      ],
      "metadata": {
        "id": "hcKETCckzSfb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "for name in sit_names:\n",
        "  y = []\n",
        "  for dataset_increment in dataset_increments:\n",
        "    y.append(DATA_SIT[name][dataset_increment]['time'])\n",
        "\n",
        "  plt.plot([dataset_increment for dataset_increment in dataset_increments], y, label=name)\n",
        "\n",
        "  plt.xlabel('Dataset increments', fontsize=14)\n",
        "  plt.ylabel(\"Training time\", fontsize=14)\n",
        "  plt.title('Training time by dataset increment for SIT', fontsize=14)\n",
        "  plt.xticks(dataset_increments)\n",
        "  plt.legend(prop={'size': 16})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "Rhl5R9R7zeDU",
        "outputId": "ab454efe-b7d7-4433-feb9-15949c078b1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for metric in sit_metrics:\n",
        "  plt.figure()\n",
        "  for name in sit_names:\n",
        "    y = []\n",
        "    for dataset_increment in dataset_increments:\n",
        "        metric_data = []\n",
        "        for epoch in epochs:\n",
        "          metric_data.append(DATA_SIT[name][dataset_increment][epoch][metric])\n",
        "\n",
        "        y.append(np.average(metric_data))\n",
        "\n",
        "    plt.plot([dataset_increment for dataset_increment in dataset_increments], y, label=name)\n",
        "\n",
        "    plt.xlabel('Dataset increments', fontsize=14)\n",
        "    plt.ylabel(metric, fontsize=14)\n",
        "    plt.title('{} by dataset increment for SIT'.format(metric), fontsize=14)\n",
        "    plt.xticks(dataset_increments)\n",
        "    plt.legend(prop={'size': 16})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 866
        },
        "id": "vEeoAO6R8809",
        "outputId": "47b2224a-123e-4ccf-941b-6a457930400b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Error Testing\n",
        "\n",
        "Testing timings of python dict to determine the approximate error percentage"
      ],
      "metadata": {
        "id": "wZHB-YLH-AjA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import timeit\n",
        "\n",
        "timeit.repeat(\"tmp[0]=True; x=tmp[0]\", \n",
        "              \"tmp={};\", \n",
        "              number=100000\n",
        "              )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8A39t1--L5k",
        "outputId": "1b53b145-8d7f-439e-9233-f284d6c43b19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.007472937999978058,\n",
              " 0.008721429999980046,\n",
              " 0.007410044999971888,\n",
              " 0.007513603999996121,\n",
              " 0.007675511000002189]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    }
  ]
}